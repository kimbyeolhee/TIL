{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Deep Learning Skills_CIFAR10 dataset .ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMDauwmuhN3MHuhS9n5PUGR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"154d674edfee431ebf5d3b7878574f76":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_7f35d1d2cc4a464c892a4a7f815a6bc9","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_d2b2b52d78b94b638ceb362f2ed12fb6","IPY_MODEL_31ee4af12e7444bd8d54dc0d7db348d3","IPY_MODEL_73a6cece23a144efbcb6aeed9df7a6af"]}},"7f35d1d2cc4a464c892a4a7f815a6bc9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d2b2b52d78b94b638ceb362f2ed12fb6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_17bb80bd0f4e4e54b2dcadfd69fb6262","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Dl Completed...: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6d2d6845408d471b887c7d0ab04ff708"}},"31ee4af12e7444bd8d54dc0d7db348d3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_be1e5194f6bb42be894f6d24f0471a37","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7340e8b4b49d4fa58e55100573332a95"}},"73a6cece23a144efbcb6aeed9df7a6af":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_777cec4545da4bfe856c7a9ba61e217e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1/1 [00:07&lt;00:00,  4.49s/ url]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_dae9a22b0adf4913b0282e930133b6ef"}},"17bb80bd0f4e4e54b2dcadfd69fb6262":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"6d2d6845408d471b887c7d0ab04ff708":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"be1e5194f6bb42be894f6d24f0471a37":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"7340e8b4b49d4fa58e55100573332a95":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":"20px","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"777cec4545da4bfe856c7a9ba61e217e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"dae9a22b0adf4913b0282e930133b6ef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"665cedca1a3e46b79d7243c6b9e8a371":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_0ba4863025cb49a4b13c0a24e2e35fb5","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_6a9856ef32c142ef9697aeb2ba9604e2","IPY_MODEL_494e7e12ce0742aab75b87ee31fae319","IPY_MODEL_6675846936c649a4b021018be25c7cf9"]}},"0ba4863025cb49a4b13c0a24e2e35fb5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6a9856ef32c142ef9697aeb2ba9604e2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_dd3eaebc4b584d0285d58186bb48b4cd","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Dl Size...: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_79b4fe8aa5d1428caa65b1569959d1ca"}},"494e7e12ce0742aab75b87ee31fae319":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_6d9fc919c17e428cbf032e96f775f0f5","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3a3ed2fb8b364cd5b62e0636e833cefc"}},"6675846936c649a4b021018be25c7cf9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_9cd43daf91e747e7ba8e633bfa4f87b1","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 162/162 [00:07&lt;00:00, 39.73 MiB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6c15485343c84812a883d8b94d993885"}},"dd3eaebc4b584d0285d58186bb48b4cd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"79b4fe8aa5d1428caa65b1569959d1ca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6d9fc919c17e428cbf032e96f775f0f5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"3a3ed2fb8b364cd5b62e0636e833cefc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":"20px","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9cd43daf91e747e7ba8e633bfa4f87b1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"6c15485343c84812a883d8b94d993885":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"74d0de3aace44be69dc5911a6c4ada19":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_643d06468d94425c8e6f2e2e5679ceb9","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_6f52fc69bde247c6a7cb7db512ffb1d0","IPY_MODEL_209bd61470604972ad5b62b73193ba70","IPY_MODEL_294482ddd2a544f4a2bab0972e8e75e3"]}},"643d06468d94425c8e6f2e2e5679ceb9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6f52fc69bde247c6a7cb7db512ffb1d0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ad449e4868fe4ddba5c31fa05485e5b0","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Extraction completed...: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f64c11522f36468e8ffb764b086c52d9"}},"209bd61470604972ad5b62b73193ba70":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_298a660174f94649a4fd503a819ef952","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_dd988af3a36d42448a4ac473cebfd258"}},"294482ddd2a544f4a2bab0972e8e75e3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_29ee6486352c45aeb80ab246d8d0850f","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1/1 [00:07&lt;00:00,  7.01s/ file]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6487f625868446639607c09a012cc20f"}},"ad449e4868fe4ddba5c31fa05485e5b0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f64c11522f36468e8ffb764b086c52d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"298a660174f94649a4fd503a819ef952":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"dd988af3a36d42448a4ac473cebfd258":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":"20px","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"29ee6486352c45aeb80ab246d8d0850f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"6487f625868446639607c09a012cc20f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f1ae4804468b49abb68edf5dd48081ce":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_114a17147e974274ab2ccbc851483556","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_f62e6c240e3a462d87b7149dcf6426ea","IPY_MODEL_604bd4d750e6492ea2296a5db8cb3b7d","IPY_MODEL_f36446e9fbd04105b5fe92d188a04b08"]}},"114a17147e974274ab2ccbc851483556":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f62e6c240e3a462d87b7149dcf6426ea":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e67ffce9bdf942f996965e9ad0aef349","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_dfde8e484fc04819a6ea6f57a23d940c"}},"604bd4d750e6492ea2296a5db8cb3b7d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_e34f3561323345149f2f5894b554857f","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ebf51643a8834b088647538d2b0e4758"}},"f36446e9fbd04105b5fe92d188a04b08":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b802d28a1a0f4df89b76605a4476ca9e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 49921/0 [01:06&lt;00:00, 844.05 examples/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_64b39d9389544c719133d0eb40360270"}},"e67ffce9bdf942f996965e9ad0aef349":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"dfde8e484fc04819a6ea6f57a23d940c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e34f3561323345149f2f5894b554857f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"ebf51643a8834b088647538d2b0e4758":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":"20px","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b802d28a1a0f4df89b76605a4476ca9e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"64b39d9389544c719133d0eb40360270":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"55d97022ba274fab99a69419b69782c3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_aa6b86dcb53546bfbcf3c89971bba470","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_968b302a49bc45249efa628fad99b619","IPY_MODEL_78ecef0baf9542c6ad8f4f501b97d943","IPY_MODEL_fa1e7e94e1a543f4becad13daeee703b"]}},"aa6b86dcb53546bfbcf3c89971bba470":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"968b302a49bc45249efa628fad99b619":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_8b956d5792ca410994a466919aef2410","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_756875feed0744bb9a993893ff30461a"}},"78ecef0baf9542c6ad8f4f501b97d943":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_27d77cdc07454c49a58641c17fd034e2","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"danger","max":50000,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":49999,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_605b4e12a4ef4abd87311006368e912f"}},"fa1e7e94e1a543f4becad13daeee703b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_17bda74c80a8455d8eedbfd231cc997e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 49999/50000 [00:00&lt;00:00, 111490.87 examples/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b7e527ecf68941b9b850e1a73804870a"}},"8b956d5792ca410994a466919aef2410":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"756875feed0744bb9a993893ff30461a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"27d77cdc07454c49a58641c17fd034e2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"605b4e12a4ef4abd87311006368e912f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"17bda74c80a8455d8eedbfd231cc997e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"b7e527ecf68941b9b850e1a73804870a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7212156e75164fa2a752dbe8a978c1b5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_5afc4c556eef4424bf92b90d5b1f6a14","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_bcc92c9921fd40f89a626a53752df765","IPY_MODEL_6375a045e4a6401aa610f55952cd01a2","IPY_MODEL_74108a2b2d6f4e56987c443d71ef8fc5"]}},"5afc4c556eef4424bf92b90d5b1f6a14":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bcc92c9921fd40f89a626a53752df765":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_c60e569db9a3462ab373dedf467881b7","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a51d17fea243499bb3143e1a2ef76cc1"}},"6375a045e4a6401aa610f55952cd01a2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_83d2a50557604ef5ac35eb1f619359e1","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1f0947b1b8da47db9c2e618df8e9dbac"}},"74108a2b2d6f4e56987c443d71ef8fc5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e3f4e43565314bc19a956f415a8769bd","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 9966/0 [00:12&lt;00:00, 843.42 examples/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_675ba730e2564267803c35a91b5fd628"}},"c60e569db9a3462ab373dedf467881b7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a51d17fea243499bb3143e1a2ef76cc1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"83d2a50557604ef5ac35eb1f619359e1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"1f0947b1b8da47db9c2e618df8e9dbac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":"20px","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e3f4e43565314bc19a956f415a8769bd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"675ba730e2564267803c35a91b5fd628":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"256398f7eb9e42649026851209526f9e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_9f4a2f348ec74392969afbaacadeb89b","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_7c17024585e74f1589c572c606de694f","IPY_MODEL_99251c550956429a9f81c011e7460bb6","IPY_MODEL_ca3badeade6f43d0a385c68ba710749d"]}},"9f4a2f348ec74392969afbaacadeb89b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7c17024585e74f1589c572c606de694f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b0b114ad634a47f9aa4ebe69604c5ab3","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8a79aedc15384d019148dda305a1097c"}},"99251c550956429a9f81c011e7460bb6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_46a2a569ce6c41adaee45a9d865cabd2","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"danger","max":10000,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":9999,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6e6596df7d4d402aa43f2fd522417d64"}},"ca3badeade6f43d0a385c68ba710749d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_51822b96b92842a7a63d9eaf85e63e2e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 9999/10000 [00:00&lt;00:00, 33194.02 examples/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_dd56b93a3ee54a1186ba2d58d734f783"}},"b0b114ad634a47f9aa4ebe69604c5ab3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"8a79aedc15384d019148dda305a1097c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"46a2a569ce6c41adaee45a9d865cabd2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"6e6596df7d4d402aa43f2fd522417d64":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"51822b96b92842a7a63d9eaf85e63e2e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"dd56b93a3ee54a1186ba2d58d734f783":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"0J7qLsOkMXvo"},"source":["# Tensorflow dataset 'CIFAR10' Load"]},{"cell_type":"code","metadata":{"id":"TKj8I0adzoln","executionInfo":{"status":"ok","timestamp":1630916865167,"user_tz":-540,"elapsed":3064,"user":{"displayName":"김별희","photoUrl":"","userId":"06602448826503759202"}}},"source":["import tensorflow as tf\n","import tensorflow_datasets as tfds"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":321,"referenced_widgets":["154d674edfee431ebf5d3b7878574f76","7f35d1d2cc4a464c892a4a7f815a6bc9","d2b2b52d78b94b638ceb362f2ed12fb6","31ee4af12e7444bd8d54dc0d7db348d3","73a6cece23a144efbcb6aeed9df7a6af","17bb80bd0f4e4e54b2dcadfd69fb6262","6d2d6845408d471b887c7d0ab04ff708","be1e5194f6bb42be894f6d24f0471a37","7340e8b4b49d4fa58e55100573332a95","777cec4545da4bfe856c7a9ba61e217e","dae9a22b0adf4913b0282e930133b6ef","665cedca1a3e46b79d7243c6b9e8a371","0ba4863025cb49a4b13c0a24e2e35fb5","6a9856ef32c142ef9697aeb2ba9604e2","494e7e12ce0742aab75b87ee31fae319","6675846936c649a4b021018be25c7cf9","dd3eaebc4b584d0285d58186bb48b4cd","79b4fe8aa5d1428caa65b1569959d1ca","6d9fc919c17e428cbf032e96f775f0f5","3a3ed2fb8b364cd5b62e0636e833cefc","9cd43daf91e747e7ba8e633bfa4f87b1","6c15485343c84812a883d8b94d993885","74d0de3aace44be69dc5911a6c4ada19","643d06468d94425c8e6f2e2e5679ceb9","6f52fc69bde247c6a7cb7db512ffb1d0","209bd61470604972ad5b62b73193ba70","294482ddd2a544f4a2bab0972e8e75e3","ad449e4868fe4ddba5c31fa05485e5b0","f64c11522f36468e8ffb764b086c52d9","298a660174f94649a4fd503a819ef952","dd988af3a36d42448a4ac473cebfd258","29ee6486352c45aeb80ab246d8d0850f","6487f625868446639607c09a012cc20f","f1ae4804468b49abb68edf5dd48081ce","114a17147e974274ab2ccbc851483556","f62e6c240e3a462d87b7149dcf6426ea","604bd4d750e6492ea2296a5db8cb3b7d","f36446e9fbd04105b5fe92d188a04b08","e67ffce9bdf942f996965e9ad0aef349","dfde8e484fc04819a6ea6f57a23d940c","e34f3561323345149f2f5894b554857f","ebf51643a8834b088647538d2b0e4758","b802d28a1a0f4df89b76605a4476ca9e","64b39d9389544c719133d0eb40360270","55d97022ba274fab99a69419b69782c3","aa6b86dcb53546bfbcf3c89971bba470","968b302a49bc45249efa628fad99b619","78ecef0baf9542c6ad8f4f501b97d943","fa1e7e94e1a543f4becad13daeee703b","8b956d5792ca410994a466919aef2410","756875feed0744bb9a993893ff30461a","27d77cdc07454c49a58641c17fd034e2","605b4e12a4ef4abd87311006368e912f","17bda74c80a8455d8eedbfd231cc997e","b7e527ecf68941b9b850e1a73804870a","7212156e75164fa2a752dbe8a978c1b5","5afc4c556eef4424bf92b90d5b1f6a14","bcc92c9921fd40f89a626a53752df765","6375a045e4a6401aa610f55952cd01a2","74108a2b2d6f4e56987c443d71ef8fc5","c60e569db9a3462ab373dedf467881b7","a51d17fea243499bb3143e1a2ef76cc1","83d2a50557604ef5ac35eb1f619359e1","1f0947b1b8da47db9c2e618df8e9dbac","e3f4e43565314bc19a956f415a8769bd","675ba730e2564267803c35a91b5fd628","256398f7eb9e42649026851209526f9e","9f4a2f348ec74392969afbaacadeb89b","7c17024585e74f1589c572c606de694f","99251c550956429a9f81c011e7460bb6","ca3badeade6f43d0a385c68ba710749d","b0b114ad634a47f9aa4ebe69604c5ab3","8a79aedc15384d019148dda305a1097c","46a2a569ce6c41adaee45a9d865cabd2","6e6596df7d4d402aa43f2fd522417d64","51822b96b92842a7a63d9eaf85e63e2e","dd56b93a3ee54a1186ba2d58d734f783"]},"id":"GpIgXiBzzxxy","executionInfo":{"status":"ok","timestamp":1630916952642,"user_tz":-540,"elapsed":87481,"user":{"displayName":"김별희","photoUrl":"","userId":"06602448826503759202"}},"outputId":"2c8930b6-e6bd-40dd-cf6b-783d381931db"},"source":["train_datasets = tfds.load('cifar10', split='train')\n","valid_datasets = tfds.load('cifar10', split='test')"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1mDownloading and preparing dataset cifar10/3.0.2 (download: 162.17 MiB, generated: 132.40 MiB, total: 294.58 MiB) to /root/tensorflow_datasets/cifar10/3.0.2...\u001b[0m\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"154d674edfee431ebf5d3b7878574f76","version_minor":0,"version_major":2},"text/plain":["Dl Completed...: 0 url [00:00, ? url/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"665cedca1a3e46b79d7243c6b9e8a371","version_minor":0,"version_major":2},"text/plain":["Dl Size...: 0 MiB [00:00, ? MiB/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"74d0de3aace44be69dc5911a6c4ada19","version_minor":0,"version_major":2},"text/plain":["Extraction completed...: 0 file [00:00, ? file/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","\n","\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f1ae4804468b49abb68edf5dd48081ce","version_minor":0,"version_major":2},"text/plain":["0 examples [00:00, ? examples/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Shuffling and writing examples to /root/tensorflow_datasets/cifar10/3.0.2.incompleteBI0NRW/cifar10-train.tfrecord\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"55d97022ba274fab99a69419b69782c3","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/50000 [00:00<?, ? examples/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7212156e75164fa2a752dbe8a978c1b5","version_minor":0,"version_major":2},"text/plain":["0 examples [00:00, ? examples/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Shuffling and writing examples to /root/tensorflow_datasets/cifar10/3.0.2.incompleteBI0NRW/cifar10-test.tfrecord\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"256398f7eb9e42649026851209526f9e","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/10000 [00:00<?, ? examples/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\u001b[1mDataset cifar10 downloaded and prepared to /root/tensorflow_datasets/cifar10/3.0.2. Subsequent calls will reuse this data.\u001b[0m\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jE7-pip9z_XS","executionInfo":{"status":"ok","timestamp":1630916952644,"user_tz":-540,"elapsed":30,"user":{"displayName":"김별희","photoUrl":"","userId":"06602448826503759202"}},"outputId":"b35378e6-ca58-418a-dbcd-c789904cf26b"},"source":["train_datasets"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<PrefetchDataset shapes: {id: (), image: (32, 32, 3), label: ()}, types: {id: tf.string, image: tf.uint8, label: tf.int64}>"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"LyluyQgg0Guy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630916952645,"user_tz":-540,"elapsed":27,"user":{"displayName":"김별희","photoUrl":"","userId":"06602448826503759202"}},"outputId":"f43ec80a-67c5-436d-d71b-5c7c6632e547"},"source":["for data in train_datasets.take(5):\n","  image = tf.cast(data['image'],tf.float32) / 255.0\n","  label = data['label']\n","  print(image.shape)\n","  print(label)"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["(32, 32, 3)\n","tf.Tensor(7, shape=(), dtype=int64)\n","(32, 32, 3)\n","tf.Tensor(8, shape=(), dtype=int64)\n","(32, 32, 3)\n","tf.Tensor(4, shape=(), dtype=int64)\n","(32, 32, 3)\n","tf.Tensor(4, shape=(), dtype=int64)\n","(32, 32, 3)\n","tf.Tensor(6, shape=(), dtype=int64)\n"]}]},{"cell_type":"code","metadata":{"id":"uysy_bMaLWZe","executionInfo":{"status":"ok","timestamp":1630916952645,"user_tz":-540,"elapsed":23,"user":{"displayName":"김별희","photoUrl":"","userId":"06602448826503759202"}}},"source":["def preprocessing(data):\n","  image = tf.cast(data['image'], tf.float32) / 255.0\n","  label = data['label']\n","  return image, label"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"26zSDrIpMAzd","executionInfo":{"status":"ok","timestamp":1630916952646,"user_tz":-540,"elapsed":23,"user":{"displayName":"김별희","photoUrl":"","userId":"06602448826503759202"}}},"source":["BATCH_SIZE = 128\n","train_data = train_datasets.map(preprocessing).shuffle(1000).batch(BATCH_SIZE)\n","valid_data = valid_datasets.map(preprocessing).batch(BATCH_SIZE)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8NUoLf5gML_M","executionInfo":{"status":"ok","timestamp":1630916952969,"user_tz":-540,"elapsed":346,"user":{"displayName":"김별희","photoUrl":"","userId":"06602448826503759202"}},"outputId":"768e10b8-ca32-4c50-bf1f-02d41bbd76e6"},"source":["for image, label in train_data.take(1):\n","  print(image.shape)\n","  print(label.shape)"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["(128, 32, 32, 3)\n","(128,)\n"]}]},{"cell_type":"markdown","metadata":{"id":"xq3Szzq1MnAd"},"source":["# Sequential API 모델링"]},{"cell_type":"code","metadata":{"id":"4yGT9ddTMVsd","executionInfo":{"status":"ok","timestamp":1630917497904,"user_tz":-540,"elapsed":225,"user":{"displayName":"김별희","photoUrl":"","userId":"06602448826503759202"}}},"source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"dE1NFnMKMu10","executionInfo":{"status":"ok","timestamp":1630916953423,"user_tz":-540,"elapsed":14,"user":{"displayName":"김별희","photoUrl":"","userId":"06602448826503759202"}}},"source":["model = Sequential([\n","                    Conv2D(32, 3, activation='relu', input_shape=(32, 32, 3)),\n","                    MaxPooling2D(2, 2),\n","                    Conv2D(64, 3, activation='relu'),\n","                    MaxPooling2D(2, 2),\n","                    Flatten(),\n","                    Dense(32, activation='relu'),\n","                    Dense(10, activation='softmax'),\n","])"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7CSe7ytZNRUj","executionInfo":{"status":"ok","timestamp":1630916953704,"user_tz":-540,"elapsed":290,"user":{"displayName":"김별희","photoUrl":"","userId":"06602448826503759202"}},"outputId":"408144e0-cbb9-404f-91ee-63d38bfdbc8c"},"source":["model.summary()"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d (Conv2D)              (None, 30, 30, 32)        896       \n","_________________________________________________________________\n","max_pooling2d (MaxPooling2D) (None, 15, 15, 32)        0         \n","_________________________________________________________________\n","conv2d_1 (Conv2D)            (None, 13, 13, 64)        18496     \n","_________________________________________________________________\n","max_pooling2d_1 (MaxPooling2 (None, 6, 6, 64)          0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 2304)              0         \n","_________________________________________________________________\n","dense (Dense)                (None, 32)                73760     \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 10)                330       \n","=================================================================\n","Total params: 93,482\n","Trainable params: 93,482\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","metadata":{"id":"4h-7vc00NT37","executionInfo":{"status":"ok","timestamp":1630916953704,"user_tz":-540,"elapsed":5,"user":{"displayName":"김별희","photoUrl":"","userId":"06602448826503759202"}}},"source":["model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['acc'])"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NWLDzuejN0li","executionInfo":{"status":"ok","timestamp":1630917082605,"user_tz":-540,"elapsed":128905,"user":{"displayName":"김별희","photoUrl":"","userId":"06602448826503759202"}},"outputId":"e3c265a8-865b-4d58-d40b-723cb0939753"},"source":["model.fit(train_data,\n","          validation_data=(valid_data),\n","          epochs=10,\n","          )"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","391/391 [==============================] - 45s 41ms/step - loss: 1.6692 - acc: 0.3989 - val_loss: 1.4528 - val_acc: 0.4925\n","Epoch 2/10\n","391/391 [==============================] - 9s 22ms/step - loss: 1.3119 - acc: 0.5354 - val_loss: 1.2157 - val_acc: 0.5784\n","Epoch 3/10\n","391/391 [==============================] - 8s 21ms/step - loss: 1.1647 - acc: 0.5929 - val_loss: 1.1310 - val_acc: 0.6073\n","Epoch 4/10\n","391/391 [==============================] - 8s 21ms/step - loss: 1.0746 - acc: 0.6259 - val_loss: 1.0728 - val_acc: 0.6337\n","Epoch 5/10\n","391/391 [==============================] - 8s 21ms/step - loss: 1.0107 - acc: 0.6491 - val_loss: 1.0096 - val_acc: 0.6554\n","Epoch 6/10\n","391/391 [==============================] - 8s 21ms/step - loss: 0.9632 - acc: 0.6672 - val_loss: 0.9742 - val_acc: 0.6711\n","Epoch 7/10\n","391/391 [==============================] - 9s 22ms/step - loss: 0.9196 - acc: 0.6840 - val_loss: 0.9597 - val_acc: 0.6706\n","Epoch 8/10\n","391/391 [==============================] - 9s 22ms/step - loss: 0.8834 - acc: 0.6970 - val_loss: 0.9484 - val_acc: 0.6800\n","Epoch 9/10\n","391/391 [==============================] - 9s 22ms/step - loss: 0.8495 - acc: 0.7086 - val_loss: 0.9483 - val_acc: 0.6772\n","Epoch 10/10\n","391/391 [==============================] - 9s 22ms/step - loss: 0.8185 - acc: 0.7198 - val_loss: 0.9417 - val_acc: 0.6834\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7ff31d6d6610>"]},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","metadata":{"id":"olM7jUETPD-7"},"source":["# Functional API 모델링"]},{"cell_type":"code","metadata":{"id":"4uTndrFGPMBX","executionInfo":{"status":"ok","timestamp":1630917174408,"user_tz":-540,"elapsed":225,"user":{"displayName":"김별희","photoUrl":"","userId":"06602448826503759202"}}},"source":["from tensorflow.keras.layers import Input\n","from tensorflow.keras.models import Model"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"jIaRYH1oPSvI","executionInfo":{"status":"ok","timestamp":1630917405411,"user_tz":-540,"elapsed":227,"user":{"displayName":"김별희","photoUrl":"","userId":"06602448826503759202"}}},"source":["input_ = Input(shape=((32, 32, 3)))"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"uALlRFcHPW6S","executionInfo":{"status":"ok","timestamp":1630917740430,"user_tz":-540,"elapsed":215,"user":{"displayName":"김별희","photoUrl":"","userId":"06602448826503759202"}}},"source":["x = Conv2D(32, 3, activation='relu')(input_)\n","x = MaxPooling2D(2, 2)(x)\n","x = Conv2D(64, 3, activation='relu')(x)\n","x = MaxPooling2D(2, 2)(x)\n","x = Flatten()(x)\n","x = Dense(32, activation='relu')(x)\n","x = Dense(10, activation='softmax')(x)"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"To5XU1DdPfIn","executionInfo":{"status":"ok","timestamp":1630917770005,"user_tz":-540,"elapsed":219,"user":{"displayName":"김별희","photoUrl":"","userId":"06602448826503759202"}}},"source":["model = Model(input_, x)"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2f2nSYbNQtij","executionInfo":{"status":"ok","timestamp":1630917774969,"user_tz":-540,"elapsed":209,"user":{"displayName":"김별희","photoUrl":"","userId":"06602448826503759202"}},"outputId":"31f76d17-f4f9-438d-c854-ec9981cd95bd"},"source":["model.summary()"],"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_2 (InputLayer)         [(None, 32, 32, 3)]       0         \n","_________________________________________________________________\n","conv2d_11 (Conv2D)           (None, 30, 30, 32)        896       \n","_________________________________________________________________\n","max_pooling2d_10 (MaxPooling (None, 15, 15, 32)        0         \n","_________________________________________________________________\n","conv2d_12 (Conv2D)           (None, 13, 13, 64)        18496     \n","_________________________________________________________________\n","max_pooling2d_11 (MaxPooling (None, 6, 6, 64)          0         \n","_________________________________________________________________\n","flatten_1 (Flatten)          (None, 2304)              0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 32)                73760     \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 10)                330       \n","=================================================================\n","Total params: 93,482\n","Trainable params: 93,482\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","metadata":{"id":"2JZnWI_2QxO7","executionInfo":{"status":"ok","timestamp":1630917792168,"user_tz":-540,"elapsed":217,"user":{"displayName":"김별희","photoUrl":"","userId":"06602448826503759202"}}},"source":["model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['acc'])"],"execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LLgzU7IZRo90","executionInfo":{"status":"ok","timestamp":1630917899505,"user_tz":-540,"elapsed":99549,"user":{"displayName":"김별희","photoUrl":"","userId":"06602448826503759202"}},"outputId":"d38d5deb-eeef-4914-8549-51b07c9951d8"},"source":["model.fit(train_data,\n","          validation_data=(valid_data),\n","          epochs=10,\n","          )"],"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","391/391 [==============================] - 9s 22ms/step - loss: 1.6659 - acc: 0.3905 - val_loss: 1.4003 - val_acc: 0.4924\n","Epoch 2/10\n","391/391 [==============================] - 8s 21ms/step - loss: 1.3320 - acc: 0.5244 - val_loss: 1.2593 - val_acc: 0.5464\n","Epoch 3/10\n","391/391 [==============================] - 8s 21ms/step - loss: 1.2020 - acc: 0.5758 - val_loss: 1.1688 - val_acc: 0.5831\n","Epoch 4/10\n","391/391 [==============================] - 8s 21ms/step - loss: 1.1136 - acc: 0.6079 - val_loss: 1.1025 - val_acc: 0.6134\n","Epoch 5/10\n","391/391 [==============================] - 8s 21ms/step - loss: 1.0457 - acc: 0.6341 - val_loss: 1.0335 - val_acc: 0.6440\n","Epoch 6/10\n","391/391 [==============================] - 8s 21ms/step - loss: 0.9858 - acc: 0.6562 - val_loss: 1.0063 - val_acc: 0.6490\n","Epoch 7/10\n","391/391 [==============================] - 8s 21ms/step - loss: 0.9423 - acc: 0.6722 - val_loss: 0.9920 - val_acc: 0.6595\n","Epoch 8/10\n","391/391 [==============================] - 8s 21ms/step - loss: 0.9046 - acc: 0.6883 - val_loss: 0.9544 - val_acc: 0.6725\n","Epoch 9/10\n","391/391 [==============================] - 8s 21ms/step - loss: 0.8701 - acc: 0.6993 - val_loss: 0.9668 - val_acc: 0.6658\n","Epoch 10/10\n","391/391 [==============================] - 8s 21ms/step - loss: 0.8385 - acc: 0.7096 - val_loss: 0.9358 - val_acc: 0.6785\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7ff31befc910>"]},"metadata":{},"execution_count":32}]},{"cell_type":"markdown","metadata":{"id":"LylmmbILR6Nn"},"source":["# train_on_batch 커스텀 학습"]},{"cell_type":"markdown","metadata":{"id":"UF_XffP3TEwd"},"source":["batch 단위의 학습을 한 다음에 batch 별로 loss를 확인하거나 시각화\n","\n","고급학습, 특히 GAN 같은 곳에서 활용\n"]},{"cell_type":"code","metadata":{"id":"GBFwYiQQRq7C","executionInfo":{"status":"ok","timestamp":1630917913788,"user_tz":-540,"elapsed":202,"user":{"displayName":"김별희","photoUrl":"","userId":"06602448826503759202"}}},"source":["model = Sequential([\n","                    Conv2D(32, 3, activation='relu', input_shape=(32, 32, 3)),\n","                    MaxPooling2D(2, 2),\n","                    Conv2D(64, 3, activation='relu'),\n","                    MaxPooling2D(2, 2),\n","                    Flatten(),\n","                    Dense(32, activation='relu'),\n","                    Dense(10, activation='softmax'),\n","])"],"execution_count":33,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SuLXL0JwSGqK","executionInfo":{"status":"ok","timestamp":1630917919740,"user_tz":-540,"elapsed":3,"user":{"displayName":"김별희","photoUrl":"","userId":"06602448826503759202"}},"outputId":"e613f518-c0f1-4f51-8ab2-53d2e563558b"},"source":["model.summary()"],"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_13 (Conv2D)           (None, 30, 30, 32)        896       \n","_________________________________________________________________\n","max_pooling2d_12 (MaxPooling (None, 15, 15, 32)        0         \n","_________________________________________________________________\n","conv2d_14 (Conv2D)           (None, 13, 13, 64)        18496     \n","_________________________________________________________________\n","max_pooling2d_13 (MaxPooling (None, 6, 6, 64)          0         \n","_________________________________________________________________\n","flatten_2 (Flatten)          (None, 2304)              0         \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 32)                73760     \n","_________________________________________________________________\n","dense_5 (Dense)              (None, 10)                330       \n","=================================================================\n","Total params: 93,482\n","Trainable params: 93,482\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","metadata":{"id":"PbYlG88MSIJ6","executionInfo":{"status":"ok","timestamp":1630917954721,"user_tz":-540,"elapsed":202,"user":{"displayName":"김별희","photoUrl":"","userId":"06602448826503759202"}}},"source":["model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['acc'])"],"execution_count":35,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q7ys71wOSQiz","executionInfo":{"status":"ok","timestamp":1630918272258,"user_tz":-540,"elapsed":158238,"user":{"displayName":"김별희","photoUrl":"","userId":"06602448826503759202"}},"outputId":"2988cde1-5256-440c-acc7-f84937043aae"},"source":["EPOCHS = 10\n","\n","for epoch in range(EPOCHS):\n","  for batch, (image, label) in train_data.enumerate():\n","    loss = model.train_on_batch(image, label)\n","    print(f'epoch: {epoch + 1}, batch: {batch + 1}, loss: {loss[0]:.3f}, acc: {loss[1]:.2f}')"],"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["epoch: 1, batch: 1, loss: 2.312, acc: 0.09\n","epoch: 1, batch: 2, loss: 2.294, acc: 0.18\n","epoch: 1, batch: 3, loss: 2.280, acc: 0.10\n","epoch: 1, batch: 4, loss: 2.276, acc: 0.14\n","epoch: 1, batch: 5, loss: 2.304, acc: 0.12\n","epoch: 1, batch: 6, loss: 2.262, acc: 0.15\n","epoch: 1, batch: 7, loss: 2.268, acc: 0.15\n","epoch: 1, batch: 8, loss: 2.289, acc: 0.12\n","epoch: 1, batch: 9, loss: 2.283, acc: 0.13\n","epoch: 1, batch: 10, loss: 2.283, acc: 0.16\n","epoch: 1, batch: 11, loss: 2.258, acc: 0.19\n","epoch: 1, batch: 12, loss: 2.249, acc: 0.21\n","epoch: 1, batch: 13, loss: 2.275, acc: 0.14\n","epoch: 1, batch: 14, loss: 2.242, acc: 0.13\n","epoch: 1, batch: 15, loss: 2.279, acc: 0.10\n","epoch: 1, batch: 16, loss: 2.258, acc: 0.14\n","epoch: 1, batch: 17, loss: 2.209, acc: 0.26\n","epoch: 1, batch: 18, loss: 2.221, acc: 0.15\n","epoch: 1, batch: 19, loss: 2.245, acc: 0.15\n","epoch: 1, batch: 20, loss: 2.210, acc: 0.18\n","epoch: 1, batch: 21, loss: 2.202, acc: 0.16\n","epoch: 1, batch: 22, loss: 2.174, acc: 0.18\n","epoch: 1, batch: 23, loss: 2.172, acc: 0.26\n","epoch: 1, batch: 24, loss: 2.167, acc: 0.24\n","epoch: 1, batch: 25, loss: 2.197, acc: 0.24\n","epoch: 1, batch: 26, loss: 2.184, acc: 0.21\n","epoch: 1, batch: 27, loss: 2.184, acc: 0.16\n","epoch: 1, batch: 28, loss: 2.179, acc: 0.18\n","epoch: 1, batch: 29, loss: 2.155, acc: 0.23\n","epoch: 1, batch: 30, loss: 2.088, acc: 0.23\n","epoch: 1, batch: 31, loss: 2.288, acc: 0.13\n","epoch: 1, batch: 32, loss: 2.123, acc: 0.24\n","epoch: 1, batch: 33, loss: 2.158, acc: 0.20\n","epoch: 1, batch: 34, loss: 2.100, acc: 0.27\n","epoch: 1, batch: 35, loss: 2.118, acc: 0.21\n","epoch: 1, batch: 36, loss: 2.119, acc: 0.20\n","epoch: 1, batch: 37, loss: 2.149, acc: 0.19\n","epoch: 1, batch: 38, loss: 2.091, acc: 0.22\n","epoch: 1, batch: 39, loss: 2.053, acc: 0.30\n","epoch: 1, batch: 40, loss: 2.141, acc: 0.22\n","epoch: 1, batch: 41, loss: 2.059, acc: 0.20\n","epoch: 1, batch: 42, loss: 2.133, acc: 0.19\n","epoch: 1, batch: 43, loss: 2.012, acc: 0.30\n","epoch: 1, batch: 44, loss: 1.991, acc: 0.22\n","epoch: 1, batch: 45, loss: 2.063, acc: 0.20\n","epoch: 1, batch: 46, loss: 2.136, acc: 0.24\n","epoch: 1, batch: 47, loss: 2.079, acc: 0.28\n","epoch: 1, batch: 48, loss: 1.959, acc: 0.36\n","epoch: 1, batch: 49, loss: 2.172, acc: 0.20\n","epoch: 1, batch: 50, loss: 2.051, acc: 0.26\n","epoch: 1, batch: 51, loss: 2.076, acc: 0.27\n","epoch: 1, batch: 52, loss: 2.056, acc: 0.24\n","epoch: 1, batch: 53, loss: 2.021, acc: 0.28\n","epoch: 1, batch: 54, loss: 2.030, acc: 0.31\n","epoch: 1, batch: 55, loss: 2.085, acc: 0.16\n","epoch: 1, batch: 56, loss: 2.073, acc: 0.22\n","epoch: 1, batch: 57, loss: 2.039, acc: 0.28\n","epoch: 1, batch: 58, loss: 2.039, acc: 0.24\n","epoch: 1, batch: 59, loss: 2.039, acc: 0.26\n","epoch: 1, batch: 60, loss: 2.038, acc: 0.28\n","epoch: 1, batch: 61, loss: 2.036, acc: 0.27\n","epoch: 1, batch: 62, loss: 1.903, acc: 0.27\n","epoch: 1, batch: 63, loss: 1.976, acc: 0.27\n","epoch: 1, batch: 64, loss: 1.978, acc: 0.29\n","epoch: 1, batch: 65, loss: 2.032, acc: 0.27\n","epoch: 1, batch: 66, loss: 1.941, acc: 0.31\n","epoch: 1, batch: 67, loss: 1.989, acc: 0.28\n","epoch: 1, batch: 68, loss: 2.062, acc: 0.20\n","epoch: 1, batch: 69, loss: 1.781, acc: 0.45\n","epoch: 1, batch: 70, loss: 1.977, acc: 0.30\n","epoch: 1, batch: 71, loss: 2.045, acc: 0.23\n","epoch: 1, batch: 72, loss: 1.915, acc: 0.34\n","epoch: 1, batch: 73, loss: 1.900, acc: 0.34\n","epoch: 1, batch: 74, loss: 1.986, acc: 0.31\n","epoch: 1, batch: 75, loss: 2.078, acc: 0.21\n","epoch: 1, batch: 76, loss: 1.924, acc: 0.33\n","epoch: 1, batch: 77, loss: 1.912, acc: 0.36\n","epoch: 1, batch: 78, loss: 1.946, acc: 0.27\n","epoch: 1, batch: 79, loss: 1.882, acc: 0.40\n","epoch: 1, batch: 80, loss: 1.869, acc: 0.35\n","epoch: 1, batch: 81, loss: 1.909, acc: 0.34\n","epoch: 1, batch: 82, loss: 1.880, acc: 0.36\n","epoch: 1, batch: 83, loss: 1.786, acc: 0.41\n","epoch: 1, batch: 84, loss: 1.964, acc: 0.27\n","epoch: 1, batch: 85, loss: 1.801, acc: 0.37\n","epoch: 1, batch: 86, loss: 1.785, acc: 0.36\n","epoch: 1, batch: 87, loss: 1.824, acc: 0.33\n","epoch: 1, batch: 88, loss: 1.843, acc: 0.32\n","epoch: 1, batch: 89, loss: 1.963, acc: 0.28\n","epoch: 1, batch: 90, loss: 1.886, acc: 0.34\n","epoch: 1, batch: 91, loss: 1.723, acc: 0.41\n","epoch: 1, batch: 92, loss: 1.864, acc: 0.30\n","epoch: 1, batch: 93, loss: 1.849, acc: 0.29\n","epoch: 1, batch: 94, loss: 1.813, acc: 0.37\n","epoch: 1, batch: 95, loss: 1.813, acc: 0.32\n","epoch: 1, batch: 96, loss: 1.775, acc: 0.30\n","epoch: 1, batch: 97, loss: 1.662, acc: 0.40\n","epoch: 1, batch: 98, loss: 1.601, acc: 0.44\n","epoch: 1, batch: 99, loss: 1.813, acc: 0.38\n","epoch: 1, batch: 100, loss: 1.880, acc: 0.31\n","epoch: 1, batch: 101, loss: 1.904, acc: 0.27\n","epoch: 1, batch: 102, loss: 1.665, acc: 0.38\n","epoch: 1, batch: 103, loss: 1.852, acc: 0.41\n","epoch: 1, batch: 104, loss: 1.796, acc: 0.34\n","epoch: 1, batch: 105, loss: 1.760, acc: 0.34\n","epoch: 1, batch: 106, loss: 1.801, acc: 0.39\n","epoch: 1, batch: 107, loss: 1.680, acc: 0.38\n","epoch: 1, batch: 108, loss: 1.575, acc: 0.46\n","epoch: 1, batch: 109, loss: 1.862, acc: 0.35\n","epoch: 1, batch: 110, loss: 1.680, acc: 0.40\n","epoch: 1, batch: 111, loss: 1.701, acc: 0.41\n","epoch: 1, batch: 112, loss: 1.717, acc: 0.35\n","epoch: 1, batch: 113, loss: 1.742, acc: 0.38\n","epoch: 1, batch: 114, loss: 1.687, acc: 0.40\n","epoch: 1, batch: 115, loss: 1.876, acc: 0.32\n","epoch: 1, batch: 116, loss: 1.704, acc: 0.38\n","epoch: 1, batch: 117, loss: 1.664, acc: 0.40\n","epoch: 1, batch: 118, loss: 1.732, acc: 0.43\n","epoch: 1, batch: 119, loss: 1.826, acc: 0.40\n","epoch: 1, batch: 120, loss: 1.691, acc: 0.37\n","epoch: 1, batch: 121, loss: 1.629, acc: 0.39\n","epoch: 1, batch: 122, loss: 1.890, acc: 0.29\n","epoch: 1, batch: 123, loss: 1.595, acc: 0.41\n","epoch: 1, batch: 124, loss: 1.757, acc: 0.33\n","epoch: 1, batch: 125, loss: 1.587, acc: 0.38\n","epoch: 1, batch: 126, loss: 1.641, acc: 0.41\n","epoch: 1, batch: 127, loss: 1.712, acc: 0.31\n","epoch: 1, batch: 128, loss: 1.728, acc: 0.46\n","epoch: 1, batch: 129, loss: 1.525, acc: 0.53\n","epoch: 1, batch: 130, loss: 1.677, acc: 0.40\n","epoch: 1, batch: 131, loss: 1.590, acc: 0.41\n","epoch: 1, batch: 132, loss: 1.652, acc: 0.34\n","epoch: 1, batch: 133, loss: 1.687, acc: 0.37\n","epoch: 1, batch: 134, loss: 1.603, acc: 0.45\n","epoch: 1, batch: 135, loss: 1.745, acc: 0.35\n","epoch: 1, batch: 136, loss: 1.544, acc: 0.43\n","epoch: 1, batch: 137, loss: 1.676, acc: 0.40\n","epoch: 1, batch: 138, loss: 1.586, acc: 0.47\n","epoch: 1, batch: 139, loss: 1.608, acc: 0.38\n","epoch: 1, batch: 140, loss: 1.635, acc: 0.41\n","epoch: 1, batch: 141, loss: 1.658, acc: 0.44\n","epoch: 1, batch: 142, loss: 1.620, acc: 0.41\n","epoch: 1, batch: 143, loss: 1.736, acc: 0.36\n","epoch: 1, batch: 144, loss: 1.516, acc: 0.49\n","epoch: 1, batch: 145, loss: 1.586, acc: 0.44\n","epoch: 1, batch: 146, loss: 1.596, acc: 0.38\n","epoch: 1, batch: 147, loss: 1.760, acc: 0.37\n","epoch: 1, batch: 148, loss: 1.774, acc: 0.37\n","epoch: 1, batch: 149, loss: 1.654, acc: 0.43\n","epoch: 1, batch: 150, loss: 1.525, acc: 0.46\n","epoch: 1, batch: 151, loss: 1.651, acc: 0.39\n","epoch: 1, batch: 152, loss: 1.720, acc: 0.43\n","epoch: 1, batch: 153, loss: 1.638, acc: 0.38\n","epoch: 1, batch: 154, loss: 1.587, acc: 0.41\n","epoch: 1, batch: 155, loss: 1.583, acc: 0.41\n","epoch: 1, batch: 156, loss: 1.734, acc: 0.27\n","epoch: 1, batch: 157, loss: 1.556, acc: 0.46\n","epoch: 1, batch: 158, loss: 1.601, acc: 0.42\n","epoch: 1, batch: 159, loss: 1.612, acc: 0.39\n","epoch: 1, batch: 160, loss: 1.580, acc: 0.41\n","epoch: 1, batch: 161, loss: 1.585, acc: 0.45\n","epoch: 1, batch: 162, loss: 1.665, acc: 0.37\n","epoch: 1, batch: 163, loss: 1.650, acc: 0.41\n","epoch: 1, batch: 164, loss: 1.445, acc: 0.46\n","epoch: 1, batch: 165, loss: 1.559, acc: 0.42\n","epoch: 1, batch: 166, loss: 1.752, acc: 0.37\n","epoch: 1, batch: 167, loss: 1.513, acc: 0.40\n","epoch: 1, batch: 168, loss: 1.547, acc: 0.42\n","epoch: 1, batch: 169, loss: 1.628, acc: 0.41\n","epoch: 1, batch: 170, loss: 1.659, acc: 0.34\n","epoch: 1, batch: 171, loss: 1.589, acc: 0.38\n","epoch: 1, batch: 172, loss: 1.530, acc: 0.42\n","epoch: 1, batch: 173, loss: 1.559, acc: 0.42\n","epoch: 1, batch: 174, loss: 1.578, acc: 0.39\n","epoch: 1, batch: 175, loss: 1.534, acc: 0.45\n","epoch: 1, batch: 176, loss: 1.460, acc: 0.47\n","epoch: 1, batch: 177, loss: 1.539, acc: 0.47\n","epoch: 1, batch: 178, loss: 1.550, acc: 0.40\n","epoch: 1, batch: 179, loss: 1.575, acc: 0.48\n","epoch: 1, batch: 180, loss: 1.586, acc: 0.38\n","epoch: 1, batch: 181, loss: 1.452, acc: 0.42\n","epoch: 1, batch: 182, loss: 1.622, acc: 0.42\n","epoch: 1, batch: 183, loss: 1.452, acc: 0.49\n","epoch: 1, batch: 184, loss: 1.578, acc: 0.38\n","epoch: 1, batch: 185, loss: 1.422, acc: 0.47\n","epoch: 1, batch: 186, loss: 1.506, acc: 0.50\n","epoch: 1, batch: 187, loss: 1.458, acc: 0.52\n","epoch: 1, batch: 188, loss: 1.539, acc: 0.41\n","epoch: 1, batch: 189, loss: 1.617, acc: 0.43\n","epoch: 1, batch: 190, loss: 1.511, acc: 0.43\n","epoch: 1, batch: 191, loss: 1.606, acc: 0.41\n","epoch: 1, batch: 192, loss: 1.551, acc: 0.40\n","epoch: 1, batch: 193, loss: 1.673, acc: 0.38\n","epoch: 1, batch: 194, loss: 1.497, acc: 0.45\n","epoch: 1, batch: 195, loss: 1.411, acc: 0.45\n","epoch: 1, batch: 196, loss: 1.553, acc: 0.45\n","epoch: 1, batch: 197, loss: 1.489, acc: 0.45\n","epoch: 1, batch: 198, loss: 1.492, acc: 0.52\n","epoch: 1, batch: 199, loss: 1.502, acc: 0.43\n","epoch: 1, batch: 200, loss: 1.580, acc: 0.43\n","epoch: 1, batch: 201, loss: 1.569, acc: 0.43\n","epoch: 1, batch: 202, loss: 1.584, acc: 0.44\n","epoch: 1, batch: 203, loss: 1.508, acc: 0.45\n","epoch: 1, batch: 204, loss: 1.470, acc: 0.45\n","epoch: 1, batch: 205, loss: 1.583, acc: 0.43\n","epoch: 1, batch: 206, loss: 1.563, acc: 0.41\n","epoch: 1, batch: 207, loss: 1.520, acc: 0.48\n","epoch: 1, batch: 208, loss: 1.607, acc: 0.39\n","epoch: 1, batch: 209, loss: 1.537, acc: 0.35\n","epoch: 1, batch: 210, loss: 1.475, acc: 0.53\n","epoch: 1, batch: 211, loss: 1.520, acc: 0.50\n","epoch: 1, batch: 212, loss: 1.495, acc: 0.46\n","epoch: 1, batch: 213, loss: 1.584, acc: 0.37\n","epoch: 1, batch: 214, loss: 1.604, acc: 0.45\n","epoch: 1, batch: 215, loss: 1.515, acc: 0.45\n","epoch: 1, batch: 216, loss: 1.491, acc: 0.52\n","epoch: 1, batch: 217, loss: 1.598, acc: 0.39\n","epoch: 1, batch: 218, loss: 1.456, acc: 0.50\n","epoch: 1, batch: 219, loss: 1.551, acc: 0.44\n","epoch: 1, batch: 220, loss: 1.530, acc: 0.36\n","epoch: 1, batch: 221, loss: 1.608, acc: 0.41\n","epoch: 1, batch: 222, loss: 1.497, acc: 0.45\n","epoch: 1, batch: 223, loss: 1.420, acc: 0.49\n","epoch: 1, batch: 224, loss: 1.633, acc: 0.40\n","epoch: 1, batch: 225, loss: 1.568, acc: 0.45\n","epoch: 1, batch: 226, loss: 1.362, acc: 0.49\n","epoch: 1, batch: 227, loss: 1.461, acc: 0.45\n","epoch: 1, batch: 228, loss: 1.423, acc: 0.53\n","epoch: 1, batch: 229, loss: 1.568, acc: 0.39\n","epoch: 1, batch: 230, loss: 1.636, acc: 0.41\n","epoch: 1, batch: 231, loss: 1.550, acc: 0.34\n","epoch: 1, batch: 232, loss: 1.390, acc: 0.53\n","epoch: 1, batch: 233, loss: 1.427, acc: 0.45\n","epoch: 1, batch: 234, loss: 1.556, acc: 0.48\n","epoch: 1, batch: 235, loss: 1.434, acc: 0.58\n","epoch: 1, batch: 236, loss: 1.388, acc: 0.49\n","epoch: 1, batch: 237, loss: 1.436, acc: 0.47\n","epoch: 1, batch: 238, loss: 1.341, acc: 0.50\n","epoch: 1, batch: 239, loss: 1.347, acc: 0.52\n","epoch: 1, batch: 240, loss: 1.354, acc: 0.51\n","epoch: 1, batch: 241, loss: 1.518, acc: 0.48\n","epoch: 1, batch: 242, loss: 1.443, acc: 0.50\n","epoch: 1, batch: 243, loss: 1.493, acc: 0.43\n","epoch: 1, batch: 244, loss: 1.484, acc: 0.44\n","epoch: 1, batch: 245, loss: 1.491, acc: 0.48\n","epoch: 1, batch: 246, loss: 1.366, acc: 0.56\n","epoch: 1, batch: 247, loss: 1.628, acc: 0.41\n","epoch: 1, batch: 248, loss: 1.440, acc: 0.44\n","epoch: 1, batch: 249, loss: 1.545, acc: 0.49\n","epoch: 1, batch: 250, loss: 1.522, acc: 0.52\n","epoch: 1, batch: 251, loss: 1.387, acc: 0.56\n","epoch: 1, batch: 252, loss: 1.457, acc: 0.46\n","epoch: 1, batch: 253, loss: 1.403, acc: 0.49\n","epoch: 1, batch: 254, loss: 1.501, acc: 0.48\n","epoch: 1, batch: 255, loss: 1.479, acc: 0.48\n","epoch: 1, batch: 256, loss: 1.543, acc: 0.46\n","epoch: 1, batch: 257, loss: 1.450, acc: 0.49\n","epoch: 1, batch: 258, loss: 1.577, acc: 0.44\n","epoch: 1, batch: 259, loss: 1.538, acc: 0.46\n","epoch: 1, batch: 260, loss: 1.514, acc: 0.47\n","epoch: 1, batch: 261, loss: 1.280, acc: 0.46\n","epoch: 1, batch: 262, loss: 1.584, acc: 0.42\n","epoch: 1, batch: 263, loss: 1.483, acc: 0.42\n","epoch: 1, batch: 264, loss: 1.455, acc: 0.50\n","epoch: 1, batch: 265, loss: 1.482, acc: 0.46\n","epoch: 1, batch: 266, loss: 1.541, acc: 0.49\n","epoch: 1, batch: 267, loss: 1.509, acc: 0.49\n","epoch: 1, batch: 268, loss: 1.421, acc: 0.50\n","epoch: 1, batch: 269, loss: 1.515, acc: 0.45\n","epoch: 1, batch: 270, loss: 1.438, acc: 0.48\n","epoch: 1, batch: 271, loss: 1.531, acc: 0.48\n","epoch: 1, batch: 272, loss: 1.336, acc: 0.49\n","epoch: 1, batch: 273, loss: 1.492, acc: 0.44\n","epoch: 1, batch: 274, loss: 1.274, acc: 0.54\n","epoch: 1, batch: 275, loss: 1.579, acc: 0.50\n","epoch: 1, batch: 276, loss: 1.293, acc: 0.53\n","epoch: 1, batch: 277, loss: 1.562, acc: 0.41\n","epoch: 1, batch: 278, loss: 1.694, acc: 0.34\n","epoch: 1, batch: 279, loss: 1.468, acc: 0.48\n","epoch: 1, batch: 280, loss: 1.490, acc: 0.45\n","epoch: 1, batch: 281, loss: 1.551, acc: 0.41\n","epoch: 1, batch: 282, loss: 1.361, acc: 0.52\n","epoch: 1, batch: 283, loss: 1.508, acc: 0.38\n","epoch: 1, batch: 284, loss: 1.507, acc: 0.46\n","epoch: 1, batch: 285, loss: 1.500, acc: 0.47\n","epoch: 1, batch: 286, loss: 1.305, acc: 0.52\n","epoch: 1, batch: 287, loss: 1.414, acc: 0.50\n","epoch: 1, batch: 288, loss: 1.542, acc: 0.45\n","epoch: 1, batch: 289, loss: 1.443, acc: 0.51\n","epoch: 1, batch: 290, loss: 1.372, acc: 0.44\n","epoch: 1, batch: 291, loss: 1.575, acc: 0.41\n","epoch: 1, batch: 292, loss: 1.463, acc: 0.45\n","epoch: 1, batch: 293, loss: 1.510, acc: 0.47\n","epoch: 1, batch: 294, loss: 1.604, acc: 0.40\n","epoch: 1, batch: 295, loss: 1.429, acc: 0.45\n","epoch: 1, batch: 296, loss: 1.463, acc: 0.48\n","epoch: 1, batch: 297, loss: 1.417, acc: 0.48\n","epoch: 1, batch: 298, loss: 1.364, acc: 0.51\n","epoch: 1, batch: 299, loss: 1.386, acc: 0.55\n","epoch: 1, batch: 300, loss: 1.535, acc: 0.41\n","epoch: 1, batch: 301, loss: 1.400, acc: 0.53\n","epoch: 1, batch: 302, loss: 1.440, acc: 0.40\n","epoch: 1, batch: 303, loss: 1.490, acc: 0.51\n","epoch: 1, batch: 304, loss: 1.237, acc: 0.47\n","epoch: 1, batch: 305, loss: 1.341, acc: 0.55\n","epoch: 1, batch: 306, loss: 1.538, acc: 0.40\n","epoch: 1, batch: 307, loss: 1.415, acc: 0.45\n","epoch: 1, batch: 308, loss: 1.390, acc: 0.47\n","epoch: 1, batch: 309, loss: 1.320, acc: 0.54\n","epoch: 1, batch: 310, loss: 1.264, acc: 0.56\n","epoch: 1, batch: 311, loss: 1.245, acc: 0.52\n","epoch: 1, batch: 312, loss: 1.513, acc: 0.47\n","epoch: 1, batch: 313, loss: 1.422, acc: 0.48\n","epoch: 1, batch: 314, loss: 1.545, acc: 0.45\n","epoch: 1, batch: 315, loss: 1.634, acc: 0.46\n","epoch: 1, batch: 316, loss: 1.490, acc: 0.44\n","epoch: 1, batch: 317, loss: 1.476, acc: 0.44\n","epoch: 1, batch: 318, loss: 1.396, acc: 0.50\n","epoch: 1, batch: 319, loss: 1.242, acc: 0.55\n","epoch: 1, batch: 320, loss: 1.423, acc: 0.46\n","epoch: 1, batch: 321, loss: 1.466, acc: 0.50\n","epoch: 1, batch: 322, loss: 1.315, acc: 0.52\n","epoch: 1, batch: 323, loss: 1.406, acc: 0.51\n","epoch: 1, batch: 324, loss: 1.438, acc: 0.47\n","epoch: 1, batch: 325, loss: 1.357, acc: 0.48\n","epoch: 1, batch: 326, loss: 1.275, acc: 0.57\n","epoch: 1, batch: 327, loss: 1.389, acc: 0.52\n","epoch: 1, batch: 328, loss: 1.504, acc: 0.41\n","epoch: 1, batch: 329, loss: 1.502, acc: 0.49\n","epoch: 1, batch: 330, loss: 1.421, acc: 0.47\n","epoch: 1, batch: 331, loss: 1.502, acc: 0.43\n","epoch: 1, batch: 332, loss: 1.491, acc: 0.41\n","epoch: 1, batch: 333, loss: 1.432, acc: 0.48\n","epoch: 1, batch: 334, loss: 1.423, acc: 0.49\n","epoch: 1, batch: 335, loss: 1.306, acc: 0.55\n","epoch: 1, batch: 336, loss: 1.429, acc: 0.52\n","epoch: 1, batch: 337, loss: 1.273, acc: 0.55\n","epoch: 1, batch: 338, loss: 1.314, acc: 0.55\n","epoch: 1, batch: 339, loss: 1.519, acc: 0.41\n","epoch: 1, batch: 340, loss: 1.371, acc: 0.50\n","epoch: 1, batch: 341, loss: 1.369, acc: 0.53\n","epoch: 1, batch: 342, loss: 1.437, acc: 0.53\n","epoch: 1, batch: 343, loss: 1.475, acc: 0.48\n","epoch: 1, batch: 344, loss: 1.489, acc: 0.50\n","epoch: 1, batch: 345, loss: 1.387, acc: 0.49\n","epoch: 1, batch: 346, loss: 1.472, acc: 0.48\n","epoch: 1, batch: 347, loss: 1.374, acc: 0.57\n","epoch: 1, batch: 348, loss: 1.481, acc: 0.49\n","epoch: 1, batch: 349, loss: 1.509, acc: 0.45\n","epoch: 1, batch: 350, loss: 1.379, acc: 0.52\n","epoch: 1, batch: 351, loss: 1.467, acc: 0.41\n","epoch: 1, batch: 352, loss: 1.470, acc: 0.48\n","epoch: 1, batch: 353, loss: 1.343, acc: 0.52\n","epoch: 1, batch: 354, loss: 1.323, acc: 0.53\n","epoch: 1, batch: 355, loss: 1.321, acc: 0.56\n","epoch: 1, batch: 356, loss: 1.480, acc: 0.45\n","epoch: 1, batch: 357, loss: 1.335, acc: 0.52\n","epoch: 1, batch: 358, loss: 1.469, acc: 0.48\n","epoch: 1, batch: 359, loss: 1.249, acc: 0.53\n","epoch: 1, batch: 360, loss: 1.527, acc: 0.45\n","epoch: 1, batch: 361, loss: 1.463, acc: 0.55\n","epoch: 1, batch: 362, loss: 1.337, acc: 0.46\n","epoch: 1, batch: 363, loss: 1.466, acc: 0.43\n","epoch: 1, batch: 364, loss: 1.347, acc: 0.52\n","epoch: 1, batch: 365, loss: 1.403, acc: 0.52\n","epoch: 1, batch: 366, loss: 1.479, acc: 0.50\n","epoch: 1, batch: 367, loss: 1.324, acc: 0.52\n","epoch: 1, batch: 368, loss: 1.320, acc: 0.52\n","epoch: 1, batch: 369, loss: 1.310, acc: 0.49\n","epoch: 1, batch: 370, loss: 1.423, acc: 0.59\n","epoch: 1, batch: 371, loss: 1.299, acc: 0.53\n","epoch: 1, batch: 372, loss: 1.359, acc: 0.48\n","epoch: 1, batch: 373, loss: 1.408, acc: 0.55\n","epoch: 1, batch: 374, loss: 1.452, acc: 0.48\n","epoch: 1, batch: 375, loss: 1.396, acc: 0.44\n","epoch: 1, batch: 376, loss: 1.328, acc: 0.48\n","epoch: 1, batch: 377, loss: 1.352, acc: 0.53\n","epoch: 1, batch: 378, loss: 1.264, acc: 0.54\n","epoch: 1, batch: 379, loss: 1.393, acc: 0.55\n","epoch: 1, batch: 380, loss: 1.439, acc: 0.50\n","epoch: 1, batch: 381, loss: 1.328, acc: 0.54\n","epoch: 1, batch: 382, loss: 1.508, acc: 0.52\n","epoch: 1, batch: 383, loss: 1.421, acc: 0.48\n","epoch: 1, batch: 384, loss: 1.322, acc: 0.54\n","epoch: 1, batch: 385, loss: 1.414, acc: 0.45\n","epoch: 1, batch: 386, loss: 1.221, acc: 0.56\n","epoch: 1, batch: 387, loss: 1.146, acc: 0.64\n","epoch: 1, batch: 388, loss: 1.390, acc: 0.52\n","epoch: 1, batch: 389, loss: 1.385, acc: 0.52\n","epoch: 1, batch: 390, loss: 1.293, acc: 0.51\n","epoch: 1, batch: 391, loss: 1.496, acc: 0.41\n","epoch: 2, batch: 1, loss: 1.612, acc: 0.45\n","epoch: 2, batch: 2, loss: 1.379, acc: 0.58\n","epoch: 2, batch: 3, loss: 1.432, acc: 0.52\n","epoch: 2, batch: 4, loss: 1.397, acc: 0.48\n","epoch: 2, batch: 5, loss: 1.231, acc: 0.62\n","epoch: 2, batch: 6, loss: 1.473, acc: 0.52\n","epoch: 2, batch: 7, loss: 1.474, acc: 0.45\n","epoch: 2, batch: 8, loss: 1.420, acc: 0.49\n","epoch: 2, batch: 9, loss: 1.362, acc: 0.48\n","epoch: 2, batch: 10, loss: 1.528, acc: 0.48\n","epoch: 2, batch: 11, loss: 1.495, acc: 0.48\n","epoch: 2, batch: 12, loss: 1.309, acc: 0.47\n","epoch: 2, batch: 13, loss: 1.248, acc: 0.56\n","epoch: 2, batch: 14, loss: 1.521, acc: 0.45\n","epoch: 2, batch: 15, loss: 1.360, acc: 0.52\n","epoch: 2, batch: 16, loss: 1.388, acc: 0.51\n","epoch: 2, batch: 17, loss: 1.400, acc: 0.51\n","epoch: 2, batch: 18, loss: 1.475, acc: 0.48\n","epoch: 2, batch: 19, loss: 1.379, acc: 0.49\n","epoch: 2, batch: 20, loss: 1.394, acc: 0.50\n","epoch: 2, batch: 21, loss: 1.430, acc: 0.48\n","epoch: 2, batch: 22, loss: 1.344, acc: 0.52\n","epoch: 2, batch: 23, loss: 1.362, acc: 0.48\n","epoch: 2, batch: 24, loss: 1.538, acc: 0.52\n","epoch: 2, batch: 25, loss: 1.384, acc: 0.47\n","epoch: 2, batch: 26, loss: 1.186, acc: 0.60\n","epoch: 2, batch: 27, loss: 1.420, acc: 0.52\n","epoch: 2, batch: 28, loss: 1.473, acc: 0.48\n","epoch: 2, batch: 29, loss: 1.440, acc: 0.55\n","epoch: 2, batch: 30, loss: 1.457, acc: 0.46\n","epoch: 2, batch: 31, loss: 1.320, acc: 0.55\n","epoch: 2, batch: 32, loss: 1.341, acc: 0.52\n","epoch: 2, batch: 33, loss: 1.393, acc: 0.53\n","epoch: 2, batch: 34, loss: 1.437, acc: 0.51\n","epoch: 2, batch: 35, loss: 1.371, acc: 0.50\n","epoch: 2, batch: 36, loss: 1.424, acc: 0.56\n","epoch: 2, batch: 37, loss: 1.318, acc: 0.53\n","epoch: 2, batch: 38, loss: 1.462, acc: 0.47\n","epoch: 2, batch: 39, loss: 1.276, acc: 0.56\n","epoch: 2, batch: 40, loss: 1.432, acc: 0.52\n","epoch: 2, batch: 41, loss: 1.379, acc: 0.55\n","epoch: 2, batch: 42, loss: 1.460, acc: 0.48\n","epoch: 2, batch: 43, loss: 1.469, acc: 0.52\n","epoch: 2, batch: 44, loss: 1.507, acc: 0.43\n","epoch: 2, batch: 45, loss: 1.309, acc: 0.54\n","epoch: 2, batch: 46, loss: 1.184, acc: 0.59\n","epoch: 2, batch: 47, loss: 1.359, acc: 0.51\n","epoch: 2, batch: 48, loss: 1.336, acc: 0.54\n","epoch: 2, batch: 49, loss: 1.356, acc: 0.55\n","epoch: 2, batch: 50, loss: 1.396, acc: 0.48\n","epoch: 2, batch: 51, loss: 1.286, acc: 0.55\n","epoch: 2, batch: 52, loss: 1.404, acc: 0.53\n","epoch: 2, batch: 53, loss: 1.374, acc: 0.50\n","epoch: 2, batch: 54, loss: 1.314, acc: 0.53\n","epoch: 2, batch: 55, loss: 1.431, acc: 0.43\n","epoch: 2, batch: 56, loss: 1.503, acc: 0.44\n","epoch: 2, batch: 57, loss: 1.434, acc: 0.49\n","epoch: 2, batch: 58, loss: 1.488, acc: 0.47\n","epoch: 2, batch: 59, loss: 1.351, acc: 0.53\n","epoch: 2, batch: 60, loss: 1.416, acc: 0.49\n","epoch: 2, batch: 61, loss: 1.356, acc: 0.53\n","epoch: 2, batch: 62, loss: 1.531, acc: 0.47\n","epoch: 2, batch: 63, loss: 1.330, acc: 0.55\n","epoch: 2, batch: 64, loss: 1.443, acc: 0.52\n","epoch: 2, batch: 65, loss: 1.384, acc: 0.52\n","epoch: 2, batch: 66, loss: 1.261, acc: 0.51\n","epoch: 2, batch: 67, loss: 1.377, acc: 0.52\n","epoch: 2, batch: 68, loss: 1.334, acc: 0.58\n","epoch: 2, batch: 69, loss: 1.541, acc: 0.48\n","epoch: 2, batch: 70, loss: 1.411, acc: 0.54\n","epoch: 2, batch: 71, loss: 1.373, acc: 0.52\n","epoch: 2, batch: 72, loss: 1.254, acc: 0.55\n","epoch: 2, batch: 73, loss: 1.411, acc: 0.50\n","epoch: 2, batch: 74, loss: 1.469, acc: 0.48\n","epoch: 2, batch: 75, loss: 1.256, acc: 0.59\n","epoch: 2, batch: 76, loss: 1.300, acc: 0.51\n","epoch: 2, batch: 77, loss: 1.415, acc: 0.58\n","epoch: 2, batch: 78, loss: 1.324, acc: 0.58\n","epoch: 2, batch: 79, loss: 1.434, acc: 0.55\n","epoch: 2, batch: 80, loss: 1.323, acc: 0.53\n","epoch: 2, batch: 81, loss: 1.366, acc: 0.52\n","epoch: 2, batch: 82, loss: 1.335, acc: 0.54\n","epoch: 2, batch: 83, loss: 1.358, acc: 0.51\n","epoch: 2, batch: 84, loss: 1.388, acc: 0.59\n","epoch: 2, batch: 85, loss: 1.302, acc: 0.56\n","epoch: 2, batch: 86, loss: 1.401, acc: 0.44\n","epoch: 2, batch: 87, loss: 1.342, acc: 0.48\n","epoch: 2, batch: 88, loss: 1.189, acc: 0.54\n","epoch: 2, batch: 89, loss: 1.404, acc: 0.53\n","epoch: 2, batch: 90, loss: 1.109, acc: 0.61\n","epoch: 2, batch: 91, loss: 1.438, acc: 0.48\n","epoch: 2, batch: 92, loss: 1.390, acc: 0.45\n","epoch: 2, batch: 93, loss: 1.439, acc: 0.49\n","epoch: 2, batch: 94, loss: 1.231, acc: 0.55\n","epoch: 2, batch: 95, loss: 1.354, acc: 0.54\n","epoch: 2, batch: 96, loss: 1.296, acc: 0.60\n","epoch: 2, batch: 97, loss: 1.363, acc: 0.55\n","epoch: 2, batch: 98, loss: 1.283, acc: 0.58\n","epoch: 2, batch: 99, loss: 1.199, acc: 0.59\n","epoch: 2, batch: 100, loss: 1.506, acc: 0.49\n","epoch: 2, batch: 101, loss: 1.196, acc: 0.59\n","epoch: 2, batch: 102, loss: 1.326, acc: 0.49\n","epoch: 2, batch: 103, loss: 1.430, acc: 0.52\n","epoch: 2, batch: 104, loss: 1.260, acc: 0.56\n","epoch: 2, batch: 105, loss: 1.463, acc: 0.48\n","epoch: 2, batch: 106, loss: 1.305, acc: 0.56\n","epoch: 2, batch: 107, loss: 1.314, acc: 0.52\n","epoch: 2, batch: 108, loss: 1.644, acc: 0.45\n","epoch: 2, batch: 109, loss: 1.298, acc: 0.53\n","epoch: 2, batch: 110, loss: 1.312, acc: 0.52\n","epoch: 2, batch: 111, loss: 1.263, acc: 0.55\n","epoch: 2, batch: 112, loss: 1.391, acc: 0.55\n","epoch: 2, batch: 113, loss: 1.025, acc: 0.68\n","epoch: 2, batch: 114, loss: 1.396, acc: 0.48\n","epoch: 2, batch: 115, loss: 1.314, acc: 0.50\n","epoch: 2, batch: 116, loss: 1.251, acc: 0.55\n","epoch: 2, batch: 117, loss: 1.352, acc: 0.55\n","epoch: 2, batch: 118, loss: 1.380, acc: 0.54\n","epoch: 2, batch: 119, loss: 1.278, acc: 0.57\n","epoch: 2, batch: 120, loss: 1.476, acc: 0.57\n","epoch: 2, batch: 121, loss: 1.245, acc: 0.56\n","epoch: 2, batch: 122, loss: 1.370, acc: 0.57\n","epoch: 2, batch: 123, loss: 1.283, acc: 0.56\n","epoch: 2, batch: 124, loss: 1.207, acc: 0.58\n","epoch: 2, batch: 125, loss: 1.319, acc: 0.52\n","epoch: 2, batch: 126, loss: 1.326, acc: 0.52\n","epoch: 2, batch: 127, loss: 1.242, acc: 0.50\n","epoch: 2, batch: 128, loss: 1.246, acc: 0.53\n","epoch: 2, batch: 129, loss: 1.358, acc: 0.59\n","epoch: 2, batch: 130, loss: 1.410, acc: 0.52\n","epoch: 2, batch: 131, loss: 1.397, acc: 0.52\n","epoch: 2, batch: 132, loss: 1.330, acc: 0.55\n","epoch: 2, batch: 133, loss: 1.217, acc: 0.55\n","epoch: 2, batch: 134, loss: 1.274, acc: 0.52\n","epoch: 2, batch: 135, loss: 1.192, acc: 0.57\n","epoch: 2, batch: 136, loss: 1.227, acc: 0.59\n","epoch: 2, batch: 137, loss: 1.246, acc: 0.59\n","epoch: 2, batch: 138, loss: 1.370, acc: 0.55\n","epoch: 2, batch: 139, loss: 1.211, acc: 0.55\n","epoch: 2, batch: 140, loss: 1.296, acc: 0.59\n","epoch: 2, batch: 141, loss: 1.271, acc: 0.52\n","epoch: 2, batch: 142, loss: 1.225, acc: 0.55\n","epoch: 2, batch: 143, loss: 1.284, acc: 0.51\n","epoch: 2, batch: 144, loss: 1.284, acc: 0.51\n","epoch: 2, batch: 145, loss: 1.320, acc: 0.52\n","epoch: 2, batch: 146, loss: 1.450, acc: 0.54\n","epoch: 2, batch: 147, loss: 1.354, acc: 0.52\n","epoch: 2, batch: 148, loss: 1.319, acc: 0.54\n","epoch: 2, batch: 149, loss: 1.235, acc: 0.54\n","epoch: 2, batch: 150, loss: 1.296, acc: 0.57\n","epoch: 2, batch: 151, loss: 1.415, acc: 0.50\n","epoch: 2, batch: 152, loss: 1.437, acc: 0.44\n","epoch: 2, batch: 153, loss: 1.316, acc: 0.48\n","epoch: 2, batch: 154, loss: 1.237, acc: 0.52\n","epoch: 2, batch: 155, loss: 1.412, acc: 0.45\n","epoch: 2, batch: 156, loss: 1.533, acc: 0.40\n","epoch: 2, batch: 157, loss: 1.320, acc: 0.55\n","epoch: 2, batch: 158, loss: 1.359, acc: 0.52\n","epoch: 2, batch: 159, loss: 1.349, acc: 0.45\n","epoch: 2, batch: 160, loss: 1.277, acc: 0.56\n","epoch: 2, batch: 161, loss: 1.425, acc: 0.45\n","epoch: 2, batch: 162, loss: 1.316, acc: 0.52\n","epoch: 2, batch: 163, loss: 1.566, acc: 0.43\n","epoch: 2, batch: 164, loss: 1.446, acc: 0.47\n","epoch: 2, batch: 165, loss: 1.204, acc: 0.59\n","epoch: 2, batch: 166, loss: 1.384, acc: 0.46\n","epoch: 2, batch: 167, loss: 1.304, acc: 0.56\n","epoch: 2, batch: 168, loss: 1.351, acc: 0.52\n","epoch: 2, batch: 169, loss: 1.157, acc: 0.59\n","epoch: 2, batch: 170, loss: 1.344, acc: 0.55\n","epoch: 2, batch: 171, loss: 1.260, acc: 0.54\n","epoch: 2, batch: 172, loss: 1.243, acc: 0.54\n","epoch: 2, batch: 173, loss: 1.398, acc: 0.52\n","epoch: 2, batch: 174, loss: 1.231, acc: 0.55\n","epoch: 2, batch: 175, loss: 1.259, acc: 0.52\n","epoch: 2, batch: 176, loss: 1.281, acc: 0.56\n","epoch: 2, batch: 177, loss: 1.227, acc: 0.54\n","epoch: 2, batch: 178, loss: 1.156, acc: 0.57\n","epoch: 2, batch: 179, loss: 1.362, acc: 0.52\n","epoch: 2, batch: 180, loss: 1.283, acc: 0.57\n","epoch: 2, batch: 181, loss: 1.374, acc: 0.51\n","epoch: 2, batch: 182, loss: 1.268, acc: 0.54\n","epoch: 2, batch: 183, loss: 1.175, acc: 0.59\n","epoch: 2, batch: 184, loss: 1.291, acc: 0.52\n","epoch: 2, batch: 185, loss: 1.318, acc: 0.59\n","epoch: 2, batch: 186, loss: 1.386, acc: 0.51\n","epoch: 2, batch: 187, loss: 1.275, acc: 0.58\n","epoch: 2, batch: 188, loss: 1.265, acc: 0.55\n","epoch: 2, batch: 189, loss: 1.245, acc: 0.59\n","epoch: 2, batch: 190, loss: 1.469, acc: 0.48\n","epoch: 2, batch: 191, loss: 1.217, acc: 0.57\n","epoch: 2, batch: 192, loss: 1.269, acc: 0.55\n","epoch: 2, batch: 193, loss: 1.218, acc: 0.58\n","epoch: 2, batch: 194, loss: 1.290, acc: 0.56\n","epoch: 2, batch: 195, loss: 1.329, acc: 0.53\n","epoch: 2, batch: 196, loss: 1.415, acc: 0.48\n","epoch: 2, batch: 197, loss: 1.141, acc: 0.58\n","epoch: 2, batch: 198, loss: 1.332, acc: 0.48\n","epoch: 2, batch: 199, loss: 1.568, acc: 0.50\n","epoch: 2, batch: 200, loss: 1.233, acc: 0.57\n","epoch: 2, batch: 201, loss: 1.426, acc: 0.51\n","epoch: 2, batch: 202, loss: 1.367, acc: 0.55\n","epoch: 2, batch: 203, loss: 1.259, acc: 0.59\n","epoch: 2, batch: 204, loss: 1.284, acc: 0.52\n","epoch: 2, batch: 205, loss: 1.264, acc: 0.52\n","epoch: 2, batch: 206, loss: 1.120, acc: 0.62\n","epoch: 2, batch: 207, loss: 1.166, acc: 0.59\n","epoch: 2, batch: 208, loss: 1.303, acc: 0.54\n","epoch: 2, batch: 209, loss: 1.249, acc: 0.59\n","epoch: 2, batch: 210, loss: 1.283, acc: 0.51\n","epoch: 2, batch: 211, loss: 1.502, acc: 0.41\n","epoch: 2, batch: 212, loss: 1.488, acc: 0.45\n","epoch: 2, batch: 213, loss: 1.336, acc: 0.57\n","epoch: 2, batch: 214, loss: 1.368, acc: 0.51\n","epoch: 2, batch: 215, loss: 1.291, acc: 0.58\n","epoch: 2, batch: 216, loss: 1.161, acc: 0.59\n","epoch: 2, batch: 217, loss: 1.314, acc: 0.56\n","epoch: 2, batch: 218, loss: 1.426, acc: 0.54\n","epoch: 2, batch: 219, loss: 1.251, acc: 0.55\n","epoch: 2, batch: 220, loss: 1.368, acc: 0.53\n","epoch: 2, batch: 221, loss: 1.180, acc: 0.57\n","epoch: 2, batch: 222, loss: 1.288, acc: 0.52\n","epoch: 2, batch: 223, loss: 1.250, acc: 0.52\n","epoch: 2, batch: 224, loss: 1.336, acc: 0.56\n","epoch: 2, batch: 225, loss: 1.295, acc: 0.53\n","epoch: 2, batch: 226, loss: 1.351, acc: 0.53\n","epoch: 2, batch: 227, loss: 1.162, acc: 0.59\n","epoch: 2, batch: 228, loss: 1.221, acc: 0.54\n","epoch: 2, batch: 229, loss: 1.261, acc: 0.51\n","epoch: 2, batch: 230, loss: 1.240, acc: 0.55\n","epoch: 2, batch: 231, loss: 1.333, acc: 0.55\n","epoch: 2, batch: 232, loss: 1.221, acc: 0.58\n","epoch: 2, batch: 233, loss: 1.314, acc: 0.56\n","epoch: 2, batch: 234, loss: 1.242, acc: 0.57\n","epoch: 2, batch: 235, loss: 1.365, acc: 0.56\n","epoch: 2, batch: 236, loss: 1.240, acc: 0.59\n","epoch: 2, batch: 237, loss: 1.154, acc: 0.57\n","epoch: 2, batch: 238, loss: 1.061, acc: 0.62\n","epoch: 2, batch: 239, loss: 1.024, acc: 0.62\n","epoch: 2, batch: 240, loss: 1.355, acc: 0.53\n","epoch: 2, batch: 241, loss: 1.250, acc: 0.59\n","epoch: 2, batch: 242, loss: 1.255, acc: 0.49\n","epoch: 2, batch: 243, loss: 1.256, acc: 0.61\n","epoch: 2, batch: 244, loss: 1.227, acc: 0.55\n","epoch: 2, batch: 245, loss: 1.361, acc: 0.47\n","epoch: 2, batch: 246, loss: 1.203, acc: 0.59\n","epoch: 2, batch: 247, loss: 1.287, acc: 0.54\n","epoch: 2, batch: 248, loss: 1.133, acc: 0.62\n","epoch: 2, batch: 249, loss: 1.305, acc: 0.52\n","epoch: 2, batch: 250, loss: 1.177, acc: 0.53\n","epoch: 2, batch: 251, loss: 1.403, acc: 0.51\n","epoch: 2, batch: 252, loss: 1.351, acc: 0.52\n","epoch: 2, batch: 253, loss: 1.224, acc: 0.54\n","epoch: 2, batch: 254, loss: 1.247, acc: 0.53\n","epoch: 2, batch: 255, loss: 1.251, acc: 0.60\n","epoch: 2, batch: 256, loss: 1.302, acc: 0.54\n","epoch: 2, batch: 257, loss: 1.124, acc: 0.62\n","epoch: 2, batch: 258, loss: 1.204, acc: 0.55\n","epoch: 2, batch: 259, loss: 1.220, acc: 0.55\n","epoch: 2, batch: 260, loss: 1.149, acc: 0.64\n","epoch: 2, batch: 261, loss: 1.280, acc: 0.51\n","epoch: 2, batch: 262, loss: 1.358, acc: 0.55\n","epoch: 2, batch: 263, loss: 1.284, acc: 0.54\n","epoch: 2, batch: 264, loss: 1.269, acc: 0.54\n","epoch: 2, batch: 265, loss: 1.243, acc: 0.58\n","epoch: 2, batch: 266, loss: 1.243, acc: 0.55\n","epoch: 2, batch: 267, loss: 1.135, acc: 0.58\n","epoch: 2, batch: 268, loss: 1.261, acc: 0.54\n","epoch: 2, batch: 269, loss: 1.316, acc: 0.57\n","epoch: 2, batch: 270, loss: 1.157, acc: 0.61\n","epoch: 2, batch: 271, loss: 1.409, acc: 0.55\n","epoch: 2, batch: 272, loss: 1.420, acc: 0.50\n","epoch: 2, batch: 273, loss: 1.265, acc: 0.54\n","epoch: 2, batch: 274, loss: 1.130, acc: 0.63\n","epoch: 2, batch: 275, loss: 1.129, acc: 0.55\n","epoch: 2, batch: 276, loss: 1.271, acc: 0.59\n","epoch: 2, batch: 277, loss: 1.164, acc: 0.65\n","epoch: 2, batch: 278, loss: 1.170, acc: 0.58\n","epoch: 2, batch: 279, loss: 1.330, acc: 0.54\n","epoch: 2, batch: 280, loss: 1.284, acc: 0.54\n","epoch: 2, batch: 281, loss: 1.234, acc: 0.57\n","epoch: 2, batch: 282, loss: 1.289, acc: 0.57\n","epoch: 2, batch: 283, loss: 1.441, acc: 0.50\n","epoch: 2, batch: 284, loss: 1.164, acc: 0.57\n","epoch: 2, batch: 285, loss: 1.210, acc: 0.54\n","epoch: 2, batch: 286, loss: 1.282, acc: 0.54\n","epoch: 2, batch: 287, loss: 1.359, acc: 0.50\n","epoch: 2, batch: 288, loss: 1.374, acc: 0.45\n","epoch: 2, batch: 289, loss: 1.190, acc: 0.57\n","epoch: 2, batch: 290, loss: 1.199, acc: 0.61\n","epoch: 2, batch: 291, loss: 1.145, acc: 0.59\n","epoch: 2, batch: 292, loss: 1.218, acc: 0.52\n","epoch: 2, batch: 293, loss: 1.177, acc: 0.62\n","epoch: 2, batch: 294, loss: 1.375, acc: 0.53\n","epoch: 2, batch: 295, loss: 1.367, acc: 0.47\n","epoch: 2, batch: 296, loss: 1.254, acc: 0.52\n","epoch: 2, batch: 297, loss: 1.291, acc: 0.53\n","epoch: 2, batch: 298, loss: 1.245, acc: 0.55\n","epoch: 2, batch: 299, loss: 1.193, acc: 0.55\n","epoch: 2, batch: 300, loss: 1.433, acc: 0.50\n","epoch: 2, batch: 301, loss: 1.253, acc: 0.59\n","epoch: 2, batch: 302, loss: 1.360, acc: 0.52\n","epoch: 2, batch: 303, loss: 1.270, acc: 0.56\n","epoch: 2, batch: 304, loss: 1.248, acc: 0.54\n","epoch: 2, batch: 305, loss: 1.157, acc: 0.59\n","epoch: 2, batch: 306, loss: 1.203, acc: 0.58\n","epoch: 2, batch: 307, loss: 1.301, acc: 0.55\n","epoch: 2, batch: 308, loss: 1.253, acc: 0.53\n","epoch: 2, batch: 309, loss: 1.168, acc: 0.61\n","epoch: 2, batch: 310, loss: 1.244, acc: 0.58\n","epoch: 2, batch: 311, loss: 1.334, acc: 0.47\n","epoch: 2, batch: 312, loss: 1.191, acc: 0.60\n","epoch: 2, batch: 313, loss: 1.197, acc: 0.59\n","epoch: 2, batch: 314, loss: 1.247, acc: 0.58\n","epoch: 2, batch: 315, loss: 1.277, acc: 0.52\n","epoch: 2, batch: 316, loss: 1.195, acc: 0.59\n","epoch: 2, batch: 317, loss: 1.279, acc: 0.59\n","epoch: 2, batch: 318, loss: 1.250, acc: 0.55\n","epoch: 2, batch: 319, loss: 1.177, acc: 0.60\n","epoch: 2, batch: 320, loss: 1.173, acc: 0.61\n","epoch: 2, batch: 321, loss: 1.191, acc: 0.56\n","epoch: 2, batch: 322, loss: 1.332, acc: 0.55\n","epoch: 2, batch: 323, loss: 1.353, acc: 0.49\n","epoch: 2, batch: 324, loss: 1.298, acc: 0.54\n","epoch: 2, batch: 325, loss: 1.224, acc: 0.56\n","epoch: 2, batch: 326, loss: 1.173, acc: 0.60\n","epoch: 2, batch: 327, loss: 1.189, acc: 0.57\n","epoch: 2, batch: 328, loss: 1.295, acc: 0.56\n","epoch: 2, batch: 329, loss: 1.421, acc: 0.56\n","epoch: 2, batch: 330, loss: 1.216, acc: 0.55\n","epoch: 2, batch: 331, loss: 1.274, acc: 0.59\n","epoch: 2, batch: 332, loss: 1.207, acc: 0.48\n","epoch: 2, batch: 333, loss: 1.300, acc: 0.52\n","epoch: 2, batch: 334, loss: 1.182, acc: 0.56\n","epoch: 2, batch: 335, loss: 1.254, acc: 0.60\n","epoch: 2, batch: 336, loss: 1.263, acc: 0.57\n","epoch: 2, batch: 337, loss: 1.334, acc: 0.51\n","epoch: 2, batch: 338, loss: 1.367, acc: 0.49\n","epoch: 2, batch: 339, loss: 1.319, acc: 0.52\n","epoch: 2, batch: 340, loss: 1.336, acc: 0.53\n","epoch: 2, batch: 341, loss: 1.199, acc: 0.59\n","epoch: 2, batch: 342, loss: 1.185, acc: 0.58\n","epoch: 2, batch: 343, loss: 1.319, acc: 0.59\n","epoch: 2, batch: 344, loss: 1.257, acc: 0.58\n","epoch: 2, batch: 345, loss: 1.246, acc: 0.52\n","epoch: 2, batch: 346, loss: 1.323, acc: 0.56\n","epoch: 2, batch: 347, loss: 1.305, acc: 0.47\n","epoch: 2, batch: 348, loss: 1.313, acc: 0.52\n","epoch: 2, batch: 349, loss: 1.204, acc: 0.57\n","epoch: 2, batch: 350, loss: 1.192, acc: 0.59\n","epoch: 2, batch: 351, loss: 1.205, acc: 0.55\n","epoch: 2, batch: 352, loss: 1.336, acc: 0.51\n","epoch: 2, batch: 353, loss: 1.305, acc: 0.48\n","epoch: 2, batch: 354, loss: 1.207, acc: 0.55\n","epoch: 2, batch: 355, loss: 1.408, acc: 0.47\n","epoch: 2, batch: 356, loss: 1.242, acc: 0.59\n","epoch: 2, batch: 357, loss: 1.128, acc: 0.60\n","epoch: 2, batch: 358, loss: 1.268, acc: 0.55\n","epoch: 2, batch: 359, loss: 1.218, acc: 0.59\n","epoch: 2, batch: 360, loss: 1.283, acc: 0.54\n","epoch: 2, batch: 361, loss: 1.297, acc: 0.49\n","epoch: 2, batch: 362, loss: 1.206, acc: 0.60\n","epoch: 2, batch: 363, loss: 1.268, acc: 0.59\n","epoch: 2, batch: 364, loss: 1.191, acc: 0.54\n","epoch: 2, batch: 365, loss: 1.350, acc: 0.52\n","epoch: 2, batch: 366, loss: 1.120, acc: 0.59\n","epoch: 2, batch: 367, loss: 1.191, acc: 0.55\n","epoch: 2, batch: 368, loss: 1.130, acc: 0.62\n","epoch: 2, batch: 369, loss: 1.481, acc: 0.52\n","epoch: 2, batch: 370, loss: 1.313, acc: 0.54\n","epoch: 2, batch: 371, loss: 1.128, acc: 0.65\n","epoch: 2, batch: 372, loss: 1.210, acc: 0.57\n","epoch: 2, batch: 373, loss: 1.363, acc: 0.58\n","epoch: 2, batch: 374, loss: 1.182, acc: 0.55\n","epoch: 2, batch: 375, loss: 1.304, acc: 0.51\n","epoch: 2, batch: 376, loss: 1.121, acc: 0.60\n","epoch: 2, batch: 377, loss: 1.423, acc: 0.48\n","epoch: 2, batch: 378, loss: 1.189, acc: 0.56\n","epoch: 2, batch: 379, loss: 1.142, acc: 0.58\n","epoch: 2, batch: 380, loss: 0.928, acc: 0.71\n","epoch: 2, batch: 381, loss: 1.250, acc: 0.59\n","epoch: 2, batch: 382, loss: 1.202, acc: 0.53\n","epoch: 2, batch: 383, loss: 1.266, acc: 0.50\n","epoch: 2, batch: 384, loss: 1.310, acc: 0.57\n","epoch: 2, batch: 385, loss: 1.258, acc: 0.57\n","epoch: 2, batch: 386, loss: 1.330, acc: 0.55\n","epoch: 2, batch: 387, loss: 1.270, acc: 0.55\n","epoch: 2, batch: 388, loss: 1.122, acc: 0.61\n","epoch: 2, batch: 389, loss: 1.039, acc: 0.59\n","epoch: 2, batch: 390, loss: 1.340, acc: 0.55\n","epoch: 2, batch: 391, loss: 1.232, acc: 0.59\n","epoch: 3, batch: 1, loss: 1.325, acc: 0.52\n","epoch: 3, batch: 2, loss: 1.254, acc: 0.56\n","epoch: 3, batch: 3, loss: 1.075, acc: 0.65\n","epoch: 3, batch: 4, loss: 1.193, acc: 0.53\n","epoch: 3, batch: 5, loss: 1.320, acc: 0.56\n","epoch: 3, batch: 6, loss: 1.286, acc: 0.52\n","epoch: 3, batch: 7, loss: 1.231, acc: 0.55\n","epoch: 3, batch: 8, loss: 1.365, acc: 0.57\n","epoch: 3, batch: 9, loss: 1.211, acc: 0.57\n","epoch: 3, batch: 10, loss: 1.170, acc: 0.55\n","epoch: 3, batch: 11, loss: 1.217, acc: 0.60\n","epoch: 3, batch: 12, loss: 1.334, acc: 0.55\n","epoch: 3, batch: 13, loss: 1.314, acc: 0.55\n","epoch: 3, batch: 14, loss: 1.217, acc: 0.54\n","epoch: 3, batch: 15, loss: 1.188, acc: 0.55\n","epoch: 3, batch: 16, loss: 1.237, acc: 0.52\n","epoch: 3, batch: 17, loss: 1.222, acc: 0.60\n","epoch: 3, batch: 18, loss: 1.198, acc: 0.59\n","epoch: 3, batch: 19, loss: 1.142, acc: 0.64\n","epoch: 3, batch: 20, loss: 1.210, acc: 0.59\n","epoch: 3, batch: 21, loss: 1.366, acc: 0.59\n","epoch: 3, batch: 22, loss: 1.321, acc: 0.56\n","epoch: 3, batch: 23, loss: 1.054, acc: 0.67\n","epoch: 3, batch: 24, loss: 1.295, acc: 0.50\n","epoch: 3, batch: 25, loss: 1.160, acc: 0.62\n","epoch: 3, batch: 26, loss: 1.210, acc: 0.60\n","epoch: 3, batch: 27, loss: 1.386, acc: 0.48\n","epoch: 3, batch: 28, loss: 1.280, acc: 0.61\n","epoch: 3, batch: 29, loss: 1.036, acc: 0.64\n","epoch: 3, batch: 30, loss: 1.205, acc: 0.56\n","epoch: 3, batch: 31, loss: 1.201, acc: 0.60\n","epoch: 3, batch: 32, loss: 1.305, acc: 0.59\n","epoch: 3, batch: 33, loss: 1.271, acc: 0.53\n","epoch: 3, batch: 34, loss: 1.186, acc: 0.59\n","epoch: 3, batch: 35, loss: 1.260, acc: 0.59\n","epoch: 3, batch: 36, loss: 1.382, acc: 0.52\n","epoch: 3, batch: 37, loss: 1.193, acc: 0.58\n","epoch: 3, batch: 38, loss: 1.415, acc: 0.48\n","epoch: 3, batch: 39, loss: 1.235, acc: 0.55\n","epoch: 3, batch: 40, loss: 1.210, acc: 0.53\n","epoch: 3, batch: 41, loss: 1.276, acc: 0.58\n","epoch: 3, batch: 42, loss: 1.413, acc: 0.54\n","epoch: 3, batch: 43, loss: 1.260, acc: 0.54\n","epoch: 3, batch: 44, loss: 1.156, acc: 0.58\n","epoch: 3, batch: 45, loss: 1.167, acc: 0.59\n","epoch: 3, batch: 46, loss: 1.209, acc: 0.61\n","epoch: 3, batch: 47, loss: 1.288, acc: 0.58\n","epoch: 3, batch: 48, loss: 1.160, acc: 0.60\n","epoch: 3, batch: 49, loss: 1.244, acc: 0.53\n","epoch: 3, batch: 50, loss: 1.110, acc: 0.63\n","epoch: 3, batch: 51, loss: 1.240, acc: 0.53\n","epoch: 3, batch: 52, loss: 1.266, acc: 0.51\n","epoch: 3, batch: 53, loss: 1.079, acc: 0.64\n","epoch: 3, batch: 54, loss: 1.321, acc: 0.55\n","epoch: 3, batch: 55, loss: 1.347, acc: 0.55\n","epoch: 3, batch: 56, loss: 1.266, acc: 0.58\n","epoch: 3, batch: 57, loss: 1.206, acc: 0.60\n","epoch: 3, batch: 58, loss: 1.222, acc: 0.61\n","epoch: 3, batch: 59, loss: 1.189, acc: 0.62\n","epoch: 3, batch: 60, loss: 1.158, acc: 0.57\n","epoch: 3, batch: 61, loss: 1.284, acc: 0.58\n","epoch: 3, batch: 62, loss: 1.159, acc: 0.59\n","epoch: 3, batch: 63, loss: 1.389, acc: 0.43\n","epoch: 3, batch: 64, loss: 1.046, acc: 0.66\n","epoch: 3, batch: 65, loss: 1.218, acc: 0.60\n","epoch: 3, batch: 66, loss: 1.148, acc: 0.62\n","epoch: 3, batch: 67, loss: 1.402, acc: 0.54\n","epoch: 3, batch: 68, loss: 1.291, acc: 0.55\n","epoch: 3, batch: 69, loss: 1.147, acc: 0.63\n","epoch: 3, batch: 70, loss: 1.315, acc: 0.59\n","epoch: 3, batch: 71, loss: 1.155, acc: 0.65\n","epoch: 3, batch: 72, loss: 1.235, acc: 0.59\n","epoch: 3, batch: 73, loss: 1.270, acc: 0.56\n","epoch: 3, batch: 74, loss: 1.160, acc: 0.61\n","epoch: 3, batch: 75, loss: 1.301, acc: 0.55\n","epoch: 3, batch: 76, loss: 1.232, acc: 0.52\n","epoch: 3, batch: 77, loss: 1.243, acc: 0.61\n","epoch: 3, batch: 78, loss: 1.253, acc: 0.60\n","epoch: 3, batch: 79, loss: 1.161, acc: 0.58\n","epoch: 3, batch: 80, loss: 1.264, acc: 0.61\n","epoch: 3, batch: 81, loss: 1.151, acc: 0.64\n","epoch: 3, batch: 82, loss: 1.348, acc: 0.57\n","epoch: 3, batch: 83, loss: 1.221, acc: 0.54\n","epoch: 3, batch: 84, loss: 1.166, acc: 0.59\n","epoch: 3, batch: 85, loss: 1.188, acc: 0.55\n","epoch: 3, batch: 86, loss: 1.164, acc: 0.57\n","epoch: 3, batch: 87, loss: 1.229, acc: 0.55\n","epoch: 3, batch: 88, loss: 1.203, acc: 0.62\n","epoch: 3, batch: 89, loss: 1.082, acc: 0.62\n","epoch: 3, batch: 90, loss: 1.174, acc: 0.49\n","epoch: 3, batch: 91, loss: 0.938, acc: 0.69\n","epoch: 3, batch: 92, loss: 1.156, acc: 0.60\n","epoch: 3, batch: 93, loss: 1.295, acc: 0.56\n","epoch: 3, batch: 94, loss: 1.137, acc: 0.59\n","epoch: 3, batch: 95, loss: 1.191, acc: 0.60\n","epoch: 3, batch: 96, loss: 1.309, acc: 0.55\n","epoch: 3, batch: 97, loss: 1.193, acc: 0.55\n","epoch: 3, batch: 98, loss: 1.301, acc: 0.54\n","epoch: 3, batch: 99, loss: 1.199, acc: 0.61\n","epoch: 3, batch: 100, loss: 1.188, acc: 0.62\n","epoch: 3, batch: 101, loss: 1.214, acc: 0.58\n","epoch: 3, batch: 102, loss: 1.232, acc: 0.59\n","epoch: 3, batch: 103, loss: 1.186, acc: 0.60\n","epoch: 3, batch: 104, loss: 1.242, acc: 0.57\n","epoch: 3, batch: 105, loss: 1.273, acc: 0.59\n","epoch: 3, batch: 106, loss: 1.291, acc: 0.59\n","epoch: 3, batch: 107, loss: 1.104, acc: 0.61\n","epoch: 3, batch: 108, loss: 1.186, acc: 0.60\n","epoch: 3, batch: 109, loss: 1.255, acc: 0.58\n","epoch: 3, batch: 110, loss: 1.154, acc: 0.55\n","epoch: 3, batch: 111, loss: 1.252, acc: 0.59\n","epoch: 3, batch: 112, loss: 1.283, acc: 0.55\n","epoch: 3, batch: 113, loss: 1.331, acc: 0.49\n","epoch: 3, batch: 114, loss: 1.057, acc: 0.66\n","epoch: 3, batch: 115, loss: 1.068, acc: 0.59\n","epoch: 3, batch: 116, loss: 1.216, acc: 0.58\n","epoch: 3, batch: 117, loss: 1.349, acc: 0.54\n","epoch: 3, batch: 118, loss: 1.173, acc: 0.66\n","epoch: 3, batch: 119, loss: 1.125, acc: 0.61\n","epoch: 3, batch: 120, loss: 1.304, acc: 0.52\n","epoch: 3, batch: 121, loss: 1.195, acc: 0.53\n","epoch: 3, batch: 122, loss: 1.118, acc: 0.64\n","epoch: 3, batch: 123, loss: 1.174, acc: 0.60\n","epoch: 3, batch: 124, loss: 1.223, acc: 0.53\n","epoch: 3, batch: 125, loss: 1.223, acc: 0.62\n","epoch: 3, batch: 126, loss: 1.190, acc: 0.57\n","epoch: 3, batch: 127, loss: 1.283, acc: 0.52\n","epoch: 3, batch: 128, loss: 1.176, acc: 0.65\n","epoch: 3, batch: 129, loss: 0.940, acc: 0.66\n","epoch: 3, batch: 130, loss: 1.220, acc: 0.55\n","epoch: 3, batch: 131, loss: 1.120, acc: 0.59\n","epoch: 3, batch: 132, loss: 1.343, acc: 0.55\n","epoch: 3, batch: 133, loss: 1.169, acc: 0.59\n","epoch: 3, batch: 134, loss: 1.094, acc: 0.64\n","epoch: 3, batch: 135, loss: 1.302, acc: 0.55\n","epoch: 3, batch: 136, loss: 1.237, acc: 0.59\n","epoch: 3, batch: 137, loss: 1.136, acc: 0.59\n","epoch: 3, batch: 138, loss: 1.190, acc: 0.51\n","epoch: 3, batch: 139, loss: 1.109, acc: 0.65\n","epoch: 3, batch: 140, loss: 1.056, acc: 0.61\n","epoch: 3, batch: 141, loss: 1.238, acc: 0.59\n","epoch: 3, batch: 142, loss: 1.159, acc: 0.57\n","epoch: 3, batch: 143, loss: 1.145, acc: 0.61\n","epoch: 3, batch: 144, loss: 1.100, acc: 0.57\n","epoch: 3, batch: 145, loss: 1.324, acc: 0.47\n","epoch: 3, batch: 146, loss: 1.306, acc: 0.54\n","epoch: 3, batch: 147, loss: 1.198, acc: 0.52\n","epoch: 3, batch: 148, loss: 1.267, acc: 0.53\n","epoch: 3, batch: 149, loss: 1.149, acc: 0.57\n","epoch: 3, batch: 150, loss: 1.411, acc: 0.52\n","epoch: 3, batch: 151, loss: 1.057, acc: 0.63\n","epoch: 3, batch: 152, loss: 1.041, acc: 0.61\n","epoch: 3, batch: 153, loss: 1.351, acc: 0.50\n","epoch: 3, batch: 154, loss: 1.220, acc: 0.57\n","epoch: 3, batch: 155, loss: 1.176, acc: 0.61\n","epoch: 3, batch: 156, loss: 1.416, acc: 0.53\n","epoch: 3, batch: 157, loss: 1.272, acc: 0.58\n","epoch: 3, batch: 158, loss: 1.189, acc: 0.59\n","epoch: 3, batch: 159, loss: 1.188, acc: 0.59\n","epoch: 3, batch: 160, loss: 1.115, acc: 0.59\n","epoch: 3, batch: 161, loss: 1.160, acc: 0.52\n","epoch: 3, batch: 162, loss: 1.088, acc: 0.62\n","epoch: 3, batch: 163, loss: 1.232, acc: 0.56\n","epoch: 3, batch: 164, loss: 1.292, acc: 0.58\n","epoch: 3, batch: 165, loss: 1.090, acc: 0.66\n","epoch: 3, batch: 166, loss: 1.303, acc: 0.55\n","epoch: 3, batch: 167, loss: 1.228, acc: 0.58\n","epoch: 3, batch: 168, loss: 1.165, acc: 0.57\n","epoch: 3, batch: 169, loss: 1.135, acc: 0.64\n","epoch: 3, batch: 170, loss: 1.031, acc: 0.63\n","epoch: 3, batch: 171, loss: 1.156, acc: 0.59\n","epoch: 3, batch: 172, loss: 1.134, acc: 0.60\n","epoch: 3, batch: 173, loss: 1.226, acc: 0.59\n","epoch: 3, batch: 174, loss: 1.137, acc: 0.62\n","epoch: 3, batch: 175, loss: 1.134, acc: 0.55\n","epoch: 3, batch: 176, loss: 1.121, acc: 0.54\n","epoch: 3, batch: 177, loss: 1.139, acc: 0.62\n","epoch: 3, batch: 178, loss: 1.205, acc: 0.57\n","epoch: 3, batch: 179, loss: 1.162, acc: 0.54\n","epoch: 3, batch: 180, loss: 1.099, acc: 0.64\n","epoch: 3, batch: 181, loss: 0.991, acc: 0.63\n","epoch: 3, batch: 182, loss: 1.288, acc: 0.58\n","epoch: 3, batch: 183, loss: 1.136, acc: 0.58\n","epoch: 3, batch: 184, loss: 1.021, acc: 0.60\n","epoch: 3, batch: 185, loss: 1.186, acc: 0.60\n","epoch: 3, batch: 186, loss: 1.099, acc: 0.62\n","epoch: 3, batch: 187, loss: 1.313, acc: 0.53\n","epoch: 3, batch: 188, loss: 1.175, acc: 0.60\n","epoch: 3, batch: 189, loss: 1.250, acc: 0.55\n","epoch: 3, batch: 190, loss: 1.173, acc: 0.56\n","epoch: 3, batch: 191, loss: 1.294, acc: 0.52\n","epoch: 3, batch: 192, loss: 1.174, acc: 0.53\n","epoch: 3, batch: 193, loss: 1.148, acc: 0.57\n","epoch: 3, batch: 194, loss: 1.234, acc: 0.57\n","epoch: 3, batch: 195, loss: 1.091, acc: 0.59\n","epoch: 3, batch: 196, loss: 1.204, acc: 0.52\n","epoch: 3, batch: 197, loss: 1.259, acc: 0.56\n","epoch: 3, batch: 198, loss: 1.045, acc: 0.65\n","epoch: 3, batch: 199, loss: 1.194, acc: 0.59\n","epoch: 3, batch: 200, loss: 1.133, acc: 0.60\n","epoch: 3, batch: 201, loss: 1.159, acc: 0.59\n","epoch: 3, batch: 202, loss: 1.283, acc: 0.52\n","epoch: 3, batch: 203, loss: 1.301, acc: 0.53\n","epoch: 3, batch: 204, loss: 1.182, acc: 0.64\n","epoch: 3, batch: 205, loss: 1.173, acc: 0.59\n","epoch: 3, batch: 206, loss: 1.258, acc: 0.57\n","epoch: 3, batch: 207, loss: 1.150, acc: 0.61\n","epoch: 3, batch: 208, loss: 1.239, acc: 0.52\n","epoch: 3, batch: 209, loss: 1.075, acc: 0.64\n","epoch: 3, batch: 210, loss: 1.139, acc: 0.62\n","epoch: 3, batch: 211, loss: 1.449, acc: 0.46\n","epoch: 3, batch: 212, loss: 1.271, acc: 0.57\n","epoch: 3, batch: 213, loss: 1.145, acc: 0.64\n","epoch: 3, batch: 214, loss: 1.183, acc: 0.59\n","epoch: 3, batch: 215, loss: 1.161, acc: 0.60\n","epoch: 3, batch: 216, loss: 1.149, acc: 0.63\n","epoch: 3, batch: 217, loss: 1.190, acc: 0.53\n","epoch: 3, batch: 218, loss: 1.147, acc: 0.55\n","epoch: 3, batch: 219, loss: 1.073, acc: 0.61\n","epoch: 3, batch: 220, loss: 1.029, acc: 0.67\n","epoch: 3, batch: 221, loss: 1.113, acc: 0.61\n","epoch: 3, batch: 222, loss: 1.056, acc: 0.58\n","epoch: 3, batch: 223, loss: 1.498, acc: 0.45\n","epoch: 3, batch: 224, loss: 1.038, acc: 0.65\n","epoch: 3, batch: 225, loss: 1.122, acc: 0.64\n","epoch: 3, batch: 226, loss: 1.134, acc: 0.64\n","epoch: 3, batch: 227, loss: 1.272, acc: 0.61\n","epoch: 3, batch: 228, loss: 1.335, acc: 0.60\n","epoch: 3, batch: 229, loss: 1.316, acc: 0.56\n","epoch: 3, batch: 230, loss: 1.143, acc: 0.61\n","epoch: 3, batch: 231, loss: 1.125, acc: 0.64\n","epoch: 3, batch: 232, loss: 1.013, acc: 0.66\n","epoch: 3, batch: 233, loss: 1.088, acc: 0.63\n","epoch: 3, batch: 234, loss: 1.065, acc: 0.65\n","epoch: 3, batch: 235, loss: 1.095, acc: 0.65\n","epoch: 3, batch: 236, loss: 1.145, acc: 0.59\n","epoch: 3, batch: 237, loss: 1.137, acc: 0.57\n","epoch: 3, batch: 238, loss: 1.223, acc: 0.62\n","epoch: 3, batch: 239, loss: 1.123, acc: 0.59\n","epoch: 3, batch: 240, loss: 1.127, acc: 0.59\n","epoch: 3, batch: 241, loss: 1.178, acc: 0.58\n","epoch: 3, batch: 242, loss: 1.163, acc: 0.62\n","epoch: 3, batch: 243, loss: 1.163, acc: 0.60\n","epoch: 3, batch: 244, loss: 1.124, acc: 0.61\n","epoch: 3, batch: 245, loss: 1.047, acc: 0.64\n","epoch: 3, batch: 246, loss: 1.206, acc: 0.61\n","epoch: 3, batch: 247, loss: 1.217, acc: 0.58\n","epoch: 3, batch: 248, loss: 1.239, acc: 0.54\n","epoch: 3, batch: 249, loss: 1.244, acc: 0.52\n","epoch: 3, batch: 250, loss: 1.158, acc: 0.55\n","epoch: 3, batch: 251, loss: 1.071, acc: 0.60\n","epoch: 3, batch: 252, loss: 1.164, acc: 0.59\n","epoch: 3, batch: 253, loss: 1.211, acc: 0.57\n","epoch: 3, batch: 254, loss: 1.164, acc: 0.59\n","epoch: 3, batch: 255, loss: 1.105, acc: 0.67\n","epoch: 3, batch: 256, loss: 1.145, acc: 0.60\n","epoch: 3, batch: 257, loss: 1.090, acc: 0.62\n","epoch: 3, batch: 258, loss: 1.221, acc: 0.55\n","epoch: 3, batch: 259, loss: 1.199, acc: 0.53\n","epoch: 3, batch: 260, loss: 1.220, acc: 0.59\n","epoch: 3, batch: 261, loss: 1.108, acc: 0.60\n","epoch: 3, batch: 262, loss: 1.419, acc: 0.55\n","epoch: 3, batch: 263, loss: 1.039, acc: 0.59\n","epoch: 3, batch: 264, loss: 1.024, acc: 0.64\n","epoch: 3, batch: 265, loss: 1.112, acc: 0.59\n","epoch: 3, batch: 266, loss: 1.210, acc: 0.59\n","epoch: 3, batch: 267, loss: 1.288, acc: 0.57\n","epoch: 3, batch: 268, loss: 1.187, acc: 0.60\n","epoch: 3, batch: 269, loss: 1.022, acc: 0.62\n","epoch: 3, batch: 270, loss: 1.065, acc: 0.61\n","epoch: 3, batch: 271, loss: 1.230, acc: 0.61\n","epoch: 3, batch: 272, loss: 1.017, acc: 0.66\n","epoch: 3, batch: 273, loss: 1.140, acc: 0.58\n","epoch: 3, batch: 274, loss: 1.120, acc: 0.59\n","epoch: 3, batch: 275, loss: 1.040, acc: 0.58\n","epoch: 3, batch: 276, loss: 1.224, acc: 0.56\n","epoch: 3, batch: 277, loss: 1.142, acc: 0.59\n","epoch: 3, batch: 278, loss: 1.110, acc: 0.65\n","epoch: 3, batch: 279, loss: 1.012, acc: 0.65\n","epoch: 3, batch: 280, loss: 1.076, acc: 0.61\n","epoch: 3, batch: 281, loss: 1.104, acc: 0.66\n","epoch: 3, batch: 282, loss: 1.225, acc: 0.52\n","epoch: 3, batch: 283, loss: 1.187, acc: 0.55\n","epoch: 3, batch: 284, loss: 1.225, acc: 0.56\n","epoch: 3, batch: 285, loss: 1.300, acc: 0.55\n","epoch: 3, batch: 286, loss: 1.102, acc: 0.60\n","epoch: 3, batch: 287, loss: 1.066, acc: 0.65\n","epoch: 3, batch: 288, loss: 1.208, acc: 0.56\n","epoch: 3, batch: 289, loss: 1.268, acc: 0.52\n","epoch: 3, batch: 290, loss: 1.067, acc: 0.61\n","epoch: 3, batch: 291, loss: 1.195, acc: 0.59\n","epoch: 3, batch: 292, loss: 1.107, acc: 0.67\n","epoch: 3, batch: 293, loss: 1.220, acc: 0.52\n","epoch: 3, batch: 294, loss: 1.406, acc: 0.48\n","epoch: 3, batch: 295, loss: 1.091, acc: 0.57\n","epoch: 3, batch: 296, loss: 1.177, acc: 0.52\n","epoch: 3, batch: 297, loss: 1.333, acc: 0.54\n","epoch: 3, batch: 298, loss: 1.108, acc: 0.65\n","epoch: 3, batch: 299, loss: 1.090, acc: 0.60\n","epoch: 3, batch: 300, loss: 1.149, acc: 0.62\n","epoch: 3, batch: 301, loss: 1.111, acc: 0.65\n","epoch: 3, batch: 302, loss: 1.080, acc: 0.66\n","epoch: 3, batch: 303, loss: 1.230, acc: 0.51\n","epoch: 3, batch: 304, loss: 1.171, acc: 0.59\n","epoch: 3, batch: 305, loss: 1.242, acc: 0.55\n","epoch: 3, batch: 306, loss: 1.246, acc: 0.61\n","epoch: 3, batch: 307, loss: 1.196, acc: 0.59\n","epoch: 3, batch: 308, loss: 1.189, acc: 0.55\n","epoch: 3, batch: 309, loss: 1.017, acc: 0.67\n","epoch: 3, batch: 310, loss: 1.102, acc: 0.62\n","epoch: 3, batch: 311, loss: 1.153, acc: 0.61\n","epoch: 3, batch: 312, loss: 1.079, acc: 0.62\n","epoch: 3, batch: 313, loss: 1.066, acc: 0.66\n","epoch: 3, batch: 314, loss: 1.157, acc: 0.59\n","epoch: 3, batch: 315, loss: 1.104, acc: 0.52\n","epoch: 3, batch: 316, loss: 1.050, acc: 0.61\n","epoch: 3, batch: 317, loss: 1.119, acc: 0.64\n","epoch: 3, batch: 318, loss: 1.124, acc: 0.59\n","epoch: 3, batch: 319, loss: 1.016, acc: 0.65\n","epoch: 3, batch: 320, loss: 1.138, acc: 0.64\n","epoch: 3, batch: 321, loss: 1.257, acc: 0.55\n","epoch: 3, batch: 322, loss: 1.328, acc: 0.55\n","epoch: 3, batch: 323, loss: 1.209, acc: 0.58\n","epoch: 3, batch: 324, loss: 1.123, acc: 0.62\n","epoch: 3, batch: 325, loss: 1.212, acc: 0.58\n","epoch: 3, batch: 326, loss: 1.061, acc: 0.66\n","epoch: 3, batch: 327, loss: 1.167, acc: 0.61\n","epoch: 3, batch: 328, loss: 1.369, acc: 0.57\n","epoch: 3, batch: 329, loss: 1.086, acc: 0.62\n","epoch: 3, batch: 330, loss: 1.221, acc: 0.60\n","epoch: 3, batch: 331, loss: 1.298, acc: 0.55\n","epoch: 3, batch: 332, loss: 1.169, acc: 0.59\n","epoch: 3, batch: 333, loss: 1.175, acc: 0.59\n","epoch: 3, batch: 334, loss: 1.141, acc: 0.56\n","epoch: 3, batch: 335, loss: 0.988, acc: 0.66\n","epoch: 3, batch: 336, loss: 1.105, acc: 0.59\n","epoch: 3, batch: 337, loss: 1.150, acc: 0.59\n","epoch: 3, batch: 338, loss: 1.069, acc: 0.66\n","epoch: 3, batch: 339, loss: 1.154, acc: 0.57\n","epoch: 3, batch: 340, loss: 1.290, acc: 0.60\n","epoch: 3, batch: 341, loss: 1.136, acc: 0.63\n","epoch: 3, batch: 342, loss: 1.130, acc: 0.59\n","epoch: 3, batch: 343, loss: 1.182, acc: 0.60\n","epoch: 3, batch: 344, loss: 1.187, acc: 0.58\n","epoch: 3, batch: 345, loss: 1.106, acc: 0.59\n","epoch: 3, batch: 346, loss: 1.168, acc: 0.57\n","epoch: 3, batch: 347, loss: 1.305, acc: 0.52\n","epoch: 3, batch: 348, loss: 1.061, acc: 0.61\n","epoch: 3, batch: 349, loss: 1.126, acc: 0.62\n","epoch: 3, batch: 350, loss: 1.350, acc: 0.53\n","epoch: 3, batch: 351, loss: 1.187, acc: 0.59\n","epoch: 3, batch: 352, loss: 1.117, acc: 0.57\n","epoch: 3, batch: 353, loss: 1.097, acc: 0.63\n","epoch: 3, batch: 354, loss: 1.176, acc: 0.56\n","epoch: 3, batch: 355, loss: 1.247, acc: 0.54\n","epoch: 3, batch: 356, loss: 1.146, acc: 0.57\n","epoch: 3, batch: 357, loss: 1.115, acc: 0.60\n","epoch: 3, batch: 358, loss: 1.073, acc: 0.60\n","epoch: 3, batch: 359, loss: 1.409, acc: 0.48\n","epoch: 3, batch: 360, loss: 1.470, acc: 0.48\n","epoch: 3, batch: 361, loss: 1.105, acc: 0.59\n","epoch: 3, batch: 362, loss: 1.043, acc: 0.66\n","epoch: 3, batch: 363, loss: 1.024, acc: 0.66\n","epoch: 3, batch: 364, loss: 1.134, acc: 0.55\n","epoch: 3, batch: 365, loss: 1.039, acc: 0.64\n","epoch: 3, batch: 366, loss: 1.030, acc: 0.68\n","epoch: 3, batch: 367, loss: 1.020, acc: 0.62\n","epoch: 3, batch: 368, loss: 1.062, acc: 0.68\n","epoch: 3, batch: 369, loss: 1.031, acc: 0.65\n","epoch: 3, batch: 370, loss: 1.283, acc: 0.48\n","epoch: 3, batch: 371, loss: 1.138, acc: 0.53\n","epoch: 3, batch: 372, loss: 1.237, acc: 0.60\n","epoch: 3, batch: 373, loss: 1.081, acc: 0.59\n","epoch: 3, batch: 374, loss: 1.050, acc: 0.62\n","epoch: 3, batch: 375, loss: 0.982, acc: 0.62\n","epoch: 3, batch: 376, loss: 1.120, acc: 0.60\n","epoch: 3, batch: 377, loss: 1.205, acc: 0.60\n","epoch: 3, batch: 378, loss: 1.102, acc: 0.62\n","epoch: 3, batch: 379, loss: 1.333, acc: 0.58\n","epoch: 3, batch: 380, loss: 1.001, acc: 0.64\n","epoch: 3, batch: 381, loss: 1.115, acc: 0.56\n","epoch: 3, batch: 382, loss: 0.985, acc: 0.64\n","epoch: 3, batch: 383, loss: 1.139, acc: 0.55\n","epoch: 3, batch: 384, loss: 1.010, acc: 0.62\n","epoch: 3, batch: 385, loss: 1.177, acc: 0.62\n","epoch: 3, batch: 386, loss: 1.225, acc: 0.55\n","epoch: 3, batch: 387, loss: 1.063, acc: 0.57\n","epoch: 3, batch: 388, loss: 1.167, acc: 0.62\n","epoch: 3, batch: 389, loss: 1.115, acc: 0.56\n","epoch: 3, batch: 390, loss: 1.183, acc: 0.55\n","epoch: 3, batch: 391, loss: 1.116, acc: 0.69\n","epoch: 4, batch: 1, loss: 1.143, acc: 0.60\n","epoch: 4, batch: 2, loss: 1.195, acc: 0.57\n","epoch: 4, batch: 3, loss: 1.188, acc: 0.60\n","epoch: 4, batch: 4, loss: 1.316, acc: 0.49\n","epoch: 4, batch: 5, loss: 1.107, acc: 0.65\n","epoch: 4, batch: 6, loss: 1.152, acc: 0.58\n","epoch: 4, batch: 7, loss: 1.194, acc: 0.63\n","epoch: 4, batch: 8, loss: 1.079, acc: 0.62\n","epoch: 4, batch: 9, loss: 1.197, acc: 0.62\n","epoch: 4, batch: 10, loss: 1.128, acc: 0.64\n","epoch: 4, batch: 11, loss: 1.251, acc: 0.52\n","epoch: 4, batch: 12, loss: 1.205, acc: 0.59\n","epoch: 4, batch: 13, loss: 1.188, acc: 0.56\n","epoch: 4, batch: 14, loss: 1.093, acc: 0.61\n","epoch: 4, batch: 15, loss: 1.163, acc: 0.59\n","epoch: 4, batch: 16, loss: 1.266, acc: 0.56\n","epoch: 4, batch: 17, loss: 1.224, acc: 0.57\n","epoch: 4, batch: 18, loss: 1.202, acc: 0.55\n","epoch: 4, batch: 19, loss: 1.010, acc: 0.67\n","epoch: 4, batch: 20, loss: 0.948, acc: 0.72\n","epoch: 4, batch: 21, loss: 1.209, acc: 0.63\n","epoch: 4, batch: 22, loss: 1.091, acc: 0.57\n","epoch: 4, batch: 23, loss: 1.131, acc: 0.65\n","epoch: 4, batch: 24, loss: 1.116, acc: 0.66\n","epoch: 4, batch: 25, loss: 1.171, acc: 0.63\n","epoch: 4, batch: 26, loss: 1.205, acc: 0.57\n","epoch: 4, batch: 27, loss: 0.971, acc: 0.65\n","epoch: 4, batch: 28, loss: 0.957, acc: 0.66\n","epoch: 4, batch: 29, loss: 1.097, acc: 0.59\n","epoch: 4, batch: 30, loss: 1.173, acc: 0.60\n","epoch: 4, batch: 31, loss: 1.238, acc: 0.58\n","epoch: 4, batch: 32, loss: 1.100, acc: 0.57\n","epoch: 4, batch: 33, loss: 1.145, acc: 0.62\n","epoch: 4, batch: 34, loss: 1.160, acc: 0.62\n","epoch: 4, batch: 35, loss: 1.281, acc: 0.55\n","epoch: 4, batch: 36, loss: 1.307, acc: 0.50\n","epoch: 4, batch: 37, loss: 1.100, acc: 0.59\n","epoch: 4, batch: 38, loss: 1.259, acc: 0.59\n","epoch: 4, batch: 39, loss: 1.210, acc: 0.52\n","epoch: 4, batch: 40, loss: 1.256, acc: 0.53\n","epoch: 4, batch: 41, loss: 1.078, acc: 0.59\n","epoch: 4, batch: 42, loss: 1.137, acc: 0.57\n","epoch: 4, batch: 43, loss: 1.132, acc: 0.60\n","epoch: 4, batch: 44, loss: 1.162, acc: 0.59\n","epoch: 4, batch: 45, loss: 1.035, acc: 0.65\n","epoch: 4, batch: 46, loss: 1.294, acc: 0.58\n","epoch: 4, batch: 47, loss: 1.089, acc: 0.59\n","epoch: 4, batch: 48, loss: 1.110, acc: 0.62\n","epoch: 4, batch: 49, loss: 0.960, acc: 0.66\n","epoch: 4, batch: 50, loss: 1.052, acc: 0.63\n","epoch: 4, batch: 51, loss: 1.206, acc: 0.57\n","epoch: 4, batch: 52, loss: 1.170, acc: 0.60\n","epoch: 4, batch: 53, loss: 1.115, acc: 0.59\n","epoch: 4, batch: 54, loss: 1.147, acc: 0.59\n","epoch: 4, batch: 55, loss: 1.139, acc: 0.59\n","epoch: 4, batch: 56, loss: 1.048, acc: 0.65\n","epoch: 4, batch: 57, loss: 1.088, acc: 0.71\n","epoch: 4, batch: 58, loss: 1.139, acc: 0.63\n","epoch: 4, batch: 59, loss: 1.283, acc: 0.55\n","epoch: 4, batch: 60, loss: 1.334, acc: 0.51\n","epoch: 4, batch: 61, loss: 1.030, acc: 0.62\n","epoch: 4, batch: 62, loss: 1.287, acc: 0.55\n","epoch: 4, batch: 63, loss: 1.018, acc: 0.67\n","epoch: 4, batch: 64, loss: 1.196, acc: 0.62\n","epoch: 4, batch: 65, loss: 1.242, acc: 0.56\n","epoch: 4, batch: 66, loss: 1.033, acc: 0.64\n","epoch: 4, batch: 67, loss: 1.186, acc: 0.62\n","epoch: 4, batch: 68, loss: 1.166, acc: 0.55\n","epoch: 4, batch: 69, loss: 1.027, acc: 0.63\n","epoch: 4, batch: 70, loss: 1.014, acc: 0.65\n","epoch: 4, batch: 71, loss: 1.185, acc: 0.59\n","epoch: 4, batch: 72, loss: 1.162, acc: 0.60\n","epoch: 4, batch: 73, loss: 1.061, acc: 0.66\n","epoch: 4, batch: 74, loss: 1.164, acc: 0.60\n","epoch: 4, batch: 75, loss: 1.226, acc: 0.58\n","epoch: 4, batch: 76, loss: 1.266, acc: 0.60\n","epoch: 4, batch: 77, loss: 1.143, acc: 0.60\n","epoch: 4, batch: 78, loss: 1.221, acc: 0.60\n","epoch: 4, batch: 79, loss: 0.972, acc: 0.64\n","epoch: 4, batch: 80, loss: 1.060, acc: 0.62\n","epoch: 4, batch: 81, loss: 1.119, acc: 0.59\n","epoch: 4, batch: 82, loss: 1.197, acc: 0.59\n","epoch: 4, batch: 83, loss: 1.460, acc: 0.49\n","epoch: 4, batch: 84, loss: 1.086, acc: 0.65\n","epoch: 4, batch: 85, loss: 1.415, acc: 0.49\n","epoch: 4, batch: 86, loss: 1.045, acc: 0.63\n","epoch: 4, batch: 87, loss: 1.029, acc: 0.67\n","epoch: 4, batch: 88, loss: 1.102, acc: 0.64\n","epoch: 4, batch: 89, loss: 1.246, acc: 0.57\n","epoch: 4, batch: 90, loss: 1.103, acc: 0.59\n","epoch: 4, batch: 91, loss: 1.014, acc: 0.66\n","epoch: 4, batch: 92, loss: 1.007, acc: 0.70\n","epoch: 4, batch: 93, loss: 1.115, acc: 0.61\n","epoch: 4, batch: 94, loss: 1.204, acc: 0.58\n","epoch: 4, batch: 95, loss: 1.104, acc: 0.62\n","epoch: 4, batch: 96, loss: 1.254, acc: 0.56\n","epoch: 4, batch: 97, loss: 1.017, acc: 0.65\n","epoch: 4, batch: 98, loss: 0.964, acc: 0.68\n","epoch: 4, batch: 99, loss: 1.059, acc: 0.61\n","epoch: 4, batch: 100, loss: 1.135, acc: 0.62\n","epoch: 4, batch: 101, loss: 1.268, acc: 0.53\n","epoch: 4, batch: 102, loss: 1.079, acc: 0.59\n","epoch: 4, batch: 103, loss: 1.171, acc: 0.62\n","epoch: 4, batch: 104, loss: 1.047, acc: 0.63\n","epoch: 4, batch: 105, loss: 1.041, acc: 0.61\n","epoch: 4, batch: 106, loss: 1.117, acc: 0.62\n","epoch: 4, batch: 107, loss: 1.145, acc: 0.57\n","epoch: 4, batch: 108, loss: 1.086, acc: 0.68\n","epoch: 4, batch: 109, loss: 1.213, acc: 0.56\n","epoch: 4, batch: 110, loss: 1.108, acc: 0.66\n","epoch: 4, batch: 111, loss: 1.137, acc: 0.62\n","epoch: 4, batch: 112, loss: 1.081, acc: 0.63\n","epoch: 4, batch: 113, loss: 1.111, acc: 0.62\n","epoch: 4, batch: 114, loss: 1.327, acc: 0.52\n","epoch: 4, batch: 115, loss: 1.076, acc: 0.63\n","epoch: 4, batch: 116, loss: 1.227, acc: 0.60\n","epoch: 4, batch: 117, loss: 1.064, acc: 0.66\n","epoch: 4, batch: 118, loss: 1.168, acc: 0.60\n","epoch: 4, batch: 119, loss: 1.144, acc: 0.59\n","epoch: 4, batch: 120, loss: 0.950, acc: 0.70\n","epoch: 4, batch: 121, loss: 1.026, acc: 0.62\n","epoch: 4, batch: 122, loss: 1.251, acc: 0.54\n","epoch: 4, batch: 123, loss: 1.061, acc: 0.64\n","epoch: 4, batch: 124, loss: 1.040, acc: 0.66\n","epoch: 4, batch: 125, loss: 1.100, acc: 0.62\n","epoch: 4, batch: 126, loss: 1.120, acc: 0.61\n","epoch: 4, batch: 127, loss: 1.275, acc: 0.56\n","epoch: 4, batch: 128, loss: 1.007, acc: 0.68\n","epoch: 4, batch: 129, loss: 0.961, acc: 0.66\n","epoch: 4, batch: 130, loss: 1.319, acc: 0.55\n","epoch: 4, batch: 131, loss: 1.126, acc: 0.62\n","epoch: 4, batch: 132, loss: 1.093, acc: 0.63\n","epoch: 4, batch: 133, loss: 1.143, acc: 0.55\n","epoch: 4, batch: 134, loss: 1.174, acc: 0.62\n","epoch: 4, batch: 135, loss: 1.158, acc: 0.59\n","epoch: 4, batch: 136, loss: 1.065, acc: 0.66\n","epoch: 4, batch: 137, loss: 1.246, acc: 0.58\n","epoch: 4, batch: 138, loss: 1.226, acc: 0.56\n","epoch: 4, batch: 139, loss: 1.195, acc: 0.59\n","epoch: 4, batch: 140, loss: 1.195, acc: 0.57\n","epoch: 4, batch: 141, loss: 1.240, acc: 0.58\n","epoch: 4, batch: 142, loss: 1.212, acc: 0.55\n","epoch: 4, batch: 143, loss: 1.114, acc: 0.63\n","epoch: 4, batch: 144, loss: 1.104, acc: 0.62\n","epoch: 4, batch: 145, loss: 1.117, acc: 0.61\n","epoch: 4, batch: 146, loss: 1.224, acc: 0.59\n","epoch: 4, batch: 147, loss: 1.010, acc: 0.61\n","epoch: 4, batch: 148, loss: 1.163, acc: 0.57\n","epoch: 4, batch: 149, loss: 1.202, acc: 0.56\n","epoch: 4, batch: 150, loss: 1.010, acc: 0.66\n","epoch: 4, batch: 151, loss: 1.213, acc: 0.55\n","epoch: 4, batch: 152, loss: 1.376, acc: 0.50\n","epoch: 4, batch: 153, loss: 1.114, acc: 0.62\n","epoch: 4, batch: 154, loss: 1.150, acc: 0.58\n","epoch: 4, batch: 155, loss: 1.244, acc: 0.56\n","epoch: 4, batch: 156, loss: 1.380, acc: 0.48\n","epoch: 4, batch: 157, loss: 1.391, acc: 0.55\n","epoch: 4, batch: 158, loss: 1.338, acc: 0.54\n","epoch: 4, batch: 159, loss: 1.060, acc: 0.62\n","epoch: 4, batch: 160, loss: 1.181, acc: 0.59\n","epoch: 4, batch: 161, loss: 1.016, acc: 0.64\n","epoch: 4, batch: 162, loss: 1.290, acc: 0.55\n","epoch: 4, batch: 163, loss: 1.174, acc: 0.59\n","epoch: 4, batch: 164, loss: 1.092, acc: 0.63\n","epoch: 4, batch: 165, loss: 1.129, acc: 0.55\n","epoch: 4, batch: 166, loss: 1.032, acc: 0.63\n","epoch: 4, batch: 167, loss: 1.230, acc: 0.55\n","epoch: 4, batch: 168, loss: 1.207, acc: 0.55\n","epoch: 4, batch: 169, loss: 1.113, acc: 0.61\n","epoch: 4, batch: 170, loss: 1.113, acc: 0.67\n","epoch: 4, batch: 171, loss: 1.010, acc: 0.66\n","epoch: 4, batch: 172, loss: 1.127, acc: 0.62\n","epoch: 4, batch: 173, loss: 1.018, acc: 0.67\n","epoch: 4, batch: 174, loss: 1.138, acc: 0.61\n","epoch: 4, batch: 175, loss: 1.229, acc: 0.58\n","epoch: 4, batch: 176, loss: 1.108, acc: 0.63\n","epoch: 4, batch: 177, loss: 1.044, acc: 0.60\n","epoch: 4, batch: 178, loss: 1.078, acc: 0.56\n","epoch: 4, batch: 179, loss: 0.942, acc: 0.66\n","epoch: 4, batch: 180, loss: 1.028, acc: 0.62\n","epoch: 4, batch: 181, loss: 1.016, acc: 0.62\n","epoch: 4, batch: 182, loss: 1.107, acc: 0.59\n","epoch: 4, batch: 183, loss: 1.151, acc: 0.54\n","epoch: 4, batch: 184, loss: 1.168, acc: 0.59\n","epoch: 4, batch: 185, loss: 1.096, acc: 0.62\n","epoch: 4, batch: 186, loss: 1.137, acc: 0.61\n","epoch: 4, batch: 187, loss: 0.940, acc: 0.68\n","epoch: 4, batch: 188, loss: 1.155, acc: 0.64\n","epoch: 4, batch: 189, loss: 1.117, acc: 0.59\n","epoch: 4, batch: 190, loss: 1.046, acc: 0.62\n","epoch: 4, batch: 191, loss: 0.943, acc: 0.66\n","epoch: 4, batch: 192, loss: 1.196, acc: 0.61\n","epoch: 4, batch: 193, loss: 1.194, acc: 0.58\n","epoch: 4, batch: 194, loss: 1.094, acc: 0.60\n","epoch: 4, batch: 195, loss: 1.248, acc: 0.59\n","epoch: 4, batch: 196, loss: 1.114, acc: 0.62\n","epoch: 4, batch: 197, loss: 1.072, acc: 0.62\n","epoch: 4, batch: 198, loss: 0.961, acc: 0.67\n","epoch: 4, batch: 199, loss: 1.035, acc: 0.62\n","epoch: 4, batch: 200, loss: 1.058, acc: 0.69\n","epoch: 4, batch: 201, loss: 1.330, acc: 0.55\n","epoch: 4, batch: 202, loss: 1.177, acc: 0.59\n","epoch: 4, batch: 203, loss: 0.996, acc: 0.62\n","epoch: 4, batch: 204, loss: 1.006, acc: 0.66\n","epoch: 4, batch: 205, loss: 1.072, acc: 0.66\n","epoch: 4, batch: 206, loss: 0.988, acc: 0.62\n","epoch: 4, batch: 207, loss: 1.131, acc: 0.60\n","epoch: 4, batch: 208, loss: 1.148, acc: 0.55\n","epoch: 4, batch: 209, loss: 1.191, acc: 0.53\n","epoch: 4, batch: 210, loss: 1.130, acc: 0.66\n","epoch: 4, batch: 211, loss: 1.137, acc: 0.59\n","epoch: 4, batch: 212, loss: 1.077, acc: 0.61\n","epoch: 4, batch: 213, loss: 1.115, acc: 0.60\n","epoch: 4, batch: 214, loss: 1.013, acc: 0.63\n","epoch: 4, batch: 215, loss: 1.006, acc: 0.58\n","epoch: 4, batch: 216, loss: 1.314, acc: 0.55\n","epoch: 4, batch: 217, loss: 1.026, acc: 0.62\n","epoch: 4, batch: 218, loss: 1.184, acc: 0.60\n","epoch: 4, batch: 219, loss: 1.129, acc: 0.61\n","epoch: 4, batch: 220, loss: 1.037, acc: 0.66\n","epoch: 4, batch: 221, loss: 1.202, acc: 0.62\n","epoch: 4, batch: 222, loss: 1.178, acc: 0.58\n","epoch: 4, batch: 223, loss: 1.099, acc: 0.60\n","epoch: 4, batch: 224, loss: 1.217, acc: 0.59\n","epoch: 4, batch: 225, loss: 1.000, acc: 0.67\n","epoch: 4, batch: 226, loss: 1.077, acc: 0.60\n","epoch: 4, batch: 227, loss: 1.076, acc: 0.65\n","epoch: 4, batch: 228, loss: 1.137, acc: 0.59\n","epoch: 4, batch: 229, loss: 1.207, acc: 0.58\n","epoch: 4, batch: 230, loss: 1.032, acc: 0.67\n","epoch: 4, batch: 231, loss: 1.021, acc: 0.62\n","epoch: 4, batch: 232, loss: 1.061, acc: 0.62\n","epoch: 4, batch: 233, loss: 1.060, acc: 0.67\n","epoch: 4, batch: 234, loss: 1.158, acc: 0.57\n","epoch: 4, batch: 235, loss: 1.040, acc: 0.67\n","epoch: 4, batch: 236, loss: 0.977, acc: 0.65\n","epoch: 4, batch: 237, loss: 1.154, acc: 0.61\n","epoch: 4, batch: 238, loss: 1.076, acc: 0.62\n","epoch: 4, batch: 239, loss: 0.918, acc: 0.68\n","epoch: 4, batch: 240, loss: 0.953, acc: 0.70\n","epoch: 4, batch: 241, loss: 0.983, acc: 0.69\n","epoch: 4, batch: 242, loss: 0.939, acc: 0.68\n","epoch: 4, batch: 243, loss: 1.007, acc: 0.60\n","epoch: 4, batch: 244, loss: 1.099, acc: 0.62\n","epoch: 4, batch: 245, loss: 0.952, acc: 0.62\n","epoch: 4, batch: 246, loss: 1.202, acc: 0.58\n","epoch: 4, batch: 247, loss: 1.069, acc: 0.58\n","epoch: 4, batch: 248, loss: 0.997, acc: 0.69\n","epoch: 4, batch: 249, loss: 1.087, acc: 0.57\n","epoch: 4, batch: 250, loss: 1.051, acc: 0.61\n","epoch: 4, batch: 251, loss: 1.143, acc: 0.59\n","epoch: 4, batch: 252, loss: 0.986, acc: 0.68\n","epoch: 4, batch: 253, loss: 1.170, acc: 0.60\n","epoch: 4, batch: 254, loss: 1.089, acc: 0.62\n","epoch: 4, batch: 255, loss: 1.207, acc: 0.59\n","epoch: 4, batch: 256, loss: 1.205, acc: 0.57\n","epoch: 4, batch: 257, loss: 1.139, acc: 0.62\n","epoch: 4, batch: 258, loss: 1.398, acc: 0.56\n","epoch: 4, batch: 259, loss: 0.979, acc: 0.68\n","epoch: 4, batch: 260, loss: 1.238, acc: 0.57\n","epoch: 4, batch: 261, loss: 1.150, acc: 0.57\n","epoch: 4, batch: 262, loss: 0.932, acc: 0.64\n","epoch: 4, batch: 263, loss: 1.165, acc: 0.60\n","epoch: 4, batch: 264, loss: 1.186, acc: 0.52\n","epoch: 4, batch: 265, loss: 1.084, acc: 0.65\n","epoch: 4, batch: 266, loss: 1.132, acc: 0.58\n","epoch: 4, batch: 267, loss: 1.094, acc: 0.63\n","epoch: 4, batch: 268, loss: 1.080, acc: 0.65\n","epoch: 4, batch: 269, loss: 1.052, acc: 0.62\n","epoch: 4, batch: 270, loss: 1.025, acc: 0.63\n","epoch: 4, batch: 271, loss: 1.110, acc: 0.63\n","epoch: 4, batch: 272, loss: 1.114, acc: 0.62\n","epoch: 4, batch: 273, loss: 0.995, acc: 0.66\n","epoch: 4, batch: 274, loss: 1.192, acc: 0.51\n","epoch: 4, batch: 275, loss: 0.866, acc: 0.68\n","epoch: 4, batch: 276, loss: 1.082, acc: 0.64\n","epoch: 4, batch: 277, loss: 0.971, acc: 0.68\n","epoch: 4, batch: 278, loss: 0.971, acc: 0.63\n","epoch: 4, batch: 279, loss: 1.213, acc: 0.62\n","epoch: 4, batch: 280, loss: 0.986, acc: 0.65\n","epoch: 4, batch: 281, loss: 1.087, acc: 0.65\n","epoch: 4, batch: 282, loss: 1.215, acc: 0.53\n","epoch: 4, batch: 283, loss: 1.137, acc: 0.60\n","epoch: 4, batch: 284, loss: 1.008, acc: 0.68\n","epoch: 4, batch: 285, loss: 1.242, acc: 0.54\n","epoch: 4, batch: 286, loss: 1.089, acc: 0.60\n","epoch: 4, batch: 287, loss: 1.053, acc: 0.61\n","epoch: 4, batch: 288, loss: 1.314, acc: 0.48\n","epoch: 4, batch: 289, loss: 1.101, acc: 0.64\n","epoch: 4, batch: 290, loss: 0.954, acc: 0.71\n","epoch: 4, batch: 291, loss: 0.970, acc: 0.69\n","epoch: 4, batch: 292, loss: 1.124, acc: 0.62\n","epoch: 4, batch: 293, loss: 1.166, acc: 0.61\n","epoch: 4, batch: 294, loss: 1.026, acc: 0.62\n","epoch: 4, batch: 295, loss: 1.078, acc: 0.59\n","epoch: 4, batch: 296, loss: 1.123, acc: 0.57\n","epoch: 4, batch: 297, loss: 1.102, acc: 0.62\n","epoch: 4, batch: 298, loss: 1.049, acc: 0.63\n","epoch: 4, batch: 299, loss: 0.990, acc: 0.65\n","epoch: 4, batch: 300, loss: 1.215, acc: 0.59\n","epoch: 4, batch: 301, loss: 0.912, acc: 0.62\n","epoch: 4, batch: 302, loss: 1.190, acc: 0.61\n","epoch: 4, batch: 303, loss: 0.958, acc: 0.65\n","epoch: 4, batch: 304, loss: 1.056, acc: 0.62\n","epoch: 4, batch: 305, loss: 1.040, acc: 0.66\n","epoch: 4, batch: 306, loss: 1.253, acc: 0.52\n","epoch: 4, batch: 307, loss: 0.986, acc: 0.64\n","epoch: 4, batch: 308, loss: 1.052, acc: 0.65\n","epoch: 4, batch: 309, loss: 1.044, acc: 0.67\n","epoch: 4, batch: 310, loss: 1.022, acc: 0.64\n","epoch: 4, batch: 311, loss: 0.889, acc: 0.68\n","epoch: 4, batch: 312, loss: 1.182, acc: 0.59\n","epoch: 4, batch: 313, loss: 1.185, acc: 0.62\n","epoch: 4, batch: 314, loss: 0.968, acc: 0.59\n","epoch: 4, batch: 315, loss: 1.116, acc: 0.59\n","epoch: 4, batch: 316, loss: 1.135, acc: 0.60\n","epoch: 4, batch: 317, loss: 0.909, acc: 0.66\n","epoch: 4, batch: 318, loss: 1.059, acc: 0.66\n","epoch: 4, batch: 319, loss: 1.046, acc: 0.67\n","epoch: 4, batch: 320, loss: 1.108, acc: 0.63\n","epoch: 4, batch: 321, loss: 1.168, acc: 0.57\n","epoch: 4, batch: 322, loss: 0.974, acc: 0.70\n","epoch: 4, batch: 323, loss: 1.085, acc: 0.64\n","epoch: 4, batch: 324, loss: 1.093, acc: 0.63\n","epoch: 4, batch: 325, loss: 1.128, acc: 0.62\n","epoch: 4, batch: 326, loss: 1.171, acc: 0.60\n","epoch: 4, batch: 327, loss: 1.016, acc: 0.64\n","epoch: 4, batch: 328, loss: 1.153, acc: 0.57\n","epoch: 4, batch: 329, loss: 1.246, acc: 0.57\n","epoch: 4, batch: 330, loss: 1.139, acc: 0.63\n","epoch: 4, batch: 331, loss: 1.137, acc: 0.60\n","epoch: 4, batch: 332, loss: 1.106, acc: 0.64\n","epoch: 4, batch: 333, loss: 1.207, acc: 0.60\n","epoch: 4, batch: 334, loss: 1.025, acc: 0.62\n","epoch: 4, batch: 335, loss: 1.036, acc: 0.62\n","epoch: 4, batch: 336, loss: 1.216, acc: 0.57\n","epoch: 4, batch: 337, loss: 1.098, acc: 0.63\n","epoch: 4, batch: 338, loss: 1.239, acc: 0.55\n","epoch: 4, batch: 339, loss: 1.135, acc: 0.55\n","epoch: 4, batch: 340, loss: 1.235, acc: 0.55\n","epoch: 4, batch: 341, loss: 1.158, acc: 0.61\n","epoch: 4, batch: 342, loss: 1.163, acc: 0.59\n","epoch: 4, batch: 343, loss: 0.944, acc: 0.73\n","epoch: 4, batch: 344, loss: 1.044, acc: 0.66\n","epoch: 4, batch: 345, loss: 1.215, acc: 0.58\n","epoch: 4, batch: 346, loss: 1.183, acc: 0.58\n","epoch: 4, batch: 347, loss: 1.234, acc: 0.52\n","epoch: 4, batch: 348, loss: 1.121, acc: 0.57\n","epoch: 4, batch: 349, loss: 0.992, acc: 0.66\n","epoch: 4, batch: 350, loss: 1.100, acc: 0.61\n","epoch: 4, batch: 351, loss: 1.115, acc: 0.58\n","epoch: 4, batch: 352, loss: 1.170, acc: 0.59\n","epoch: 4, batch: 353, loss: 1.097, acc: 0.62\n","epoch: 4, batch: 354, loss: 1.064, acc: 0.65\n","epoch: 4, batch: 355, loss: 1.011, acc: 0.64\n","epoch: 4, batch: 356, loss: 1.004, acc: 0.64\n","epoch: 4, batch: 357, loss: 0.987, acc: 0.63\n","epoch: 4, batch: 358, loss: 1.110, acc: 0.64\n","epoch: 4, batch: 359, loss: 1.051, acc: 0.63\n","epoch: 4, batch: 360, loss: 1.082, acc: 0.57\n","epoch: 4, batch: 361, loss: 1.047, acc: 0.63\n","epoch: 4, batch: 362, loss: 1.087, acc: 0.61\n","epoch: 4, batch: 363, loss: 1.019, acc: 0.62\n","epoch: 4, batch: 364, loss: 1.146, acc: 0.53\n","epoch: 4, batch: 365, loss: 1.143, acc: 0.62\n","epoch: 4, batch: 366, loss: 1.034, acc: 0.66\n","epoch: 4, batch: 367, loss: 1.083, acc: 0.66\n","epoch: 4, batch: 368, loss: 1.145, acc: 0.60\n","epoch: 4, batch: 369, loss: 1.217, acc: 0.58\n","epoch: 4, batch: 370, loss: 1.212, acc: 0.60\n","epoch: 4, batch: 371, loss: 0.977, acc: 0.59\n","epoch: 4, batch: 372, loss: 1.005, acc: 0.65\n","epoch: 4, batch: 373, loss: 0.940, acc: 0.67\n","epoch: 4, batch: 374, loss: 1.188, acc: 0.61\n","epoch: 4, batch: 375, loss: 1.150, acc: 0.59\n","epoch: 4, batch: 376, loss: 0.939, acc: 0.69\n","epoch: 4, batch: 377, loss: 0.941, acc: 0.70\n","epoch: 4, batch: 378, loss: 0.993, acc: 0.70\n","epoch: 4, batch: 379, loss: 0.995, acc: 0.62\n","epoch: 4, batch: 380, loss: 1.060, acc: 0.63\n","epoch: 4, batch: 381, loss: 1.099, acc: 0.59\n","epoch: 4, batch: 382, loss: 1.028, acc: 0.62\n","epoch: 4, batch: 383, loss: 1.124, acc: 0.59\n","epoch: 4, batch: 384, loss: 1.138, acc: 0.61\n","epoch: 4, batch: 385, loss: 1.138, acc: 0.57\n","epoch: 4, batch: 386, loss: 1.143, acc: 0.58\n","epoch: 4, batch: 387, loss: 0.887, acc: 0.69\n","epoch: 4, batch: 388, loss: 1.024, acc: 0.65\n","epoch: 4, batch: 389, loss: 1.002, acc: 0.62\n","epoch: 4, batch: 390, loss: 1.067, acc: 0.68\n","epoch: 4, batch: 391, loss: 0.963, acc: 0.66\n","epoch: 5, batch: 1, loss: 1.232, acc: 0.58\n","epoch: 5, batch: 2, loss: 1.039, acc: 0.60\n","epoch: 5, batch: 3, loss: 1.052, acc: 0.66\n","epoch: 5, batch: 4, loss: 1.076, acc: 0.59\n","epoch: 5, batch: 5, loss: 0.958, acc: 0.64\n","epoch: 5, batch: 6, loss: 1.075, acc: 0.61\n","epoch: 5, batch: 7, loss: 1.135, acc: 0.55\n","epoch: 5, batch: 8, loss: 1.082, acc: 0.67\n","epoch: 5, batch: 9, loss: 1.121, acc: 0.64\n","epoch: 5, batch: 10, loss: 0.984, acc: 0.61\n","epoch: 5, batch: 11, loss: 0.964, acc: 0.69\n","epoch: 5, batch: 12, loss: 1.061, acc: 0.62\n","epoch: 5, batch: 13, loss: 1.197, acc: 0.58\n","epoch: 5, batch: 14, loss: 1.217, acc: 0.55\n","epoch: 5, batch: 15, loss: 1.095, acc: 0.62\n","epoch: 5, batch: 16, loss: 1.329, acc: 0.59\n","epoch: 5, batch: 17, loss: 1.178, acc: 0.62\n","epoch: 5, batch: 18, loss: 1.103, acc: 0.60\n","epoch: 5, batch: 19, loss: 1.075, acc: 0.63\n","epoch: 5, batch: 20, loss: 1.097, acc: 0.59\n","epoch: 5, batch: 21, loss: 1.150, acc: 0.62\n","epoch: 5, batch: 22, loss: 0.922, acc: 0.68\n","epoch: 5, batch: 23, loss: 1.045, acc: 0.66\n","epoch: 5, batch: 24, loss: 1.027, acc: 0.65\n","epoch: 5, batch: 25, loss: 1.169, acc: 0.56\n","epoch: 5, batch: 26, loss: 0.921, acc: 0.66\n","epoch: 5, batch: 27, loss: 1.105, acc: 0.58\n","epoch: 5, batch: 28, loss: 1.093, acc: 0.61\n","epoch: 5, batch: 29, loss: 1.074, acc: 0.62\n","epoch: 5, batch: 30, loss: 1.096, acc: 0.62\n","epoch: 5, batch: 31, loss: 1.030, acc: 0.69\n","epoch: 5, batch: 32, loss: 0.912, acc: 0.66\n","epoch: 5, batch: 33, loss: 1.159, acc: 0.63\n","epoch: 5, batch: 34, loss: 1.143, acc: 0.66\n","epoch: 5, batch: 35, loss: 1.141, acc: 0.62\n","epoch: 5, batch: 36, loss: 1.153, acc: 0.65\n","epoch: 5, batch: 37, loss: 1.040, acc: 0.63\n","epoch: 5, batch: 38, loss: 1.095, acc: 0.59\n","epoch: 5, batch: 39, loss: 1.264, acc: 0.56\n","epoch: 5, batch: 40, loss: 1.057, acc: 0.63\n","epoch: 5, batch: 41, loss: 0.928, acc: 0.66\n","epoch: 5, batch: 42, loss: 1.209, acc: 0.59\n","epoch: 5, batch: 43, loss: 1.096, acc: 0.65\n","epoch: 5, batch: 44, loss: 0.968, acc: 0.63\n","epoch: 5, batch: 45, loss: 0.928, acc: 0.67\n","epoch: 5, batch: 46, loss: 0.956, acc: 0.63\n","epoch: 5, batch: 47, loss: 0.972, acc: 0.62\n","epoch: 5, batch: 48, loss: 1.034, acc: 0.66\n","epoch: 5, batch: 49, loss: 1.028, acc: 0.66\n","epoch: 5, batch: 50, loss: 1.255, acc: 0.52\n","epoch: 5, batch: 51, loss: 0.975, acc: 0.65\n","epoch: 5, batch: 52, loss: 1.080, acc: 0.65\n","epoch: 5, batch: 53, loss: 1.136, acc: 0.62\n","epoch: 5, batch: 54, loss: 0.976, acc: 0.66\n","epoch: 5, batch: 55, loss: 1.105, acc: 0.62\n","epoch: 5, batch: 56, loss: 0.937, acc: 0.65\n","epoch: 5, batch: 57, loss: 1.059, acc: 0.62\n","epoch: 5, batch: 58, loss: 1.213, acc: 0.59\n","epoch: 5, batch: 59, loss: 1.104, acc: 0.62\n","epoch: 5, batch: 60, loss: 1.231, acc: 0.60\n","epoch: 5, batch: 61, loss: 1.014, acc: 0.67\n","epoch: 5, batch: 62, loss: 1.088, acc: 0.67\n","epoch: 5, batch: 63, loss: 1.065, acc: 0.62\n","epoch: 5, batch: 64, loss: 1.057, acc: 0.64\n","epoch: 5, batch: 65, loss: 1.005, acc: 0.66\n","epoch: 5, batch: 66, loss: 0.987, acc: 0.68\n","epoch: 5, batch: 67, loss: 1.087, acc: 0.63\n","epoch: 5, batch: 68, loss: 0.993, acc: 0.66\n","epoch: 5, batch: 69, loss: 1.090, acc: 0.66\n","epoch: 5, batch: 70, loss: 1.111, acc: 0.66\n","epoch: 5, batch: 71, loss: 1.213, acc: 0.59\n","epoch: 5, batch: 72, loss: 1.158, acc: 0.60\n","epoch: 5, batch: 73, loss: 1.095, acc: 0.56\n","epoch: 5, batch: 74, loss: 1.117, acc: 0.61\n","epoch: 5, batch: 75, loss: 1.093, acc: 0.60\n","epoch: 5, batch: 76, loss: 1.233, acc: 0.55\n","epoch: 5, batch: 77, loss: 1.068, acc: 0.67\n","epoch: 5, batch: 78, loss: 1.151, acc: 0.60\n","epoch: 5, batch: 79, loss: 1.123, acc: 0.62\n","epoch: 5, batch: 80, loss: 1.139, acc: 0.62\n","epoch: 5, batch: 81, loss: 1.118, acc: 0.62\n","epoch: 5, batch: 82, loss: 1.177, acc: 0.58\n","epoch: 5, batch: 83, loss: 1.008, acc: 0.64\n","epoch: 5, batch: 84, loss: 1.033, acc: 0.66\n","epoch: 5, batch: 85, loss: 1.129, acc: 0.62\n","epoch: 5, batch: 86, loss: 1.239, acc: 0.61\n","epoch: 5, batch: 87, loss: 0.994, acc: 0.62\n","epoch: 5, batch: 88, loss: 1.229, acc: 0.59\n","epoch: 5, batch: 89, loss: 1.106, acc: 0.67\n","epoch: 5, batch: 90, loss: 1.020, acc: 0.63\n","epoch: 5, batch: 91, loss: 1.098, acc: 0.65\n","epoch: 5, batch: 92, loss: 1.134, acc: 0.62\n","epoch: 5, batch: 93, loss: 1.065, acc: 0.63\n","epoch: 5, batch: 94, loss: 0.916, acc: 0.68\n","epoch: 5, batch: 95, loss: 1.065, acc: 0.61\n","epoch: 5, batch: 96, loss: 0.973, acc: 0.65\n","epoch: 5, batch: 97, loss: 1.170, acc: 0.58\n","epoch: 5, batch: 98, loss: 0.989, acc: 0.70\n","epoch: 5, batch: 99, loss: 1.163, acc: 0.63\n","epoch: 5, batch: 100, loss: 0.989, acc: 0.71\n","epoch: 5, batch: 101, loss: 0.954, acc: 0.66\n","epoch: 5, batch: 102, loss: 1.007, acc: 0.63\n","epoch: 5, batch: 103, loss: 0.950, acc: 0.69\n","epoch: 5, batch: 104, loss: 1.065, acc: 0.66\n","epoch: 5, batch: 105, loss: 1.171, acc: 0.59\n","epoch: 5, batch: 106, loss: 1.067, acc: 0.67\n","epoch: 5, batch: 107, loss: 0.849, acc: 0.70\n","epoch: 5, batch: 108, loss: 0.926, acc: 0.67\n","epoch: 5, batch: 109, loss: 0.999, acc: 0.66\n","epoch: 5, batch: 110, loss: 1.086, acc: 0.63\n","epoch: 5, batch: 111, loss: 1.014, acc: 0.62\n","epoch: 5, batch: 112, loss: 0.976, acc: 0.66\n","epoch: 5, batch: 113, loss: 1.265, acc: 0.63\n","epoch: 5, batch: 114, loss: 0.967, acc: 0.65\n","epoch: 5, batch: 115, loss: 1.064, acc: 0.64\n","epoch: 5, batch: 116, loss: 0.958, acc: 0.70\n","epoch: 5, batch: 117, loss: 1.062, acc: 0.62\n","epoch: 5, batch: 118, loss: 0.845, acc: 0.73\n","epoch: 5, batch: 119, loss: 1.021, acc: 0.67\n","epoch: 5, batch: 120, loss: 1.096, acc: 0.58\n","epoch: 5, batch: 121, loss: 1.052, acc: 0.63\n","epoch: 5, batch: 122, loss: 0.976, acc: 0.66\n","epoch: 5, batch: 123, loss: 0.888, acc: 0.67\n","epoch: 5, batch: 124, loss: 1.157, acc: 0.62\n","epoch: 5, batch: 125, loss: 0.995, acc: 0.62\n","epoch: 5, batch: 126, loss: 1.128, acc: 0.67\n","epoch: 5, batch: 127, loss: 1.008, acc: 0.67\n","epoch: 5, batch: 128, loss: 1.189, acc: 0.60\n","epoch: 5, batch: 129, loss: 0.991, acc: 0.66\n","epoch: 5, batch: 130, loss: 1.027, acc: 0.63\n","epoch: 5, batch: 131, loss: 1.053, acc: 0.67\n","epoch: 5, batch: 132, loss: 1.196, acc: 0.62\n","epoch: 5, batch: 133, loss: 0.978, acc: 0.62\n","epoch: 5, batch: 134, loss: 1.123, acc: 0.66\n","epoch: 5, batch: 135, loss: 1.165, acc: 0.59\n","epoch: 5, batch: 136, loss: 1.078, acc: 0.61\n","epoch: 5, batch: 137, loss: 1.180, acc: 0.58\n","epoch: 5, batch: 138, loss: 1.092, acc: 0.65\n","epoch: 5, batch: 139, loss: 0.911, acc: 0.66\n","epoch: 5, batch: 140, loss: 1.097, acc: 0.58\n","epoch: 5, batch: 141, loss: 1.046, acc: 0.59\n","epoch: 5, batch: 142, loss: 1.188, acc: 0.60\n","epoch: 5, batch: 143, loss: 0.971, acc: 0.63\n","epoch: 5, batch: 144, loss: 1.040, acc: 0.62\n","epoch: 5, batch: 145, loss: 1.108, acc: 0.62\n","epoch: 5, batch: 146, loss: 1.061, acc: 0.63\n","epoch: 5, batch: 147, loss: 1.113, acc: 0.62\n","epoch: 5, batch: 148, loss: 0.996, acc: 0.66\n","epoch: 5, batch: 149, loss: 1.033, acc: 0.67\n","epoch: 5, batch: 150, loss: 1.122, acc: 0.58\n","epoch: 5, batch: 151, loss: 1.138, acc: 0.66\n","epoch: 5, batch: 152, loss: 1.101, acc: 0.59\n","epoch: 5, batch: 153, loss: 1.008, acc: 0.67\n","epoch: 5, batch: 154, loss: 0.913, acc: 0.67\n","epoch: 5, batch: 155, loss: 1.133, acc: 0.58\n","epoch: 5, batch: 156, loss: 1.269, acc: 0.54\n","epoch: 5, batch: 157, loss: 0.995, acc: 0.60\n","epoch: 5, batch: 158, loss: 1.089, acc: 0.66\n","epoch: 5, batch: 159, loss: 1.153, acc: 0.58\n","epoch: 5, batch: 160, loss: 0.992, acc: 0.73\n","epoch: 5, batch: 161, loss: 1.142, acc: 0.60\n","epoch: 5, batch: 162, loss: 1.197, acc: 0.55\n","epoch: 5, batch: 163, loss: 1.101, acc: 0.59\n","epoch: 5, batch: 164, loss: 1.073, acc: 0.63\n","epoch: 5, batch: 165, loss: 1.201, acc: 0.62\n","epoch: 5, batch: 166, loss: 1.096, acc: 0.66\n","epoch: 5, batch: 167, loss: 1.028, acc: 0.70\n","epoch: 5, batch: 168, loss: 1.151, acc: 0.59\n","epoch: 5, batch: 169, loss: 1.085, acc: 0.61\n","epoch: 5, batch: 170, loss: 1.123, acc: 0.62\n","epoch: 5, batch: 171, loss: 1.080, acc: 0.56\n","epoch: 5, batch: 172, loss: 1.094, acc: 0.60\n","epoch: 5, batch: 173, loss: 1.132, acc: 0.58\n","epoch: 5, batch: 174, loss: 1.093, acc: 0.57\n","epoch: 5, batch: 175, loss: 1.079, acc: 0.66\n","epoch: 5, batch: 176, loss: 1.020, acc: 0.60\n","epoch: 5, batch: 177, loss: 0.962, acc: 0.69\n","epoch: 5, batch: 178, loss: 1.027, acc: 0.59\n","epoch: 5, batch: 179, loss: 1.153, acc: 0.60\n","epoch: 5, batch: 180, loss: 1.033, acc: 0.66\n","epoch: 5, batch: 181, loss: 1.013, acc: 0.70\n","epoch: 5, batch: 182, loss: 1.118, acc: 0.57\n","epoch: 5, batch: 183, loss: 0.972, acc: 0.63\n","epoch: 5, batch: 184, loss: 1.146, acc: 0.58\n","epoch: 5, batch: 185, loss: 0.918, acc: 0.66\n","epoch: 5, batch: 186, loss: 1.189, acc: 0.59\n","epoch: 5, batch: 187, loss: 1.143, acc: 0.63\n","epoch: 5, batch: 188, loss: 1.024, acc: 0.64\n","epoch: 5, batch: 189, loss: 1.244, acc: 0.56\n","epoch: 5, batch: 190, loss: 1.078, acc: 0.61\n","epoch: 5, batch: 191, loss: 1.079, acc: 0.62\n","epoch: 5, batch: 192, loss: 1.039, acc: 0.63\n","epoch: 5, batch: 193, loss: 1.055, acc: 0.66\n","epoch: 5, batch: 194, loss: 1.003, acc: 0.68\n","epoch: 5, batch: 195, loss: 0.957, acc: 0.67\n","epoch: 5, batch: 196, loss: 1.050, acc: 0.65\n","epoch: 5, batch: 197, loss: 1.102, acc: 0.59\n","epoch: 5, batch: 198, loss: 1.178, acc: 0.58\n","epoch: 5, batch: 199, loss: 0.954, acc: 0.70\n","epoch: 5, batch: 200, loss: 1.207, acc: 0.55\n","epoch: 5, batch: 201, loss: 0.979, acc: 0.65\n","epoch: 5, batch: 202, loss: 1.177, acc: 0.63\n","epoch: 5, batch: 203, loss: 0.961, acc: 0.62\n","epoch: 5, batch: 204, loss: 1.070, acc: 0.64\n","epoch: 5, batch: 205, loss: 0.926, acc: 0.66\n","epoch: 5, batch: 206, loss: 1.087, acc: 0.62\n","epoch: 5, batch: 207, loss: 1.029, acc: 0.65\n","epoch: 5, batch: 208, loss: 1.116, acc: 0.62\n","epoch: 5, batch: 209, loss: 0.950, acc: 0.66\n","epoch: 5, batch: 210, loss: 0.837, acc: 0.70\n","epoch: 5, batch: 211, loss: 1.018, acc: 0.64\n","epoch: 5, batch: 212, loss: 1.183, acc: 0.61\n","epoch: 5, batch: 213, loss: 1.053, acc: 0.64\n","epoch: 5, batch: 214, loss: 0.974, acc: 0.64\n","epoch: 5, batch: 215, loss: 0.941, acc: 0.69\n","epoch: 5, batch: 216, loss: 0.984, acc: 0.63\n","epoch: 5, batch: 217, loss: 0.967, acc: 0.62\n","epoch: 5, batch: 218, loss: 1.061, acc: 0.63\n","epoch: 5, batch: 219, loss: 1.205, acc: 0.60\n","epoch: 5, batch: 220, loss: 0.996, acc: 0.66\n","epoch: 5, batch: 221, loss: 0.987, acc: 0.65\n","epoch: 5, batch: 222, loss: 0.961, acc: 0.69\n","epoch: 5, batch: 223, loss: 1.049, acc: 0.66\n","epoch: 5, batch: 224, loss: 1.114, acc: 0.57\n","epoch: 5, batch: 225, loss: 1.028, acc: 0.65\n","epoch: 5, batch: 226, loss: 1.006, acc: 0.64\n","epoch: 5, batch: 227, loss: 1.120, acc: 0.61\n","epoch: 5, batch: 228, loss: 1.055, acc: 0.65\n","epoch: 5, batch: 229, loss: 1.215, acc: 0.59\n","epoch: 5, batch: 230, loss: 1.027, acc: 0.59\n","epoch: 5, batch: 231, loss: 0.985, acc: 0.62\n","epoch: 5, batch: 232, loss: 0.907, acc: 0.68\n","epoch: 5, batch: 233, loss: 0.955, acc: 0.64\n","epoch: 5, batch: 234, loss: 0.921, acc: 0.72\n","epoch: 5, batch: 235, loss: 1.089, acc: 0.62\n","epoch: 5, batch: 236, loss: 0.913, acc: 0.70\n","epoch: 5, batch: 237, loss: 1.098, acc: 0.62\n","epoch: 5, batch: 238, loss: 0.870, acc: 0.65\n","epoch: 5, batch: 239, loss: 0.942, acc: 0.70\n","epoch: 5, batch: 240, loss: 1.026, acc: 0.67\n","epoch: 5, batch: 241, loss: 0.908, acc: 0.67\n","epoch: 5, batch: 242, loss: 1.020, acc: 0.63\n","epoch: 5, batch: 243, loss: 0.928, acc: 0.68\n","epoch: 5, batch: 244, loss: 1.071, acc: 0.62\n","epoch: 5, batch: 245, loss: 1.137, acc: 0.60\n","epoch: 5, batch: 246, loss: 1.102, acc: 0.56\n","epoch: 5, batch: 247, loss: 1.078, acc: 0.64\n","epoch: 5, batch: 248, loss: 1.005, acc: 0.63\n","epoch: 5, batch: 249, loss: 1.069, acc: 0.63\n","epoch: 5, batch: 250, loss: 1.039, acc: 0.62\n","epoch: 5, batch: 251, loss: 1.146, acc: 0.57\n","epoch: 5, batch: 252, loss: 1.040, acc: 0.63\n","epoch: 5, batch: 253, loss: 1.011, acc: 0.63\n","epoch: 5, batch: 254, loss: 1.093, acc: 0.57\n","epoch: 5, batch: 255, loss: 1.064, acc: 0.59\n","epoch: 5, batch: 256, loss: 0.968, acc: 0.61\n","epoch: 5, batch: 257, loss: 0.934, acc: 0.71\n","epoch: 5, batch: 258, loss: 0.968, acc: 0.69\n","epoch: 5, batch: 259, loss: 1.084, acc: 0.63\n","epoch: 5, batch: 260, loss: 1.080, acc: 0.66\n","epoch: 5, batch: 261, loss: 1.048, acc: 0.64\n","epoch: 5, batch: 262, loss: 0.966, acc: 0.64\n","epoch: 5, batch: 263, loss: 0.981, acc: 0.61\n","epoch: 5, batch: 264, loss: 0.927, acc: 0.68\n","epoch: 5, batch: 265, loss: 1.080, acc: 0.59\n","epoch: 5, batch: 266, loss: 1.048, acc: 0.74\n","epoch: 5, batch: 267, loss: 1.049, acc: 0.69\n","epoch: 5, batch: 268, loss: 1.001, acc: 0.65\n","epoch: 5, batch: 269, loss: 0.932, acc: 0.66\n","epoch: 5, batch: 270, loss: 1.130, acc: 0.60\n","epoch: 5, batch: 271, loss: 1.070, acc: 0.60\n","epoch: 5, batch: 272, loss: 1.005, acc: 0.64\n","epoch: 5, batch: 273, loss: 0.897, acc: 0.66\n","epoch: 5, batch: 274, loss: 0.931, acc: 0.69\n","epoch: 5, batch: 275, loss: 1.062, acc: 0.64\n","epoch: 5, batch: 276, loss: 0.993, acc: 0.60\n","epoch: 5, batch: 277, loss: 1.026, acc: 0.64\n","epoch: 5, batch: 278, loss: 1.035, acc: 0.66\n","epoch: 5, batch: 279, loss: 1.021, acc: 0.61\n","epoch: 5, batch: 280, loss: 1.085, acc: 0.62\n","epoch: 5, batch: 281, loss: 0.900, acc: 0.72\n","epoch: 5, batch: 282, loss: 1.036, acc: 0.67\n","epoch: 5, batch: 283, loss: 1.096, acc: 0.66\n","epoch: 5, batch: 284, loss: 1.007, acc: 0.63\n","epoch: 5, batch: 285, loss: 1.121, acc: 0.57\n","epoch: 5, batch: 286, loss: 0.885, acc: 0.68\n","epoch: 5, batch: 287, loss: 0.887, acc: 0.71\n","epoch: 5, batch: 288, loss: 1.104, acc: 0.59\n","epoch: 5, batch: 289, loss: 1.049, acc: 0.63\n","epoch: 5, batch: 290, loss: 1.099, acc: 0.61\n","epoch: 5, batch: 291, loss: 1.171, acc: 0.63\n","epoch: 5, batch: 292, loss: 1.195, acc: 0.55\n","epoch: 5, batch: 293, loss: 0.901, acc: 0.68\n","epoch: 5, batch: 294, loss: 1.022, acc: 0.61\n","epoch: 5, batch: 295, loss: 0.845, acc: 0.66\n","epoch: 5, batch: 296, loss: 0.940, acc: 0.66\n","epoch: 5, batch: 297, loss: 1.036, acc: 0.62\n","epoch: 5, batch: 298, loss: 1.058, acc: 0.62\n","epoch: 5, batch: 299, loss: 1.086, acc: 0.62\n","epoch: 5, batch: 300, loss: 1.184, acc: 0.55\n","epoch: 5, batch: 301, loss: 1.108, acc: 0.59\n","epoch: 5, batch: 302, loss: 1.119, acc: 0.57\n","epoch: 5, batch: 303, loss: 1.031, acc: 0.66\n","epoch: 5, batch: 304, loss: 1.002, acc: 0.62\n","epoch: 5, batch: 305, loss: 1.117, acc: 0.66\n","epoch: 5, batch: 306, loss: 1.251, acc: 0.55\n","epoch: 5, batch: 307, loss: 0.941, acc: 0.70\n","epoch: 5, batch: 308, loss: 0.883, acc: 0.68\n","epoch: 5, batch: 309, loss: 0.883, acc: 0.69\n","epoch: 5, batch: 310, loss: 0.894, acc: 0.70\n","epoch: 5, batch: 311, loss: 1.007, acc: 0.63\n","epoch: 5, batch: 312, loss: 0.962, acc: 0.64\n","epoch: 5, batch: 313, loss: 1.112, acc: 0.64\n","epoch: 5, batch: 314, loss: 1.000, acc: 0.63\n","epoch: 5, batch: 315, loss: 1.035, acc: 0.64\n","epoch: 5, batch: 316, loss: 0.931, acc: 0.65\n","epoch: 5, batch: 317, loss: 0.981, acc: 0.70\n","epoch: 5, batch: 318, loss: 1.114, acc: 0.62\n","epoch: 5, batch: 319, loss: 1.072, acc: 0.65\n","epoch: 5, batch: 320, loss: 1.025, acc: 0.61\n","epoch: 5, batch: 321, loss: 1.120, acc: 0.60\n","epoch: 5, batch: 322, loss: 0.966, acc: 0.62\n","epoch: 5, batch: 323, loss: 1.165, acc: 0.60\n","epoch: 5, batch: 324, loss: 0.995, acc: 0.66\n","epoch: 5, batch: 325, loss: 1.117, acc: 0.62\n","epoch: 5, batch: 326, loss: 0.931, acc: 0.66\n","epoch: 5, batch: 327, loss: 1.186, acc: 0.61\n","epoch: 5, batch: 328, loss: 0.974, acc: 0.67\n","epoch: 5, batch: 329, loss: 0.980, acc: 0.67\n","epoch: 5, batch: 330, loss: 1.040, acc: 0.61\n","epoch: 5, batch: 331, loss: 1.050, acc: 0.62\n","epoch: 5, batch: 332, loss: 0.984, acc: 0.68\n","epoch: 5, batch: 333, loss: 0.995, acc: 0.62\n","epoch: 5, batch: 334, loss: 1.059, acc: 0.63\n","epoch: 5, batch: 335, loss: 1.081, acc: 0.66\n","epoch: 5, batch: 336, loss: 0.985, acc: 0.66\n","epoch: 5, batch: 337, loss: 0.940, acc: 0.66\n","epoch: 5, batch: 338, loss: 0.986, acc: 0.66\n","epoch: 5, batch: 339, loss: 1.011, acc: 0.66\n","epoch: 5, batch: 340, loss: 1.116, acc: 0.62\n","epoch: 5, batch: 341, loss: 1.200, acc: 0.60\n","epoch: 5, batch: 342, loss: 1.031, acc: 0.62\n","epoch: 5, batch: 343, loss: 1.061, acc: 0.66\n","epoch: 5, batch: 344, loss: 0.926, acc: 0.66\n","epoch: 5, batch: 345, loss: 1.088, acc: 0.65\n","epoch: 5, batch: 346, loss: 1.053, acc: 0.60\n","epoch: 5, batch: 347, loss: 1.173, acc: 0.62\n","epoch: 5, batch: 348, loss: 0.893, acc: 0.68\n","epoch: 5, batch: 349, loss: 1.091, acc: 0.57\n","epoch: 5, batch: 350, loss: 1.169, acc: 0.59\n","epoch: 5, batch: 351, loss: 1.008, acc: 0.66\n","epoch: 5, batch: 352, loss: 1.182, acc: 0.61\n","epoch: 5, batch: 353, loss: 1.000, acc: 0.59\n","epoch: 5, batch: 354, loss: 1.001, acc: 0.62\n","epoch: 5, batch: 355, loss: 1.044, acc: 0.62\n","epoch: 5, batch: 356, loss: 1.192, acc: 0.59\n","epoch: 5, batch: 357, loss: 1.041, acc: 0.62\n","epoch: 5, batch: 358, loss: 1.044, acc: 0.62\n","epoch: 5, batch: 359, loss: 1.000, acc: 0.66\n","epoch: 5, batch: 360, loss: 0.945, acc: 0.71\n","epoch: 5, batch: 361, loss: 0.814, acc: 0.74\n","epoch: 5, batch: 362, loss: 1.017, acc: 0.60\n","epoch: 5, batch: 363, loss: 1.065, acc: 0.61\n","epoch: 5, batch: 364, loss: 1.039, acc: 0.59\n","epoch: 5, batch: 365, loss: 1.096, acc: 0.64\n","epoch: 5, batch: 366, loss: 1.191, acc: 0.63\n","epoch: 5, batch: 367, loss: 1.116, acc: 0.67\n","epoch: 5, batch: 368, loss: 0.960, acc: 0.66\n","epoch: 5, batch: 369, loss: 1.081, acc: 0.63\n","epoch: 5, batch: 370, loss: 1.255, acc: 0.56\n","epoch: 5, batch: 371, loss: 0.930, acc: 0.66\n","epoch: 5, batch: 372, loss: 0.972, acc: 0.67\n","epoch: 5, batch: 373, loss: 0.865, acc: 0.72\n","epoch: 5, batch: 374, loss: 0.933, acc: 0.70\n","epoch: 5, batch: 375, loss: 0.925, acc: 0.69\n","epoch: 5, batch: 376, loss: 1.166, acc: 0.54\n","epoch: 5, batch: 377, loss: 0.960, acc: 0.63\n","epoch: 5, batch: 378, loss: 0.837, acc: 0.71\n","epoch: 5, batch: 379, loss: 0.843, acc: 0.73\n","epoch: 5, batch: 380, loss: 1.062, acc: 0.66\n","epoch: 5, batch: 381, loss: 0.928, acc: 0.67\n","epoch: 5, batch: 382, loss: 1.102, acc: 0.61\n","epoch: 5, batch: 383, loss: 0.943, acc: 0.73\n","epoch: 5, batch: 384, loss: 1.044, acc: 0.70\n","epoch: 5, batch: 385, loss: 1.030, acc: 0.64\n","epoch: 5, batch: 386, loss: 1.173, acc: 0.62\n","epoch: 5, batch: 387, loss: 0.863, acc: 0.70\n","epoch: 5, batch: 388, loss: 0.981, acc: 0.66\n","epoch: 5, batch: 389, loss: 0.909, acc: 0.67\n","epoch: 5, batch: 390, loss: 1.007, acc: 0.65\n","epoch: 5, batch: 391, loss: 1.085, acc: 0.59\n","epoch: 6, batch: 1, loss: 1.054, acc: 0.57\n","epoch: 6, batch: 2, loss: 1.035, acc: 0.65\n","epoch: 6, batch: 3, loss: 1.019, acc: 0.60\n","epoch: 6, batch: 4, loss: 1.209, acc: 0.56\n","epoch: 6, batch: 5, loss: 1.124, acc: 0.62\n","epoch: 6, batch: 6, loss: 1.111, acc: 0.59\n","epoch: 6, batch: 7, loss: 0.956, acc: 0.67\n","epoch: 6, batch: 8, loss: 1.039, acc: 0.60\n","epoch: 6, batch: 9, loss: 1.072, acc: 0.60\n","epoch: 6, batch: 10, loss: 1.081, acc: 0.67\n","epoch: 6, batch: 11, loss: 0.999, acc: 0.66\n","epoch: 6, batch: 12, loss: 0.964, acc: 0.65\n","epoch: 6, batch: 13, loss: 0.992, acc: 0.68\n","epoch: 6, batch: 14, loss: 1.047, acc: 0.67\n","epoch: 6, batch: 15, loss: 0.923, acc: 0.67\n","epoch: 6, batch: 16, loss: 0.886, acc: 0.70\n","epoch: 6, batch: 17, loss: 1.117, acc: 0.58\n","epoch: 6, batch: 18, loss: 1.139, acc: 0.62\n","epoch: 6, batch: 19, loss: 1.000, acc: 0.69\n","epoch: 6, batch: 20, loss: 0.895, acc: 0.70\n","epoch: 6, batch: 21, loss: 0.974, acc: 0.59\n","epoch: 6, batch: 22, loss: 0.926, acc: 0.66\n","epoch: 6, batch: 23, loss: 0.896, acc: 0.69\n","epoch: 6, batch: 24, loss: 0.888, acc: 0.70\n","epoch: 6, batch: 25, loss: 1.139, acc: 0.66\n","epoch: 6, batch: 26, loss: 0.999, acc: 0.69\n","epoch: 6, batch: 27, loss: 1.115, acc: 0.64\n","epoch: 6, batch: 28, loss: 1.038, acc: 0.62\n","epoch: 6, batch: 29, loss: 0.974, acc: 0.69\n","epoch: 6, batch: 30, loss: 0.850, acc: 0.71\n","epoch: 6, batch: 31, loss: 0.981, acc: 0.70\n","epoch: 6, batch: 32, loss: 0.882, acc: 0.66\n","epoch: 6, batch: 33, loss: 0.922, acc: 0.71\n","epoch: 6, batch: 34, loss: 0.985, acc: 0.66\n","epoch: 6, batch: 35, loss: 1.191, acc: 0.59\n","epoch: 6, batch: 36, loss: 0.998, acc: 0.66\n","epoch: 6, batch: 37, loss: 0.980, acc: 0.65\n","epoch: 6, batch: 38, loss: 1.032, acc: 0.63\n","epoch: 6, batch: 39, loss: 1.075, acc: 0.67\n","epoch: 6, batch: 40, loss: 1.112, acc: 0.62\n","epoch: 6, batch: 41, loss: 1.041, acc: 0.67\n","epoch: 6, batch: 42, loss: 1.000, acc: 0.62\n","epoch: 6, batch: 43, loss: 1.129, acc: 0.64\n","epoch: 6, batch: 44, loss: 1.029, acc: 0.66\n","epoch: 6, batch: 45, loss: 1.036, acc: 0.59\n","epoch: 6, batch: 46, loss: 0.917, acc: 0.72\n","epoch: 6, batch: 47, loss: 0.891, acc: 0.69\n","epoch: 6, batch: 48, loss: 1.047, acc: 0.66\n","epoch: 6, batch: 49, loss: 1.113, acc: 0.60\n","epoch: 6, batch: 50, loss: 1.086, acc: 0.62\n","epoch: 6, batch: 51, loss: 1.036, acc: 0.63\n","epoch: 6, batch: 52, loss: 0.861, acc: 0.67\n","epoch: 6, batch: 53, loss: 1.050, acc: 0.60\n","epoch: 6, batch: 54, loss: 0.992, acc: 0.68\n","epoch: 6, batch: 55, loss: 1.189, acc: 0.59\n","epoch: 6, batch: 56, loss: 1.066, acc: 0.66\n","epoch: 6, batch: 57, loss: 0.862, acc: 0.70\n","epoch: 6, batch: 58, loss: 0.848, acc: 0.71\n","epoch: 6, batch: 59, loss: 1.243, acc: 0.58\n","epoch: 6, batch: 60, loss: 0.903, acc: 0.66\n","epoch: 6, batch: 61, loss: 0.909, acc: 0.69\n","epoch: 6, batch: 62, loss: 1.181, acc: 0.62\n","epoch: 6, batch: 63, loss: 1.129, acc: 0.63\n","epoch: 6, batch: 64, loss: 0.939, acc: 0.64\n","epoch: 6, batch: 65, loss: 0.856, acc: 0.69\n","epoch: 6, batch: 66, loss: 1.152, acc: 0.62\n","epoch: 6, batch: 67, loss: 0.911, acc: 0.67\n","epoch: 6, batch: 68, loss: 1.111, acc: 0.59\n","epoch: 6, batch: 69, loss: 1.062, acc: 0.67\n","epoch: 6, batch: 70, loss: 1.297, acc: 0.57\n","epoch: 6, batch: 71, loss: 1.046, acc: 0.62\n","epoch: 6, batch: 72, loss: 1.030, acc: 0.62\n","epoch: 6, batch: 73, loss: 0.892, acc: 0.68\n","epoch: 6, batch: 74, loss: 0.949, acc: 0.63\n","epoch: 6, batch: 75, loss: 1.047, acc: 0.67\n","epoch: 6, batch: 76, loss: 0.912, acc: 0.67\n","epoch: 6, batch: 77, loss: 0.988, acc: 0.68\n","epoch: 6, batch: 78, loss: 1.125, acc: 0.58\n","epoch: 6, batch: 79, loss: 0.815, acc: 0.77\n","epoch: 6, batch: 80, loss: 1.114, acc: 0.64\n","epoch: 6, batch: 81, loss: 1.047, acc: 0.70\n","epoch: 6, batch: 82, loss: 1.039, acc: 0.68\n","epoch: 6, batch: 83, loss: 1.067, acc: 0.66\n","epoch: 6, batch: 84, loss: 0.986, acc: 0.64\n","epoch: 6, batch: 85, loss: 1.127, acc: 0.65\n","epoch: 6, batch: 86, loss: 1.044, acc: 0.70\n","epoch: 6, batch: 87, loss: 0.962, acc: 0.66\n","epoch: 6, batch: 88, loss: 0.905, acc: 0.71\n","epoch: 6, batch: 89, loss: 0.919, acc: 0.72\n","epoch: 6, batch: 90, loss: 0.945, acc: 0.73\n","epoch: 6, batch: 91, loss: 1.063, acc: 0.68\n","epoch: 6, batch: 92, loss: 0.821, acc: 0.74\n","epoch: 6, batch: 93, loss: 1.196, acc: 0.64\n","epoch: 6, batch: 94, loss: 1.088, acc: 0.63\n","epoch: 6, batch: 95, loss: 0.907, acc: 0.69\n","epoch: 6, batch: 96, loss: 0.962, acc: 0.67\n","epoch: 6, batch: 97, loss: 1.191, acc: 0.64\n","epoch: 6, batch: 98, loss: 0.939, acc: 0.66\n","epoch: 6, batch: 99, loss: 0.954, acc: 0.69\n","epoch: 6, batch: 100, loss: 1.111, acc: 0.62\n","epoch: 6, batch: 101, loss: 1.031, acc: 0.64\n","epoch: 6, batch: 102, loss: 1.149, acc: 0.62\n","epoch: 6, batch: 103, loss: 1.043, acc: 0.65\n","epoch: 6, batch: 104, loss: 1.125, acc: 0.59\n","epoch: 6, batch: 105, loss: 0.982, acc: 0.65\n","epoch: 6, batch: 106, loss: 1.009, acc: 0.62\n","epoch: 6, batch: 107, loss: 1.114, acc: 0.66\n","epoch: 6, batch: 108, loss: 0.946, acc: 0.66\n","epoch: 6, batch: 109, loss: 1.030, acc: 0.65\n","epoch: 6, batch: 110, loss: 0.966, acc: 0.68\n","epoch: 6, batch: 111, loss: 0.966, acc: 0.68\n","epoch: 6, batch: 112, loss: 1.002, acc: 0.65\n","epoch: 6, batch: 113, loss: 1.053, acc: 0.66\n","epoch: 6, batch: 114, loss: 1.145, acc: 0.66\n","epoch: 6, batch: 115, loss: 0.936, acc: 0.73\n","epoch: 6, batch: 116, loss: 0.952, acc: 0.68\n","epoch: 6, batch: 117, loss: 1.107, acc: 0.65\n","epoch: 6, batch: 118, loss: 1.014, acc: 0.67\n","epoch: 6, batch: 119, loss: 0.917, acc: 0.68\n","epoch: 6, batch: 120, loss: 0.913, acc: 0.74\n","epoch: 6, batch: 121, loss: 0.989, acc: 0.64\n","epoch: 6, batch: 122, loss: 0.968, acc: 0.64\n","epoch: 6, batch: 123, loss: 1.075, acc: 0.64\n","epoch: 6, batch: 124, loss: 0.955, acc: 0.68\n","epoch: 6, batch: 125, loss: 0.949, acc: 0.66\n","epoch: 6, batch: 126, loss: 0.904, acc: 0.66\n","epoch: 6, batch: 127, loss: 1.154, acc: 0.55\n","epoch: 6, batch: 128, loss: 1.112, acc: 0.64\n","epoch: 6, batch: 129, loss: 1.216, acc: 0.58\n","epoch: 6, batch: 130, loss: 1.072, acc: 0.63\n","epoch: 6, batch: 131, loss: 1.064, acc: 0.58\n","epoch: 6, batch: 132, loss: 0.977, acc: 0.64\n","epoch: 6, batch: 133, loss: 0.995, acc: 0.68\n","epoch: 6, batch: 134, loss: 0.819, acc: 0.71\n","epoch: 6, batch: 135, loss: 0.980, acc: 0.66\n","epoch: 6, batch: 136, loss: 1.207, acc: 0.62\n","epoch: 6, batch: 137, loss: 1.065, acc: 0.66\n","epoch: 6, batch: 138, loss: 0.902, acc: 0.73\n","epoch: 6, batch: 139, loss: 1.023, acc: 0.64\n","epoch: 6, batch: 140, loss: 1.010, acc: 0.65\n","epoch: 6, batch: 141, loss: 1.116, acc: 0.60\n","epoch: 6, batch: 142, loss: 1.087, acc: 0.59\n","epoch: 6, batch: 143, loss: 0.898, acc: 0.66\n","epoch: 6, batch: 144, loss: 1.067, acc: 0.62\n","epoch: 6, batch: 145, loss: 1.012, acc: 0.64\n","epoch: 6, batch: 146, loss: 0.992, acc: 0.62\n","epoch: 6, batch: 147, loss: 0.922, acc: 0.70\n","epoch: 6, batch: 148, loss: 1.111, acc: 0.66\n","epoch: 6, batch: 149, loss: 0.853, acc: 0.73\n","epoch: 6, batch: 150, loss: 1.033, acc: 0.66\n","epoch: 6, batch: 151, loss: 0.968, acc: 0.65\n","epoch: 6, batch: 152, loss: 1.144, acc: 0.64\n","epoch: 6, batch: 153, loss: 1.050, acc: 0.61\n","epoch: 6, batch: 154, loss: 0.962, acc: 0.66\n","epoch: 6, batch: 155, loss: 0.976, acc: 0.69\n","epoch: 6, batch: 156, loss: 1.130, acc: 0.62\n","epoch: 6, batch: 157, loss: 1.119, acc: 0.59\n","epoch: 6, batch: 158, loss: 1.063, acc: 0.62\n","epoch: 6, batch: 159, loss: 0.890, acc: 0.76\n","epoch: 6, batch: 160, loss: 0.947, acc: 0.68\n","epoch: 6, batch: 161, loss: 1.125, acc: 0.61\n","epoch: 6, batch: 162, loss: 1.007, acc: 0.66\n","epoch: 6, batch: 163, loss: 0.894, acc: 0.73\n","epoch: 6, batch: 164, loss: 1.216, acc: 0.57\n","epoch: 6, batch: 165, loss: 0.995, acc: 0.64\n","epoch: 6, batch: 166, loss: 1.056, acc: 0.65\n","epoch: 6, batch: 167, loss: 0.956, acc: 0.66\n","epoch: 6, batch: 168, loss: 0.979, acc: 0.65\n","epoch: 6, batch: 169, loss: 0.845, acc: 0.68\n","epoch: 6, batch: 170, loss: 1.060, acc: 0.67\n","epoch: 6, batch: 171, loss: 0.995, acc: 0.66\n","epoch: 6, batch: 172, loss: 0.892, acc: 0.70\n","epoch: 6, batch: 173, loss: 0.866, acc: 0.71\n","epoch: 6, batch: 174, loss: 1.214, acc: 0.63\n","epoch: 6, batch: 175, loss: 1.118, acc: 0.61\n","epoch: 6, batch: 176, loss: 1.048, acc: 0.62\n","epoch: 6, batch: 177, loss: 1.063, acc: 0.60\n","epoch: 6, batch: 178, loss: 0.936, acc: 0.68\n","epoch: 6, batch: 179, loss: 1.059, acc: 0.61\n","epoch: 6, batch: 180, loss: 0.980, acc: 0.64\n","epoch: 6, batch: 181, loss: 1.024, acc: 0.63\n","epoch: 6, batch: 182, loss: 1.087, acc: 0.66\n","epoch: 6, batch: 183, loss: 0.954, acc: 0.64\n","epoch: 6, batch: 184, loss: 1.032, acc: 0.62\n","epoch: 6, batch: 185, loss: 0.930, acc: 0.65\n","epoch: 6, batch: 186, loss: 1.060, acc: 0.62\n","epoch: 6, batch: 187, loss: 0.933, acc: 0.69\n","epoch: 6, batch: 188, loss: 0.987, acc: 0.62\n","epoch: 6, batch: 189, loss: 0.937, acc: 0.68\n","epoch: 6, batch: 190, loss: 1.047, acc: 0.65\n","epoch: 6, batch: 191, loss: 0.897, acc: 0.64\n","epoch: 6, batch: 192, loss: 1.066, acc: 0.66\n","epoch: 6, batch: 193, loss: 0.973, acc: 0.70\n","epoch: 6, batch: 194, loss: 0.998, acc: 0.63\n","epoch: 6, batch: 195, loss: 0.810, acc: 0.72\n","epoch: 6, batch: 196, loss: 1.047, acc: 0.59\n","epoch: 6, batch: 197, loss: 1.072, acc: 0.65\n","epoch: 6, batch: 198, loss: 1.095, acc: 0.62\n","epoch: 6, batch: 199, loss: 0.770, acc: 0.74\n","epoch: 6, batch: 200, loss: 1.087, acc: 0.66\n","epoch: 6, batch: 201, loss: 1.061, acc: 0.62\n","epoch: 6, batch: 202, loss: 1.035, acc: 0.64\n","epoch: 6, batch: 203, loss: 1.022, acc: 0.64\n","epoch: 6, batch: 204, loss: 0.957, acc: 0.68\n","epoch: 6, batch: 205, loss: 0.912, acc: 0.67\n","epoch: 6, batch: 206, loss: 1.026, acc: 0.62\n","epoch: 6, batch: 207, loss: 1.080, acc: 0.62\n","epoch: 6, batch: 208, loss: 0.924, acc: 0.66\n","epoch: 6, batch: 209, loss: 1.022, acc: 0.66\n","epoch: 6, batch: 210, loss: 0.953, acc: 0.63\n","epoch: 6, batch: 211, loss: 0.947, acc: 0.68\n","epoch: 6, batch: 212, loss: 1.039, acc: 0.69\n","epoch: 6, batch: 213, loss: 1.002, acc: 0.66\n","epoch: 6, batch: 214, loss: 0.906, acc: 0.66\n","epoch: 6, batch: 215, loss: 1.070, acc: 0.62\n","epoch: 6, batch: 216, loss: 0.835, acc: 0.73\n","epoch: 6, batch: 217, loss: 1.030, acc: 0.67\n","epoch: 6, batch: 218, loss: 0.999, acc: 0.64\n","epoch: 6, batch: 219, loss: 0.967, acc: 0.65\n","epoch: 6, batch: 220, loss: 1.014, acc: 0.66\n","epoch: 6, batch: 221, loss: 1.065, acc: 0.63\n","epoch: 6, batch: 222, loss: 0.855, acc: 0.69\n","epoch: 6, batch: 223, loss: 1.056, acc: 0.68\n","epoch: 6, batch: 224, loss: 1.044, acc: 0.62\n","epoch: 6, batch: 225, loss: 0.878, acc: 0.71\n","epoch: 6, batch: 226, loss: 1.053, acc: 0.62\n","epoch: 6, batch: 227, loss: 1.011, acc: 0.66\n","epoch: 6, batch: 228, loss: 0.855, acc: 0.72\n","epoch: 6, batch: 229, loss: 0.957, acc: 0.67\n","epoch: 6, batch: 230, loss: 1.057, acc: 0.66\n","epoch: 6, batch: 231, loss: 0.820, acc: 0.70\n","epoch: 6, batch: 232, loss: 0.911, acc: 0.67\n","epoch: 6, batch: 233, loss: 0.996, acc: 0.69\n","epoch: 6, batch: 234, loss: 0.927, acc: 0.67\n","epoch: 6, batch: 235, loss: 0.833, acc: 0.73\n","epoch: 6, batch: 236, loss: 0.843, acc: 0.70\n","epoch: 6, batch: 237, loss: 1.066, acc: 0.64\n","epoch: 6, batch: 238, loss: 0.947, acc: 0.70\n","epoch: 6, batch: 239, loss: 0.851, acc: 0.70\n","epoch: 6, batch: 240, loss: 0.789, acc: 0.70\n","epoch: 6, batch: 241, loss: 0.927, acc: 0.67\n","epoch: 6, batch: 242, loss: 0.937, acc: 0.66\n","epoch: 6, batch: 243, loss: 0.981, acc: 0.67\n","epoch: 6, batch: 244, loss: 0.959, acc: 0.64\n","epoch: 6, batch: 245, loss: 0.982, acc: 0.65\n","epoch: 6, batch: 246, loss: 0.888, acc: 0.63\n","epoch: 6, batch: 247, loss: 1.112, acc: 0.59\n","epoch: 6, batch: 248, loss: 1.044, acc: 0.60\n","epoch: 6, batch: 249, loss: 0.863, acc: 0.73\n","epoch: 6, batch: 250, loss: 1.239, acc: 0.52\n","epoch: 6, batch: 251, loss: 1.123, acc: 0.57\n","epoch: 6, batch: 252, loss: 0.927, acc: 0.73\n","epoch: 6, batch: 253, loss: 0.883, acc: 0.66\n","epoch: 6, batch: 254, loss: 0.971, acc: 0.68\n","epoch: 6, batch: 255, loss: 1.039, acc: 0.59\n","epoch: 6, batch: 256, loss: 0.859, acc: 0.72\n","epoch: 6, batch: 257, loss: 0.904, acc: 0.67\n","epoch: 6, batch: 258, loss: 0.875, acc: 0.71\n","epoch: 6, batch: 259, loss: 1.009, acc: 0.66\n","epoch: 6, batch: 260, loss: 0.990, acc: 0.62\n","epoch: 6, batch: 261, loss: 1.050, acc: 0.63\n","epoch: 6, batch: 262, loss: 0.915, acc: 0.65\n","epoch: 6, batch: 263, loss: 1.110, acc: 0.62\n","epoch: 6, batch: 264, loss: 0.964, acc: 0.70\n","epoch: 6, batch: 265, loss: 1.220, acc: 0.58\n","epoch: 6, batch: 266, loss: 0.937, acc: 0.63\n","epoch: 6, batch: 267, loss: 0.955, acc: 0.70\n","epoch: 6, batch: 268, loss: 0.933, acc: 0.70\n","epoch: 6, batch: 269, loss: 1.102, acc: 0.61\n","epoch: 6, batch: 270, loss: 0.979, acc: 0.65\n","epoch: 6, batch: 271, loss: 0.823, acc: 0.72\n","epoch: 6, batch: 272, loss: 0.936, acc: 0.70\n","epoch: 6, batch: 273, loss: 0.903, acc: 0.70\n","epoch: 6, batch: 274, loss: 0.958, acc: 0.65\n","epoch: 6, batch: 275, loss: 0.962, acc: 0.65\n","epoch: 6, batch: 276, loss: 0.904, acc: 0.68\n","epoch: 6, batch: 277, loss: 0.971, acc: 0.68\n","epoch: 6, batch: 278, loss: 0.960, acc: 0.68\n","epoch: 6, batch: 279, loss: 0.982, acc: 0.69\n","epoch: 6, batch: 280, loss: 0.928, acc: 0.70\n","epoch: 6, batch: 281, loss: 0.918, acc: 0.70\n","epoch: 6, batch: 282, loss: 1.025, acc: 0.60\n","epoch: 6, batch: 283, loss: 0.861, acc: 0.70\n","epoch: 6, batch: 284, loss: 0.959, acc: 0.66\n","epoch: 6, batch: 285, loss: 0.881, acc: 0.69\n","epoch: 6, batch: 286, loss: 1.074, acc: 0.62\n","epoch: 6, batch: 287, loss: 1.053, acc: 0.60\n","epoch: 6, batch: 288, loss: 1.183, acc: 0.59\n","epoch: 6, batch: 289, loss: 0.994, acc: 0.63\n","epoch: 6, batch: 290, loss: 1.171, acc: 0.60\n","epoch: 6, batch: 291, loss: 0.988, acc: 0.68\n","epoch: 6, batch: 292, loss: 1.014, acc: 0.65\n","epoch: 6, batch: 293, loss: 1.097, acc: 0.63\n","epoch: 6, batch: 294, loss: 1.107, acc: 0.66\n","epoch: 6, batch: 295, loss: 0.947, acc: 0.67\n","epoch: 6, batch: 296, loss: 0.981, acc: 0.66\n","epoch: 6, batch: 297, loss: 1.146, acc: 0.59\n","epoch: 6, batch: 298, loss: 0.931, acc: 0.66\n","epoch: 6, batch: 299, loss: 0.890, acc: 0.66\n","epoch: 6, batch: 300, loss: 1.030, acc: 0.59\n","epoch: 6, batch: 301, loss: 1.114, acc: 0.65\n","epoch: 6, batch: 302, loss: 0.894, acc: 0.70\n","epoch: 6, batch: 303, loss: 0.997, acc: 0.66\n","epoch: 6, batch: 304, loss: 0.854, acc: 0.73\n","epoch: 6, batch: 305, loss: 1.102, acc: 0.60\n","epoch: 6, batch: 306, loss: 0.964, acc: 0.65\n","epoch: 6, batch: 307, loss: 1.156, acc: 0.66\n","epoch: 6, batch: 308, loss: 0.938, acc: 0.67\n","epoch: 6, batch: 309, loss: 0.874, acc: 0.69\n","epoch: 6, batch: 310, loss: 0.999, acc: 0.66\n","epoch: 6, batch: 311, loss: 1.026, acc: 0.62\n","epoch: 6, batch: 312, loss: 0.941, acc: 0.73\n","epoch: 6, batch: 313, loss: 1.041, acc: 0.69\n","epoch: 6, batch: 314, loss: 0.726, acc: 0.73\n","epoch: 6, batch: 315, loss: 0.964, acc: 0.68\n","epoch: 6, batch: 316, loss: 1.086, acc: 0.61\n","epoch: 6, batch: 317, loss: 0.935, acc: 0.65\n","epoch: 6, batch: 318, loss: 0.979, acc: 0.65\n","epoch: 6, batch: 319, loss: 0.870, acc: 0.67\n","epoch: 6, batch: 320, loss: 0.988, acc: 0.67\n","epoch: 6, batch: 321, loss: 1.031, acc: 0.65\n","epoch: 6, batch: 322, loss: 0.809, acc: 0.72\n","epoch: 6, batch: 323, loss: 0.865, acc: 0.72\n","epoch: 6, batch: 324, loss: 0.984, acc: 0.66\n","epoch: 6, batch: 325, loss: 1.113, acc: 0.61\n","epoch: 6, batch: 326, loss: 0.941, acc: 0.73\n","epoch: 6, batch: 327, loss: 0.878, acc: 0.69\n","epoch: 6, batch: 328, loss: 1.034, acc: 0.62\n","epoch: 6, batch: 329, loss: 1.084, acc: 0.62\n","epoch: 6, batch: 330, loss: 1.110, acc: 0.63\n","epoch: 6, batch: 331, loss: 0.842, acc: 0.66\n","epoch: 6, batch: 332, loss: 0.989, acc: 0.66\n","epoch: 6, batch: 333, loss: 1.071, acc: 0.65\n","epoch: 6, batch: 334, loss: 1.135, acc: 0.62\n","epoch: 6, batch: 335, loss: 1.095, acc: 0.59\n","epoch: 6, batch: 336, loss: 1.011, acc: 0.68\n","epoch: 6, batch: 337, loss: 0.919, acc: 0.63\n","epoch: 6, batch: 338, loss: 0.878, acc: 0.70\n","epoch: 6, batch: 339, loss: 0.761, acc: 0.73\n","epoch: 6, batch: 340, loss: 0.987, acc: 0.70\n","epoch: 6, batch: 341, loss: 0.896, acc: 0.73\n","epoch: 6, batch: 342, loss: 1.003, acc: 0.67\n","epoch: 6, batch: 343, loss: 1.156, acc: 0.60\n","epoch: 6, batch: 344, loss: 1.142, acc: 0.57\n","epoch: 6, batch: 345, loss: 1.130, acc: 0.62\n","epoch: 6, batch: 346, loss: 0.945, acc: 0.66\n","epoch: 6, batch: 347, loss: 0.915, acc: 0.66\n","epoch: 6, batch: 348, loss: 0.946, acc: 0.66\n","epoch: 6, batch: 349, loss: 0.957, acc: 0.66\n","epoch: 6, batch: 350, loss: 1.047, acc: 0.62\n","epoch: 6, batch: 351, loss: 0.904, acc: 0.67\n","epoch: 6, batch: 352, loss: 1.166, acc: 0.59\n","epoch: 6, batch: 353, loss: 0.936, acc: 0.66\n","epoch: 6, batch: 354, loss: 0.925, acc: 0.67\n","epoch: 6, batch: 355, loss: 0.801, acc: 0.73\n","epoch: 6, batch: 356, loss: 1.071, acc: 0.62\n","epoch: 6, batch: 357, loss: 0.810, acc: 0.70\n","epoch: 6, batch: 358, loss: 1.021, acc: 0.66\n","epoch: 6, batch: 359, loss: 1.074, acc: 0.62\n","epoch: 6, batch: 360, loss: 1.145, acc: 0.59\n","epoch: 6, batch: 361, loss: 0.952, acc: 0.68\n","epoch: 6, batch: 362, loss: 1.115, acc: 0.61\n","epoch: 6, batch: 363, loss: 0.991, acc: 0.66\n","epoch: 6, batch: 364, loss: 0.872, acc: 0.70\n","epoch: 6, batch: 365, loss: 1.200, acc: 0.58\n","epoch: 6, batch: 366, loss: 0.985, acc: 0.64\n","epoch: 6, batch: 367, loss: 0.983, acc: 0.61\n","epoch: 6, batch: 368, loss: 0.916, acc: 0.66\n","epoch: 6, batch: 369, loss: 1.011, acc: 0.69\n","epoch: 6, batch: 370, loss: 0.972, acc: 0.63\n","epoch: 6, batch: 371, loss: 1.025, acc: 0.68\n","epoch: 6, batch: 372, loss: 1.102, acc: 0.61\n","epoch: 6, batch: 373, loss: 0.958, acc: 0.65\n","epoch: 6, batch: 374, loss: 1.046, acc: 0.64\n","epoch: 6, batch: 375, loss: 0.983, acc: 0.67\n","epoch: 6, batch: 376, loss: 0.987, acc: 0.68\n","epoch: 6, batch: 377, loss: 0.908, acc: 0.71\n","epoch: 6, batch: 378, loss: 0.902, acc: 0.66\n","epoch: 6, batch: 379, loss: 1.102, acc: 0.65\n","epoch: 6, batch: 380, loss: 0.947, acc: 0.66\n","epoch: 6, batch: 381, loss: 0.952, acc: 0.66\n","epoch: 6, batch: 382, loss: 0.896, acc: 0.71\n","epoch: 6, batch: 383, loss: 0.921, acc: 0.66\n","epoch: 6, batch: 384, loss: 0.957, acc: 0.70\n","epoch: 6, batch: 385, loss: 0.839, acc: 0.71\n","epoch: 6, batch: 386, loss: 0.975, acc: 0.67\n","epoch: 6, batch: 387, loss: 1.009, acc: 0.67\n","epoch: 6, batch: 388, loss: 0.925, acc: 0.66\n","epoch: 6, batch: 389, loss: 0.822, acc: 0.73\n","epoch: 6, batch: 390, loss: 0.932, acc: 0.65\n","epoch: 6, batch: 391, loss: 0.899, acc: 0.70\n","epoch: 7, batch: 1, loss: 0.996, acc: 0.62\n","epoch: 7, batch: 2, loss: 0.940, acc: 0.66\n","epoch: 7, batch: 3, loss: 1.045, acc: 0.66\n","epoch: 7, batch: 4, loss: 1.051, acc: 0.58\n","epoch: 7, batch: 5, loss: 0.978, acc: 0.65\n","epoch: 7, batch: 6, loss: 0.910, acc: 0.66\n","epoch: 7, batch: 7, loss: 0.978, acc: 0.69\n","epoch: 7, batch: 8, loss: 1.145, acc: 0.64\n","epoch: 7, batch: 9, loss: 1.035, acc: 0.66\n","epoch: 7, batch: 10, loss: 0.905, acc: 0.69\n","epoch: 7, batch: 11, loss: 0.763, acc: 0.76\n","epoch: 7, batch: 12, loss: 0.985, acc: 0.68\n","epoch: 7, batch: 13, loss: 1.079, acc: 0.59\n","epoch: 7, batch: 14, loss: 1.072, acc: 0.63\n","epoch: 7, batch: 15, loss: 1.104, acc: 0.62\n","epoch: 7, batch: 16, loss: 1.099, acc: 0.63\n","epoch: 7, batch: 17, loss: 1.028, acc: 0.64\n","epoch: 7, batch: 18, loss: 0.957, acc: 0.66\n","epoch: 7, batch: 19, loss: 0.974, acc: 0.64\n","epoch: 7, batch: 20, loss: 0.973, acc: 0.66\n","epoch: 7, batch: 21, loss: 0.964, acc: 0.66\n","epoch: 7, batch: 22, loss: 0.896, acc: 0.69\n","epoch: 7, batch: 23, loss: 0.954, acc: 0.69\n","epoch: 7, batch: 24, loss: 0.932, acc: 0.66\n","epoch: 7, batch: 25, loss: 1.104, acc: 0.62\n","epoch: 7, batch: 26, loss: 0.949, acc: 0.67\n","epoch: 7, batch: 27, loss: 1.071, acc: 0.68\n","epoch: 7, batch: 28, loss: 0.854, acc: 0.74\n","epoch: 7, batch: 29, loss: 0.862, acc: 0.73\n","epoch: 7, batch: 30, loss: 1.024, acc: 0.67\n","epoch: 7, batch: 31, loss: 0.837, acc: 0.72\n","epoch: 7, batch: 32, loss: 0.989, acc: 0.62\n","epoch: 7, batch: 33, loss: 0.855, acc: 0.71\n","epoch: 7, batch: 34, loss: 0.944, acc: 0.71\n","epoch: 7, batch: 35, loss: 0.890, acc: 0.67\n","epoch: 7, batch: 36, loss: 0.922, acc: 0.73\n","epoch: 7, batch: 37, loss: 0.996, acc: 0.64\n","epoch: 7, batch: 38, loss: 0.964, acc: 0.69\n","epoch: 7, batch: 39, loss: 1.204, acc: 0.60\n","epoch: 7, batch: 40, loss: 0.899, acc: 0.70\n","epoch: 7, batch: 41, loss: 1.107, acc: 0.62\n","epoch: 7, batch: 42, loss: 0.924, acc: 0.65\n","epoch: 7, batch: 43, loss: 0.793, acc: 0.71\n","epoch: 7, batch: 44, loss: 0.962, acc: 0.65\n","epoch: 7, batch: 45, loss: 1.112, acc: 0.59\n","epoch: 7, batch: 46, loss: 0.881, acc: 0.69\n","epoch: 7, batch: 47, loss: 0.874, acc: 0.68\n","epoch: 7, batch: 48, loss: 0.915, acc: 0.70\n","epoch: 7, batch: 49, loss: 0.920, acc: 0.71\n","epoch: 7, batch: 50, loss: 0.980, acc: 0.66\n","epoch: 7, batch: 51, loss: 1.061, acc: 0.60\n","epoch: 7, batch: 52, loss: 0.960, acc: 0.70\n","epoch: 7, batch: 53, loss: 0.933, acc: 0.67\n","epoch: 7, batch: 54, loss: 0.959, acc: 0.64\n","epoch: 7, batch: 55, loss: 0.813, acc: 0.71\n","epoch: 7, batch: 56, loss: 1.064, acc: 0.66\n","epoch: 7, batch: 57, loss: 1.037, acc: 0.60\n","epoch: 7, batch: 58, loss: 0.978, acc: 0.68\n","epoch: 7, batch: 59, loss: 0.803, acc: 0.76\n","epoch: 7, batch: 60, loss: 1.037, acc: 0.61\n","epoch: 7, batch: 61, loss: 0.996, acc: 0.67\n","epoch: 7, batch: 62, loss: 0.923, acc: 0.68\n","epoch: 7, batch: 63, loss: 0.897, acc: 0.73\n","epoch: 7, batch: 64, loss: 0.850, acc: 0.72\n","epoch: 7, batch: 65, loss: 0.784, acc: 0.75\n","epoch: 7, batch: 66, loss: 1.031, acc: 0.66\n","epoch: 7, batch: 67, loss: 1.316, acc: 0.60\n","epoch: 7, batch: 68, loss: 0.866, acc: 0.68\n","epoch: 7, batch: 69, loss: 0.959, acc: 0.67\n","epoch: 7, batch: 70, loss: 1.064, acc: 0.60\n","epoch: 7, batch: 71, loss: 1.104, acc: 0.61\n","epoch: 7, batch: 72, loss: 0.875, acc: 0.66\n","epoch: 7, batch: 73, loss: 1.110, acc: 0.61\n","epoch: 7, batch: 74, loss: 1.054, acc: 0.65\n","epoch: 7, batch: 75, loss: 0.941, acc: 0.71\n","epoch: 7, batch: 76, loss: 0.965, acc: 0.67\n","epoch: 7, batch: 77, loss: 1.248, acc: 0.57\n","epoch: 7, batch: 78, loss: 1.117, acc: 0.55\n","epoch: 7, batch: 79, loss: 0.967, acc: 0.67\n","epoch: 7, batch: 80, loss: 0.873, acc: 0.70\n","epoch: 7, batch: 81, loss: 0.878, acc: 0.70\n","epoch: 7, batch: 82, loss: 1.026, acc: 0.61\n","epoch: 7, batch: 83, loss: 0.899, acc: 0.69\n","epoch: 7, batch: 84, loss: 1.141, acc: 0.60\n","epoch: 7, batch: 85, loss: 1.027, acc: 0.59\n","epoch: 7, batch: 86, loss: 0.979, acc: 0.66\n","epoch: 7, batch: 87, loss: 0.916, acc: 0.68\n","epoch: 7, batch: 88, loss: 0.883, acc: 0.72\n","epoch: 7, batch: 89, loss: 0.947, acc: 0.68\n","epoch: 7, batch: 90, loss: 0.930, acc: 0.66\n","epoch: 7, batch: 91, loss: 0.915, acc: 0.73\n","epoch: 7, batch: 92, loss: 0.926, acc: 0.65\n","epoch: 7, batch: 93, loss: 1.121, acc: 0.63\n","epoch: 7, batch: 94, loss: 0.948, acc: 0.70\n","epoch: 7, batch: 95, loss: 0.985, acc: 0.66\n","epoch: 7, batch: 96, loss: 0.995, acc: 0.66\n","epoch: 7, batch: 97, loss: 0.832, acc: 0.72\n","epoch: 7, batch: 98, loss: 0.885, acc: 0.71\n","epoch: 7, batch: 99, loss: 0.973, acc: 0.68\n","epoch: 7, batch: 100, loss: 1.089, acc: 0.63\n","epoch: 7, batch: 101, loss: 0.942, acc: 0.72\n","epoch: 7, batch: 102, loss: 1.023, acc: 0.69\n","epoch: 7, batch: 103, loss: 0.896, acc: 0.70\n","epoch: 7, batch: 104, loss: 0.977, acc: 0.67\n","epoch: 7, batch: 105, loss: 1.000, acc: 0.66\n","epoch: 7, batch: 106, loss: 0.913, acc: 0.70\n","epoch: 7, batch: 107, loss: 0.821, acc: 0.72\n","epoch: 7, batch: 108, loss: 1.002, acc: 0.63\n","epoch: 7, batch: 109, loss: 0.990, acc: 0.65\n","epoch: 7, batch: 110, loss: 1.017, acc: 0.66\n","epoch: 7, batch: 111, loss: 0.969, acc: 0.66\n","epoch: 7, batch: 112, loss: 0.906, acc: 0.75\n","epoch: 7, batch: 113, loss: 0.724, acc: 0.74\n","epoch: 7, batch: 114, loss: 1.032, acc: 0.63\n","epoch: 7, batch: 115, loss: 0.849, acc: 0.73\n","epoch: 7, batch: 116, loss: 1.039, acc: 0.66\n","epoch: 7, batch: 117, loss: 0.985, acc: 0.65\n","epoch: 7, batch: 118, loss: 1.031, acc: 0.69\n","epoch: 7, batch: 119, loss: 0.988, acc: 0.66\n","epoch: 7, batch: 120, loss: 1.018, acc: 0.67\n","epoch: 7, batch: 121, loss: 1.077, acc: 0.63\n","epoch: 7, batch: 122, loss: 1.011, acc: 0.73\n","epoch: 7, batch: 123, loss: 0.887, acc: 0.68\n","epoch: 7, batch: 124, loss: 1.040, acc: 0.65\n","epoch: 7, batch: 125, loss: 0.985, acc: 0.70\n","epoch: 7, batch: 126, loss: 1.061, acc: 0.67\n","epoch: 7, batch: 127, loss: 0.967, acc: 0.65\n","epoch: 7, batch: 128, loss: 0.965, acc: 0.65\n","epoch: 7, batch: 129, loss: 0.919, acc: 0.66\n","epoch: 7, batch: 130, loss: 0.940, acc: 0.66\n","epoch: 7, batch: 131, loss: 1.076, acc: 0.62\n","epoch: 7, batch: 132, loss: 1.028, acc: 0.68\n","epoch: 7, batch: 133, loss: 0.967, acc: 0.66\n","epoch: 7, batch: 134, loss: 0.821, acc: 0.71\n","epoch: 7, batch: 135, loss: 0.773, acc: 0.77\n","epoch: 7, batch: 136, loss: 0.884, acc: 0.69\n","epoch: 7, batch: 137, loss: 0.938, acc: 0.68\n","epoch: 7, batch: 138, loss: 0.898, acc: 0.71\n","epoch: 7, batch: 139, loss: 1.119, acc: 0.63\n","epoch: 7, batch: 140, loss: 0.908, acc: 0.69\n","epoch: 7, batch: 141, loss: 0.913, acc: 0.70\n","epoch: 7, batch: 142, loss: 1.103, acc: 0.63\n","epoch: 7, batch: 143, loss: 0.875, acc: 0.72\n","epoch: 7, batch: 144, loss: 1.031, acc: 0.63\n","epoch: 7, batch: 145, loss: 1.120, acc: 0.61\n","epoch: 7, batch: 146, loss: 0.789, acc: 0.77\n","epoch: 7, batch: 147, loss: 0.867, acc: 0.68\n","epoch: 7, batch: 148, loss: 0.999, acc: 0.66\n","epoch: 7, batch: 149, loss: 0.977, acc: 0.66\n","epoch: 7, batch: 150, loss: 0.818, acc: 0.71\n","epoch: 7, batch: 151, loss: 0.964, acc: 0.64\n","epoch: 7, batch: 152, loss: 1.015, acc: 0.63\n","epoch: 7, batch: 153, loss: 0.959, acc: 0.72\n","epoch: 7, batch: 154, loss: 1.151, acc: 0.62\n","epoch: 7, batch: 155, loss: 1.022, acc: 0.66\n","epoch: 7, batch: 156, loss: 1.011, acc: 0.66\n","epoch: 7, batch: 157, loss: 0.951, acc: 0.68\n","epoch: 7, batch: 158, loss: 1.003, acc: 0.64\n","epoch: 7, batch: 159, loss: 1.123, acc: 0.59\n","epoch: 7, batch: 160, loss: 0.750, acc: 0.82\n","epoch: 7, batch: 161, loss: 1.029, acc: 0.66\n","epoch: 7, batch: 162, loss: 0.956, acc: 0.70\n","epoch: 7, batch: 163, loss: 0.949, acc: 0.73\n","epoch: 7, batch: 164, loss: 0.994, acc: 0.64\n","epoch: 7, batch: 165, loss: 0.935, acc: 0.68\n","epoch: 7, batch: 166, loss: 1.051, acc: 0.62\n","epoch: 7, batch: 167, loss: 1.039, acc: 0.59\n","epoch: 7, batch: 168, loss: 0.970, acc: 0.73\n","epoch: 7, batch: 169, loss: 1.018, acc: 0.66\n","epoch: 7, batch: 170, loss: 0.988, acc: 0.68\n","epoch: 7, batch: 171, loss: 0.988, acc: 0.70\n","epoch: 7, batch: 172, loss: 0.801, acc: 0.73\n","epoch: 7, batch: 173, loss: 0.890, acc: 0.71\n","epoch: 7, batch: 174, loss: 1.030, acc: 0.66\n","epoch: 7, batch: 175, loss: 0.879, acc: 0.67\n","epoch: 7, batch: 176, loss: 0.861, acc: 0.68\n","epoch: 7, batch: 177, loss: 0.842, acc: 0.69\n","epoch: 7, batch: 178, loss: 0.936, acc: 0.63\n","epoch: 7, batch: 179, loss: 0.906, acc: 0.70\n","epoch: 7, batch: 180, loss: 1.192, acc: 0.58\n","epoch: 7, batch: 181, loss: 1.010, acc: 0.60\n","epoch: 7, batch: 182, loss: 1.083, acc: 0.61\n","epoch: 7, batch: 183, loss: 0.903, acc: 0.69\n","epoch: 7, batch: 184, loss: 0.880, acc: 0.65\n","epoch: 7, batch: 185, loss: 0.956, acc: 0.68\n","epoch: 7, batch: 186, loss: 0.905, acc: 0.67\n","epoch: 7, batch: 187, loss: 0.995, acc: 0.64\n","epoch: 7, batch: 188, loss: 1.107, acc: 0.60\n","epoch: 7, batch: 189, loss: 1.041, acc: 0.60\n","epoch: 7, batch: 190, loss: 0.918, acc: 0.64\n","epoch: 7, batch: 191, loss: 0.951, acc: 0.66\n","epoch: 7, batch: 192, loss: 1.037, acc: 0.67\n","epoch: 7, batch: 193, loss: 1.059, acc: 0.66\n","epoch: 7, batch: 194, loss: 0.727, acc: 0.70\n","epoch: 7, batch: 195, loss: 0.811, acc: 0.72\n","epoch: 7, batch: 196, loss: 1.039, acc: 0.63\n","epoch: 7, batch: 197, loss: 0.866, acc: 0.70\n","epoch: 7, batch: 198, loss: 0.841, acc: 0.71\n","epoch: 7, batch: 199, loss: 0.962, acc: 0.70\n","epoch: 7, batch: 200, loss: 1.089, acc: 0.62\n","epoch: 7, batch: 201, loss: 0.780, acc: 0.73\n","epoch: 7, batch: 202, loss: 0.947, acc: 0.62\n","epoch: 7, batch: 203, loss: 0.921, acc: 0.66\n","epoch: 7, batch: 204, loss: 1.049, acc: 0.67\n","epoch: 7, batch: 205, loss: 0.980, acc: 0.59\n","epoch: 7, batch: 206, loss: 0.892, acc: 0.61\n","epoch: 7, batch: 207, loss: 0.728, acc: 0.80\n","epoch: 7, batch: 208, loss: 0.917, acc: 0.66\n","epoch: 7, batch: 209, loss: 0.939, acc: 0.63\n","epoch: 7, batch: 210, loss: 0.802, acc: 0.73\n","epoch: 7, batch: 211, loss: 0.864, acc: 0.72\n","epoch: 7, batch: 212, loss: 0.955, acc: 0.65\n","epoch: 7, batch: 213, loss: 1.073, acc: 0.57\n","epoch: 7, batch: 214, loss: 0.928, acc: 0.67\n","epoch: 7, batch: 215, loss: 0.918, acc: 0.63\n","epoch: 7, batch: 216, loss: 1.091, acc: 0.64\n","epoch: 7, batch: 217, loss: 1.044, acc: 0.66\n","epoch: 7, batch: 218, loss: 1.003, acc: 0.64\n","epoch: 7, batch: 219, loss: 0.915, acc: 0.70\n","epoch: 7, batch: 220, loss: 0.922, acc: 0.70\n","epoch: 7, batch: 221, loss: 0.846, acc: 0.70\n","epoch: 7, batch: 222, loss: 1.070, acc: 0.59\n","epoch: 7, batch: 223, loss: 0.812, acc: 0.70\n","epoch: 7, batch: 224, loss: 1.025, acc: 0.66\n","epoch: 7, batch: 225, loss: 1.006, acc: 0.70\n","epoch: 7, batch: 226, loss: 0.866, acc: 0.70\n","epoch: 7, batch: 227, loss: 0.976, acc: 0.67\n","epoch: 7, batch: 228, loss: 0.994, acc: 0.66\n","epoch: 7, batch: 229, loss: 1.040, acc: 0.67\n","epoch: 7, batch: 230, loss: 0.662, acc: 0.80\n","epoch: 7, batch: 231, loss: 0.862, acc: 0.69\n","epoch: 7, batch: 232, loss: 0.989, acc: 0.66\n","epoch: 7, batch: 233, loss: 0.901, acc: 0.72\n","epoch: 7, batch: 234, loss: 0.955, acc: 0.65\n","epoch: 7, batch: 235, loss: 0.977, acc: 0.65\n","epoch: 7, batch: 236, loss: 1.191, acc: 0.62\n","epoch: 7, batch: 237, loss: 0.763, acc: 0.74\n","epoch: 7, batch: 238, loss: 0.856, acc: 0.67\n","epoch: 7, batch: 239, loss: 0.880, acc: 0.77\n","epoch: 7, batch: 240, loss: 0.879, acc: 0.73\n","epoch: 7, batch: 241, loss: 0.901, acc: 0.71\n","epoch: 7, batch: 242, loss: 0.977, acc: 0.69\n","epoch: 7, batch: 243, loss: 0.869, acc: 0.70\n","epoch: 7, batch: 244, loss: 0.773, acc: 0.72\n","epoch: 7, batch: 245, loss: 0.939, acc: 0.66\n","epoch: 7, batch: 246, loss: 1.045, acc: 0.69\n","epoch: 7, batch: 247, loss: 1.082, acc: 0.59\n","epoch: 7, batch: 248, loss: 0.859, acc: 0.68\n","epoch: 7, batch: 249, loss: 0.990, acc: 0.64\n","epoch: 7, batch: 250, loss: 0.856, acc: 0.70\n","epoch: 7, batch: 251, loss: 0.988, acc: 0.66\n","epoch: 7, batch: 252, loss: 1.077, acc: 0.64\n","epoch: 7, batch: 253, loss: 0.873, acc: 0.73\n","epoch: 7, batch: 254, loss: 0.951, acc: 0.64\n","epoch: 7, batch: 255, loss: 0.896, acc: 0.72\n","epoch: 7, batch: 256, loss: 1.009, acc: 0.64\n","epoch: 7, batch: 257, loss: 0.804, acc: 0.76\n","epoch: 7, batch: 258, loss: 0.840, acc: 0.64\n","epoch: 7, batch: 259, loss: 0.903, acc: 0.66\n","epoch: 7, batch: 260, loss: 0.854, acc: 0.70\n","epoch: 7, batch: 261, loss: 1.051, acc: 0.59\n","epoch: 7, batch: 262, loss: 0.990, acc: 0.62\n","epoch: 7, batch: 263, loss: 0.935, acc: 0.70\n","epoch: 7, batch: 264, loss: 1.096, acc: 0.61\n","epoch: 7, batch: 265, loss: 0.853, acc: 0.70\n","epoch: 7, batch: 266, loss: 0.817, acc: 0.73\n","epoch: 7, batch: 267, loss: 0.970, acc: 0.66\n","epoch: 7, batch: 268, loss: 0.998, acc: 0.69\n","epoch: 7, batch: 269, loss: 0.974, acc: 0.63\n","epoch: 7, batch: 270, loss: 0.835, acc: 0.73\n","epoch: 7, batch: 271, loss: 1.017, acc: 0.65\n","epoch: 7, batch: 272, loss: 0.810, acc: 0.74\n","epoch: 7, batch: 273, loss: 1.013, acc: 0.67\n","epoch: 7, batch: 274, loss: 1.137, acc: 0.59\n","epoch: 7, batch: 275, loss: 1.080, acc: 0.63\n","epoch: 7, batch: 276, loss: 0.920, acc: 0.64\n","epoch: 7, batch: 277, loss: 1.094, acc: 0.70\n","epoch: 7, batch: 278, loss: 0.863, acc: 0.70\n","epoch: 7, batch: 279, loss: 0.881, acc: 0.71\n","epoch: 7, batch: 280, loss: 0.917, acc: 0.69\n","epoch: 7, batch: 281, loss: 0.869, acc: 0.69\n","epoch: 7, batch: 282, loss: 0.897, acc: 0.69\n","epoch: 7, batch: 283, loss: 1.027, acc: 0.61\n","epoch: 7, batch: 284, loss: 0.877, acc: 0.71\n","epoch: 7, batch: 285, loss: 0.982, acc: 0.62\n","epoch: 7, batch: 286, loss: 0.862, acc: 0.66\n","epoch: 7, batch: 287, loss: 0.983, acc: 0.67\n","epoch: 7, batch: 288, loss: 0.903, acc: 0.73\n","epoch: 7, batch: 289, loss: 0.911, acc: 0.70\n","epoch: 7, batch: 290, loss: 1.203, acc: 0.59\n","epoch: 7, batch: 291, loss: 0.827, acc: 0.70\n","epoch: 7, batch: 292, loss: 0.932, acc: 0.66\n","epoch: 7, batch: 293, loss: 1.192, acc: 0.54\n","epoch: 7, batch: 294, loss: 1.080, acc: 0.62\n","epoch: 7, batch: 295, loss: 0.986, acc: 0.65\n","epoch: 7, batch: 296, loss: 1.017, acc: 0.65\n","epoch: 7, batch: 297, loss: 0.851, acc: 0.72\n","epoch: 7, batch: 298, loss: 0.906, acc: 0.66\n","epoch: 7, batch: 299, loss: 0.811, acc: 0.72\n","epoch: 7, batch: 300, loss: 1.022, acc: 0.66\n","epoch: 7, batch: 301, loss: 1.031, acc: 0.63\n","epoch: 7, batch: 302, loss: 0.806, acc: 0.70\n","epoch: 7, batch: 303, loss: 0.866, acc: 0.67\n","epoch: 7, batch: 304, loss: 1.034, acc: 0.64\n","epoch: 7, batch: 305, loss: 1.001, acc: 0.62\n","epoch: 7, batch: 306, loss: 0.947, acc: 0.69\n","epoch: 7, batch: 307, loss: 0.775, acc: 0.73\n","epoch: 7, batch: 308, loss: 0.866, acc: 0.68\n","epoch: 7, batch: 309, loss: 0.821, acc: 0.74\n","epoch: 7, batch: 310, loss: 0.873, acc: 0.70\n","epoch: 7, batch: 311, loss: 1.028, acc: 0.67\n","epoch: 7, batch: 312, loss: 0.928, acc: 0.68\n","epoch: 7, batch: 313, loss: 0.942, acc: 0.69\n","epoch: 7, batch: 314, loss: 1.038, acc: 0.62\n","epoch: 7, batch: 315, loss: 1.135, acc: 0.64\n","epoch: 7, batch: 316, loss: 0.816, acc: 0.73\n","epoch: 7, batch: 317, loss: 0.965, acc: 0.62\n","epoch: 7, batch: 318, loss: 0.892, acc: 0.70\n","epoch: 7, batch: 319, loss: 1.003, acc: 0.66\n","epoch: 7, batch: 320, loss: 1.043, acc: 0.67\n","epoch: 7, batch: 321, loss: 0.964, acc: 0.67\n","epoch: 7, batch: 322, loss: 0.851, acc: 0.73\n","epoch: 7, batch: 323, loss: 1.043, acc: 0.62\n","epoch: 7, batch: 324, loss: 0.765, acc: 0.73\n","epoch: 7, batch: 325, loss: 1.002, acc: 0.67\n","epoch: 7, batch: 326, loss: 0.832, acc: 0.70\n","epoch: 7, batch: 327, loss: 1.065, acc: 0.59\n","epoch: 7, batch: 328, loss: 0.817, acc: 0.73\n","epoch: 7, batch: 329, loss: 0.883, acc: 0.72\n","epoch: 7, batch: 330, loss: 0.856, acc: 0.71\n","epoch: 7, batch: 331, loss: 0.825, acc: 0.73\n","epoch: 7, batch: 332, loss: 0.980, acc: 0.66\n","epoch: 7, batch: 333, loss: 1.015, acc: 0.62\n","epoch: 7, batch: 334, loss: 0.905, acc: 0.67\n","epoch: 7, batch: 335, loss: 1.000, acc: 0.63\n","epoch: 7, batch: 336, loss: 0.909, acc: 0.70\n","epoch: 7, batch: 337, loss: 0.937, acc: 0.65\n","epoch: 7, batch: 338, loss: 1.093, acc: 0.66\n","epoch: 7, batch: 339, loss: 0.866, acc: 0.70\n","epoch: 7, batch: 340, loss: 1.108, acc: 0.63\n","epoch: 7, batch: 341, loss: 1.010, acc: 0.65\n","epoch: 7, batch: 342, loss: 1.088, acc: 0.61\n","epoch: 7, batch: 343, loss: 0.886, acc: 0.73\n","epoch: 7, batch: 344, loss: 0.887, acc: 0.65\n","epoch: 7, batch: 345, loss: 0.900, acc: 0.70\n","epoch: 7, batch: 346, loss: 0.958, acc: 0.65\n","epoch: 7, batch: 347, loss: 1.079, acc: 0.62\n","epoch: 7, batch: 348, loss: 0.789, acc: 0.73\n","epoch: 7, batch: 349, loss: 0.981, acc: 0.68\n","epoch: 7, batch: 350, loss: 0.957, acc: 0.66\n","epoch: 7, batch: 351, loss: 0.998, acc: 0.62\n","epoch: 7, batch: 352, loss: 0.856, acc: 0.72\n","epoch: 7, batch: 353, loss: 0.808, acc: 0.72\n","epoch: 7, batch: 354, loss: 1.012, acc: 0.63\n","epoch: 7, batch: 355, loss: 0.971, acc: 0.66\n","epoch: 7, batch: 356, loss: 0.955, acc: 0.66\n","epoch: 7, batch: 357, loss: 0.899, acc: 0.66\n","epoch: 7, batch: 358, loss: 1.159, acc: 0.59\n","epoch: 7, batch: 359, loss: 0.927, acc: 0.71\n","epoch: 7, batch: 360, loss: 0.916, acc: 0.70\n","epoch: 7, batch: 361, loss: 0.976, acc: 0.64\n","epoch: 7, batch: 362, loss: 0.917, acc: 0.70\n","epoch: 7, batch: 363, loss: 0.967, acc: 0.67\n","epoch: 7, batch: 364, loss: 1.065, acc: 0.65\n","epoch: 7, batch: 365, loss: 0.936, acc: 0.70\n","epoch: 7, batch: 366, loss: 0.916, acc: 0.66\n","epoch: 7, batch: 367, loss: 0.945, acc: 0.69\n","epoch: 7, batch: 368, loss: 0.871, acc: 0.70\n","epoch: 7, batch: 369, loss: 1.050, acc: 0.65\n","epoch: 7, batch: 370, loss: 0.928, acc: 0.70\n","epoch: 7, batch: 371, loss: 0.870, acc: 0.66\n","epoch: 7, batch: 372, loss: 0.915, acc: 0.70\n","epoch: 7, batch: 373, loss: 0.890, acc: 0.71\n","epoch: 7, batch: 374, loss: 0.866, acc: 0.70\n","epoch: 7, batch: 375, loss: 0.932, acc: 0.68\n","epoch: 7, batch: 376, loss: 0.833, acc: 0.70\n","epoch: 7, batch: 377, loss: 0.902, acc: 0.70\n","epoch: 7, batch: 378, loss: 1.004, acc: 0.65\n","epoch: 7, batch: 379, loss: 0.855, acc: 0.70\n","epoch: 7, batch: 380, loss: 0.828, acc: 0.72\n","epoch: 7, batch: 381, loss: 0.850, acc: 0.69\n","epoch: 7, batch: 382, loss: 0.854, acc: 0.69\n","epoch: 7, batch: 383, loss: 0.738, acc: 0.77\n","epoch: 7, batch: 384, loss: 1.028, acc: 0.62\n","epoch: 7, batch: 385, loss: 0.854, acc: 0.72\n","epoch: 7, batch: 386, loss: 0.882, acc: 0.71\n","epoch: 7, batch: 387, loss: 0.737, acc: 0.76\n","epoch: 7, batch: 388, loss: 1.268, acc: 0.56\n","epoch: 7, batch: 389, loss: 0.808, acc: 0.70\n","epoch: 7, batch: 390, loss: 0.966, acc: 0.68\n","epoch: 7, batch: 391, loss: 0.993, acc: 0.62\n","epoch: 8, batch: 1, loss: 0.989, acc: 0.59\n","epoch: 8, batch: 2, loss: 1.056, acc: 0.61\n","epoch: 8, batch: 3, loss: 0.946, acc: 0.64\n","epoch: 8, batch: 4, loss: 1.062, acc: 0.59\n","epoch: 8, batch: 5, loss: 0.996, acc: 0.66\n","epoch: 8, batch: 6, loss: 0.853, acc: 0.66\n","epoch: 8, batch: 7, loss: 0.746, acc: 0.72\n","epoch: 8, batch: 8, loss: 0.871, acc: 0.69\n","epoch: 8, batch: 9, loss: 1.000, acc: 0.67\n","epoch: 8, batch: 10, loss: 0.837, acc: 0.66\n","epoch: 8, batch: 11, loss: 0.865, acc: 0.71\n","epoch: 8, batch: 12, loss: 0.827, acc: 0.72\n","epoch: 8, batch: 13, loss: 1.006, acc: 0.65\n","epoch: 8, batch: 14, loss: 0.869, acc: 0.70\n","epoch: 8, batch: 15, loss: 0.978, acc: 0.65\n","epoch: 8, batch: 16, loss: 0.931, acc: 0.70\n","epoch: 8, batch: 17, loss: 0.947, acc: 0.66\n","epoch: 8, batch: 18, loss: 0.935, acc: 0.72\n","epoch: 8, batch: 19, loss: 0.885, acc: 0.68\n","epoch: 8, batch: 20, loss: 0.823, acc: 0.69\n","epoch: 8, batch: 21, loss: 0.962, acc: 0.70\n","epoch: 8, batch: 22, loss: 0.963, acc: 0.66\n","epoch: 8, batch: 23, loss: 0.868, acc: 0.71\n","epoch: 8, batch: 24, loss: 0.805, acc: 0.75\n","epoch: 8, batch: 25, loss: 0.985, acc: 0.68\n","epoch: 8, batch: 26, loss: 0.984, acc: 0.63\n","epoch: 8, batch: 27, loss: 0.940, acc: 0.73\n","epoch: 8, batch: 28, loss: 0.920, acc: 0.71\n","epoch: 8, batch: 29, loss: 0.935, acc: 0.74\n","epoch: 8, batch: 30, loss: 0.929, acc: 0.66\n","epoch: 8, batch: 31, loss: 0.822, acc: 0.71\n","epoch: 8, batch: 32, loss: 0.919, acc: 0.68\n","epoch: 8, batch: 33, loss: 1.076, acc: 0.65\n","epoch: 8, batch: 34, loss: 1.110, acc: 0.59\n","epoch: 8, batch: 35, loss: 1.050, acc: 0.63\n","epoch: 8, batch: 36, loss: 0.873, acc: 0.71\n","epoch: 8, batch: 37, loss: 1.058, acc: 0.63\n","epoch: 8, batch: 38, loss: 0.931, acc: 0.71\n","epoch: 8, batch: 39, loss: 0.985, acc: 0.69\n","epoch: 8, batch: 40, loss: 1.060, acc: 0.64\n","epoch: 8, batch: 41, loss: 1.036, acc: 0.65\n","epoch: 8, batch: 42, loss: 0.933, acc: 0.69\n","epoch: 8, batch: 43, loss: 1.047, acc: 0.69\n","epoch: 8, batch: 44, loss: 0.857, acc: 0.71\n","epoch: 8, batch: 45, loss: 0.796, acc: 0.73\n","epoch: 8, batch: 46, loss: 0.933, acc: 0.62\n","epoch: 8, batch: 47, loss: 0.855, acc: 0.68\n","epoch: 8, batch: 48, loss: 1.021, acc: 0.65\n","epoch: 8, batch: 49, loss: 1.001, acc: 0.68\n","epoch: 8, batch: 50, loss: 0.957, acc: 0.65\n","epoch: 8, batch: 51, loss: 0.856, acc: 0.70\n","epoch: 8, batch: 52, loss: 1.015, acc: 0.69\n","epoch: 8, batch: 53, loss: 1.026, acc: 0.63\n","epoch: 8, batch: 54, loss: 0.936, acc: 0.69\n","epoch: 8, batch: 55, loss: 0.921, acc: 0.66\n","epoch: 8, batch: 56, loss: 0.961, acc: 0.66\n","epoch: 8, batch: 57, loss: 1.047, acc: 0.73\n","epoch: 8, batch: 58, loss: 0.916, acc: 0.67\n","epoch: 8, batch: 59, loss: 1.021, acc: 0.66\n","epoch: 8, batch: 60, loss: 0.781, acc: 0.75\n","epoch: 8, batch: 61, loss: 0.914, acc: 0.66\n","epoch: 8, batch: 62, loss: 0.979, acc: 0.74\n","epoch: 8, batch: 63, loss: 0.812, acc: 0.75\n","epoch: 8, batch: 64, loss: 0.928, acc: 0.66\n","epoch: 8, batch: 65, loss: 1.037, acc: 0.64\n","epoch: 8, batch: 66, loss: 0.971, acc: 0.66\n","epoch: 8, batch: 67, loss: 0.861, acc: 0.70\n","epoch: 8, batch: 68, loss: 1.051, acc: 0.63\n","epoch: 8, batch: 69, loss: 0.865, acc: 0.69\n","epoch: 8, batch: 70, loss: 0.941, acc: 0.72\n","epoch: 8, batch: 71, loss: 0.910, acc: 0.67\n","epoch: 8, batch: 72, loss: 0.971, acc: 0.70\n","epoch: 8, batch: 73, loss: 0.910, acc: 0.63\n","epoch: 8, batch: 74, loss: 0.864, acc: 0.71\n","epoch: 8, batch: 75, loss: 1.040, acc: 0.65\n","epoch: 8, batch: 76, loss: 0.971, acc: 0.66\n","epoch: 8, batch: 77, loss: 0.891, acc: 0.71\n","epoch: 8, batch: 78, loss: 0.920, acc: 0.66\n","epoch: 8, batch: 79, loss: 0.913, acc: 0.72\n","epoch: 8, batch: 80, loss: 1.075, acc: 0.62\n","epoch: 8, batch: 81, loss: 1.150, acc: 0.58\n","epoch: 8, batch: 82, loss: 0.878, acc: 0.66\n","epoch: 8, batch: 83, loss: 0.925, acc: 0.70\n","epoch: 8, batch: 84, loss: 0.889, acc: 0.70\n","epoch: 8, batch: 85, loss: 0.855, acc: 0.71\n","epoch: 8, batch: 86, loss: 1.058, acc: 0.68\n","epoch: 8, batch: 87, loss: 0.845, acc: 0.74\n","epoch: 8, batch: 88, loss: 0.980, acc: 0.70\n","epoch: 8, batch: 89, loss: 0.897, acc: 0.67\n","epoch: 8, batch: 90, loss: 1.062, acc: 0.66\n","epoch: 8, batch: 91, loss: 0.823, acc: 0.76\n","epoch: 8, batch: 92, loss: 0.892, acc: 0.69\n","epoch: 8, batch: 93, loss: 1.061, acc: 0.62\n","epoch: 8, batch: 94, loss: 0.816, acc: 0.76\n","epoch: 8, batch: 95, loss: 1.013, acc: 0.63\n","epoch: 8, batch: 96, loss: 0.815, acc: 0.75\n","epoch: 8, batch: 97, loss: 0.850, acc: 0.73\n","epoch: 8, batch: 98, loss: 0.870, acc: 0.71\n","epoch: 8, batch: 99, loss: 0.973, acc: 0.66\n","epoch: 8, batch: 100, loss: 0.904, acc: 0.70\n","epoch: 8, batch: 101, loss: 0.960, acc: 0.65\n","epoch: 8, batch: 102, loss: 0.992, acc: 0.68\n","epoch: 8, batch: 103, loss: 0.930, acc: 0.66\n","epoch: 8, batch: 104, loss: 0.996, acc: 0.62\n","epoch: 8, batch: 105, loss: 0.828, acc: 0.74\n","epoch: 8, batch: 106, loss: 1.009, acc: 0.65\n","epoch: 8, batch: 107, loss: 1.120, acc: 0.60\n","epoch: 8, batch: 108, loss: 0.850, acc: 0.70\n","epoch: 8, batch: 109, loss: 0.841, acc: 0.71\n","epoch: 8, batch: 110, loss: 0.979, acc: 0.67\n","epoch: 8, batch: 111, loss: 0.794, acc: 0.76\n","epoch: 8, batch: 112, loss: 0.956, acc: 0.70\n","epoch: 8, batch: 113, loss: 0.838, acc: 0.70\n","epoch: 8, batch: 114, loss: 0.856, acc: 0.77\n","epoch: 8, batch: 115, loss: 0.940, acc: 0.66\n","epoch: 8, batch: 116, loss: 0.953, acc: 0.70\n","epoch: 8, batch: 117, loss: 1.017, acc: 0.66\n","epoch: 8, batch: 118, loss: 1.115, acc: 0.66\n","epoch: 8, batch: 119, loss: 0.830, acc: 0.76\n","epoch: 8, batch: 120, loss: 0.871, acc: 0.72\n","epoch: 8, batch: 121, loss: 0.947, acc: 0.69\n","epoch: 8, batch: 122, loss: 0.879, acc: 0.69\n","epoch: 8, batch: 123, loss: 1.012, acc: 0.66\n","epoch: 8, batch: 124, loss: 0.914, acc: 0.66\n","epoch: 8, batch: 125, loss: 0.878, acc: 0.70\n","epoch: 8, batch: 126, loss: 0.821, acc: 0.70\n","epoch: 8, batch: 127, loss: 0.877, acc: 0.71\n","epoch: 8, batch: 128, loss: 0.799, acc: 0.73\n","epoch: 8, batch: 129, loss: 0.902, acc: 0.67\n","epoch: 8, batch: 130, loss: 0.880, acc: 0.67\n","epoch: 8, batch: 131, loss: 1.016, acc: 0.61\n","epoch: 8, batch: 132, loss: 0.801, acc: 0.70\n","epoch: 8, batch: 133, loss: 0.951, acc: 0.67\n","epoch: 8, batch: 134, loss: 0.926, acc: 0.69\n","epoch: 8, batch: 135, loss: 0.781, acc: 0.73\n","epoch: 8, batch: 136, loss: 0.838, acc: 0.69\n","epoch: 8, batch: 137, loss: 0.872, acc: 0.72\n","epoch: 8, batch: 138, loss: 0.886, acc: 0.68\n","epoch: 8, batch: 139, loss: 0.917, acc: 0.65\n","epoch: 8, batch: 140, loss: 1.021, acc: 0.62\n","epoch: 8, batch: 141, loss: 0.888, acc: 0.72\n","epoch: 8, batch: 142, loss: 1.010, acc: 0.68\n","epoch: 8, batch: 143, loss: 1.078, acc: 0.59\n","epoch: 8, batch: 144, loss: 0.881, acc: 0.71\n","epoch: 8, batch: 145, loss: 0.945, acc: 0.66\n","epoch: 8, batch: 146, loss: 0.865, acc: 0.70\n","epoch: 8, batch: 147, loss: 0.787, acc: 0.77\n","epoch: 8, batch: 148, loss: 0.970, acc: 0.66\n","epoch: 8, batch: 149, loss: 0.742, acc: 0.74\n","epoch: 8, batch: 150, loss: 0.898, acc: 0.67\n","epoch: 8, batch: 151, loss: 0.934, acc: 0.67\n","epoch: 8, batch: 152, loss: 0.812, acc: 0.73\n","epoch: 8, batch: 153, loss: 0.917, acc: 0.70\n","epoch: 8, batch: 154, loss: 0.818, acc: 0.67\n","epoch: 8, batch: 155, loss: 0.985, acc: 0.67\n","epoch: 8, batch: 156, loss: 0.759, acc: 0.74\n","epoch: 8, batch: 157, loss: 1.010, acc: 0.60\n","epoch: 8, batch: 158, loss: 0.985, acc: 0.67\n","epoch: 8, batch: 159, loss: 0.981, acc: 0.68\n","epoch: 8, batch: 160, loss: 0.996, acc: 0.68\n","epoch: 8, batch: 161, loss: 1.002, acc: 0.66\n","epoch: 8, batch: 162, loss: 1.082, acc: 0.63\n","epoch: 8, batch: 163, loss: 1.101, acc: 0.70\n","epoch: 8, batch: 164, loss: 0.952, acc: 0.64\n","epoch: 8, batch: 165, loss: 1.049, acc: 0.62\n","epoch: 8, batch: 166, loss: 0.940, acc: 0.67\n","epoch: 8, batch: 167, loss: 0.868, acc: 0.73\n","epoch: 8, batch: 168, loss: 0.791, acc: 0.72\n","epoch: 8, batch: 169, loss: 0.861, acc: 0.72\n","epoch: 8, batch: 170, loss: 0.968, acc: 0.66\n","epoch: 8, batch: 171, loss: 1.084, acc: 0.63\n","epoch: 8, batch: 172, loss: 0.889, acc: 0.70\n","epoch: 8, batch: 173, loss: 0.995, acc: 0.69\n","epoch: 8, batch: 174, loss: 0.912, acc: 0.67\n","epoch: 8, batch: 175, loss: 0.927, acc: 0.71\n","epoch: 8, batch: 176, loss: 0.935, acc: 0.70\n","epoch: 8, batch: 177, loss: 0.755, acc: 0.70\n","epoch: 8, batch: 178, loss: 0.885, acc: 0.71\n","epoch: 8, batch: 179, loss: 0.919, acc: 0.70\n","epoch: 8, batch: 180, loss: 0.917, acc: 0.70\n","epoch: 8, batch: 181, loss: 0.949, acc: 0.61\n","epoch: 8, batch: 182, loss: 0.866, acc: 0.69\n","epoch: 8, batch: 183, loss: 1.000, acc: 0.62\n","epoch: 8, batch: 184, loss: 0.878, acc: 0.72\n","epoch: 8, batch: 185, loss: 1.055, acc: 0.63\n","epoch: 8, batch: 186, loss: 0.857, acc: 0.68\n","epoch: 8, batch: 187, loss: 0.944, acc: 0.68\n","epoch: 8, batch: 188, loss: 0.863, acc: 0.68\n","epoch: 8, batch: 189, loss: 0.880, acc: 0.69\n","epoch: 8, batch: 190, loss: 1.045, acc: 0.59\n","epoch: 8, batch: 191, loss: 0.984, acc: 0.64\n","epoch: 8, batch: 192, loss: 0.941, acc: 0.64\n","epoch: 8, batch: 193, loss: 0.919, acc: 0.66\n","epoch: 8, batch: 194, loss: 0.787, acc: 0.71\n","epoch: 8, batch: 195, loss: 1.052, acc: 0.67\n","epoch: 8, batch: 196, loss: 0.898, acc: 0.66\n","epoch: 8, batch: 197, loss: 0.963, acc: 0.69\n","epoch: 8, batch: 198, loss: 0.833, acc: 0.70\n","epoch: 8, batch: 199, loss: 0.937, acc: 0.68\n","epoch: 8, batch: 200, loss: 1.003, acc: 0.68\n","epoch: 8, batch: 201, loss: 0.806, acc: 0.71\n","epoch: 8, batch: 202, loss: 0.873, acc: 0.68\n","epoch: 8, batch: 203, loss: 1.021, acc: 0.64\n","epoch: 8, batch: 204, loss: 0.824, acc: 0.70\n","epoch: 8, batch: 205, loss: 0.856, acc: 0.69\n","epoch: 8, batch: 206, loss: 0.971, acc: 0.68\n","epoch: 8, batch: 207, loss: 1.017, acc: 0.63\n","epoch: 8, batch: 208, loss: 0.853, acc: 0.67\n","epoch: 8, batch: 209, loss: 0.889, acc: 0.71\n","epoch: 8, batch: 210, loss: 0.817, acc: 0.71\n","epoch: 8, batch: 211, loss: 0.879, acc: 0.69\n","epoch: 8, batch: 212, loss: 0.939, acc: 0.70\n","epoch: 8, batch: 213, loss: 0.914, acc: 0.66\n","epoch: 8, batch: 214, loss: 0.877, acc: 0.69\n","epoch: 8, batch: 215, loss: 0.874, acc: 0.67\n","epoch: 8, batch: 216, loss: 0.767, acc: 0.73\n","epoch: 8, batch: 217, loss: 0.798, acc: 0.76\n","epoch: 8, batch: 218, loss: 0.866, acc: 0.67\n","epoch: 8, batch: 219, loss: 1.065, acc: 0.62\n","epoch: 8, batch: 220, loss: 0.802, acc: 0.75\n","epoch: 8, batch: 221, loss: 0.880, acc: 0.70\n","epoch: 8, batch: 222, loss: 1.050, acc: 0.65\n","epoch: 8, batch: 223, loss: 1.194, acc: 0.60\n","epoch: 8, batch: 224, loss: 0.891, acc: 0.70\n","epoch: 8, batch: 225, loss: 0.928, acc: 0.67\n","epoch: 8, batch: 226, loss: 1.016, acc: 0.63\n","epoch: 8, batch: 227, loss: 0.821, acc: 0.72\n","epoch: 8, batch: 228, loss: 0.868, acc: 0.75\n","epoch: 8, batch: 229, loss: 0.972, acc: 0.68\n","epoch: 8, batch: 230, loss: 0.906, acc: 0.69\n","epoch: 8, batch: 231, loss: 1.163, acc: 0.55\n","epoch: 8, batch: 232, loss: 0.772, acc: 0.72\n","epoch: 8, batch: 233, loss: 0.846, acc: 0.72\n","epoch: 8, batch: 234, loss: 0.695, acc: 0.77\n","epoch: 8, batch: 235, loss: 0.895, acc: 0.65\n","epoch: 8, batch: 236, loss: 0.806, acc: 0.73\n","epoch: 8, batch: 237, loss: 0.883, acc: 0.72\n","epoch: 8, batch: 238, loss: 0.987, acc: 0.73\n","epoch: 8, batch: 239, loss: 0.727, acc: 0.79\n","epoch: 8, batch: 240, loss: 0.907, acc: 0.66\n","epoch: 8, batch: 241, loss: 0.806, acc: 0.73\n","epoch: 8, batch: 242, loss: 0.893, acc: 0.71\n","epoch: 8, batch: 243, loss: 0.930, acc: 0.66\n","epoch: 8, batch: 244, loss: 0.961, acc: 0.70\n","epoch: 8, batch: 245, loss: 0.830, acc: 0.68\n","epoch: 8, batch: 246, loss: 0.823, acc: 0.75\n","epoch: 8, batch: 247, loss: 0.982, acc: 0.66\n","epoch: 8, batch: 248, loss: 0.897, acc: 0.66\n","epoch: 8, batch: 249, loss: 0.957, acc: 0.70\n","epoch: 8, batch: 250, loss: 0.997, acc: 0.62\n","epoch: 8, batch: 251, loss: 0.961, acc: 0.67\n","epoch: 8, batch: 252, loss: 1.057, acc: 0.63\n","epoch: 8, batch: 253, loss: 0.779, acc: 0.74\n","epoch: 8, batch: 254, loss: 0.876, acc: 0.74\n","epoch: 8, batch: 255, loss: 0.856, acc: 0.70\n","epoch: 8, batch: 256, loss: 0.901, acc: 0.72\n","epoch: 8, batch: 257, loss: 0.864, acc: 0.64\n","epoch: 8, batch: 258, loss: 0.898, acc: 0.66\n","epoch: 8, batch: 259, loss: 0.902, acc: 0.69\n","epoch: 8, batch: 260, loss: 0.857, acc: 0.70\n","epoch: 8, batch: 261, loss: 0.918, acc: 0.70\n","epoch: 8, batch: 262, loss: 0.931, acc: 0.73\n","epoch: 8, batch: 263, loss: 0.838, acc: 0.74\n","epoch: 8, batch: 264, loss: 0.831, acc: 0.70\n","epoch: 8, batch: 265, loss: 0.940, acc: 0.68\n","epoch: 8, batch: 266, loss: 0.860, acc: 0.69\n","epoch: 8, batch: 267, loss: 0.753, acc: 0.70\n","epoch: 8, batch: 268, loss: 0.845, acc: 0.72\n","epoch: 8, batch: 269, loss: 0.893, acc: 0.66\n","epoch: 8, batch: 270, loss: 0.723, acc: 0.74\n","epoch: 8, batch: 271, loss: 1.003, acc: 0.65\n","epoch: 8, batch: 272, loss: 1.102, acc: 0.62\n","epoch: 8, batch: 273, loss: 1.057, acc: 0.62\n","epoch: 8, batch: 274, loss: 0.806, acc: 0.75\n","epoch: 8, batch: 275, loss: 0.993, acc: 0.73\n","epoch: 8, batch: 276, loss: 0.902, acc: 0.68\n","epoch: 8, batch: 277, loss: 0.859, acc: 0.74\n","epoch: 8, batch: 278, loss: 0.787, acc: 0.76\n","epoch: 8, batch: 279, loss: 0.900, acc: 0.67\n","epoch: 8, batch: 280, loss: 1.039, acc: 0.66\n","epoch: 8, batch: 281, loss: 0.880, acc: 0.70\n","epoch: 8, batch: 282, loss: 0.930, acc: 0.65\n","epoch: 8, batch: 283, loss: 0.961, acc: 0.67\n","epoch: 8, batch: 284, loss: 0.918, acc: 0.66\n","epoch: 8, batch: 285, loss: 1.009, acc: 0.66\n","epoch: 8, batch: 286, loss: 0.872, acc: 0.69\n","epoch: 8, batch: 287, loss: 0.842, acc: 0.70\n","epoch: 8, batch: 288, loss: 0.903, acc: 0.72\n","epoch: 8, batch: 289, loss: 1.030, acc: 0.63\n","epoch: 8, batch: 290, loss: 0.810, acc: 0.70\n","epoch: 8, batch: 291, loss: 0.803, acc: 0.70\n","epoch: 8, batch: 292, loss: 0.936, acc: 0.67\n","epoch: 8, batch: 293, loss: 0.901, acc: 0.67\n","epoch: 8, batch: 294, loss: 0.854, acc: 0.66\n","epoch: 8, batch: 295, loss: 0.805, acc: 0.74\n","epoch: 8, batch: 296, loss: 1.042, acc: 0.70\n","epoch: 8, batch: 297, loss: 0.835, acc: 0.70\n","epoch: 8, batch: 298, loss: 0.923, acc: 0.64\n","epoch: 8, batch: 299, loss: 0.866, acc: 0.70\n","epoch: 8, batch: 300, loss: 0.905, acc: 0.71\n","epoch: 8, batch: 301, loss: 0.918, acc: 0.67\n","epoch: 8, batch: 302, loss: 0.922, acc: 0.65\n","epoch: 8, batch: 303, loss: 0.810, acc: 0.69\n","epoch: 8, batch: 304, loss: 0.978, acc: 0.68\n","epoch: 8, batch: 305, loss: 1.017, acc: 0.62\n","epoch: 8, batch: 306, loss: 0.785, acc: 0.73\n","epoch: 8, batch: 307, loss: 1.021, acc: 0.62\n","epoch: 8, batch: 308, loss: 0.771, acc: 0.77\n","epoch: 8, batch: 309, loss: 0.846, acc: 0.71\n","epoch: 8, batch: 310, loss: 0.758, acc: 0.76\n","epoch: 8, batch: 311, loss: 0.927, acc: 0.69\n","epoch: 8, batch: 312, loss: 0.877, acc: 0.72\n","epoch: 8, batch: 313, loss: 0.879, acc: 0.70\n","epoch: 8, batch: 314, loss: 0.948, acc: 0.68\n","epoch: 8, batch: 315, loss: 1.167, acc: 0.62\n","epoch: 8, batch: 316, loss: 0.956, acc: 0.65\n","epoch: 8, batch: 317, loss: 0.818, acc: 0.73\n","epoch: 8, batch: 318, loss: 0.685, acc: 0.77\n","epoch: 8, batch: 319, loss: 0.931, acc: 0.71\n","epoch: 8, batch: 320, loss: 0.977, acc: 0.69\n","epoch: 8, batch: 321, loss: 0.866, acc: 0.70\n","epoch: 8, batch: 322, loss: 0.839, acc: 0.70\n","epoch: 8, batch: 323, loss: 0.817, acc: 0.70\n","epoch: 8, batch: 324, loss: 0.976, acc: 0.66\n","epoch: 8, batch: 325, loss: 0.851, acc: 0.67\n","epoch: 8, batch: 326, loss: 1.009, acc: 0.70\n","epoch: 8, batch: 327, loss: 0.939, acc: 0.66\n","epoch: 8, batch: 328, loss: 0.803, acc: 0.66\n","epoch: 8, batch: 329, loss: 0.989, acc: 0.65\n","epoch: 8, batch: 330, loss: 1.050, acc: 0.64\n","epoch: 8, batch: 331, loss: 0.883, acc: 0.73\n","epoch: 8, batch: 332, loss: 1.014, acc: 0.63\n","epoch: 8, batch: 333, loss: 0.850, acc: 0.71\n","epoch: 8, batch: 334, loss: 0.911, acc: 0.72\n","epoch: 8, batch: 335, loss: 0.852, acc: 0.67\n","epoch: 8, batch: 336, loss: 0.899, acc: 0.70\n","epoch: 8, batch: 337, loss: 0.851, acc: 0.74\n","epoch: 8, batch: 338, loss: 0.886, acc: 0.72\n","epoch: 8, batch: 339, loss: 0.881, acc: 0.72\n","epoch: 8, batch: 340, loss: 0.990, acc: 0.70\n","epoch: 8, batch: 341, loss: 0.708, acc: 0.77\n","epoch: 8, batch: 342, loss: 1.076, acc: 0.61\n","epoch: 8, batch: 343, loss: 1.034, acc: 0.66\n","epoch: 8, batch: 344, loss: 1.011, acc: 0.69\n","epoch: 8, batch: 345, loss: 0.902, acc: 0.70\n","epoch: 8, batch: 346, loss: 0.990, acc: 0.60\n","epoch: 8, batch: 347, loss: 0.952, acc: 0.65\n","epoch: 8, batch: 348, loss: 0.840, acc: 0.67\n","epoch: 8, batch: 349, loss: 0.871, acc: 0.70\n","epoch: 8, batch: 350, loss: 0.867, acc: 0.66\n","epoch: 8, batch: 351, loss: 0.961, acc: 0.65\n","epoch: 8, batch: 352, loss: 0.929, acc: 0.66\n","epoch: 8, batch: 353, loss: 0.808, acc: 0.72\n","epoch: 8, batch: 354, loss: 0.855, acc: 0.69\n","epoch: 8, batch: 355, loss: 1.115, acc: 0.62\n","epoch: 8, batch: 356, loss: 1.009, acc: 0.65\n","epoch: 8, batch: 357, loss: 0.953, acc: 0.68\n","epoch: 8, batch: 358, loss: 0.980, acc: 0.68\n","epoch: 8, batch: 359, loss: 0.998, acc: 0.66\n","epoch: 8, batch: 360, loss: 0.837, acc: 0.69\n","epoch: 8, batch: 361, loss: 0.939, acc: 0.69\n","epoch: 8, batch: 362, loss: 0.948, acc: 0.60\n","epoch: 8, batch: 363, loss: 0.994, acc: 0.60\n","epoch: 8, batch: 364, loss: 1.024, acc: 0.62\n","epoch: 8, batch: 365, loss: 0.873, acc: 0.70\n","epoch: 8, batch: 366, loss: 0.873, acc: 0.70\n","epoch: 8, batch: 367, loss: 0.928, acc: 0.70\n","epoch: 8, batch: 368, loss: 1.010, acc: 0.65\n","epoch: 8, batch: 369, loss: 0.988, acc: 0.62\n","epoch: 8, batch: 370, loss: 1.007, acc: 0.66\n","epoch: 8, batch: 371, loss: 1.040, acc: 0.66\n","epoch: 8, batch: 372, loss: 0.852, acc: 0.67\n","epoch: 8, batch: 373, loss: 0.780, acc: 0.73\n","epoch: 8, batch: 374, loss: 0.815, acc: 0.70\n","epoch: 8, batch: 375, loss: 0.771, acc: 0.73\n","epoch: 8, batch: 376, loss: 0.949, acc: 0.63\n","epoch: 8, batch: 377, loss: 0.855, acc: 0.70\n","epoch: 8, batch: 378, loss: 0.735, acc: 0.74\n","epoch: 8, batch: 379, loss: 0.857, acc: 0.70\n","epoch: 8, batch: 380, loss: 0.842, acc: 0.73\n","epoch: 8, batch: 381, loss: 0.906, acc: 0.69\n","epoch: 8, batch: 382, loss: 0.817, acc: 0.76\n","epoch: 8, batch: 383, loss: 0.963, acc: 0.66\n","epoch: 8, batch: 384, loss: 0.752, acc: 0.76\n","epoch: 8, batch: 385, loss: 0.860, acc: 0.70\n","epoch: 8, batch: 386, loss: 0.917, acc: 0.68\n","epoch: 8, batch: 387, loss: 0.819, acc: 0.70\n","epoch: 8, batch: 388, loss: 0.861, acc: 0.70\n","epoch: 8, batch: 389, loss: 0.967, acc: 0.69\n","epoch: 8, batch: 390, loss: 0.930, acc: 0.66\n","epoch: 8, batch: 391, loss: 0.905, acc: 0.73\n","epoch: 9, batch: 1, loss: 0.844, acc: 0.71\n","epoch: 9, batch: 2, loss: 0.949, acc: 0.69\n","epoch: 9, batch: 3, loss: 1.008, acc: 0.59\n","epoch: 9, batch: 4, loss: 1.016, acc: 0.59\n","epoch: 9, batch: 5, loss: 0.951, acc: 0.65\n","epoch: 9, batch: 6, loss: 0.864, acc: 0.69\n","epoch: 9, batch: 7, loss: 1.010, acc: 0.63\n","epoch: 9, batch: 8, loss: 1.042, acc: 0.65\n","epoch: 9, batch: 9, loss: 0.852, acc: 0.67\n","epoch: 9, batch: 10, loss: 0.938, acc: 0.69\n","epoch: 9, batch: 11, loss: 0.864, acc: 0.67\n","epoch: 9, batch: 12, loss: 0.986, acc: 0.64\n","epoch: 9, batch: 13, loss: 0.919, acc: 0.68\n","epoch: 9, batch: 14, loss: 0.772, acc: 0.78\n","epoch: 9, batch: 15, loss: 0.964, acc: 0.68\n","epoch: 9, batch: 16, loss: 0.925, acc: 0.67\n","epoch: 9, batch: 17, loss: 0.905, acc: 0.70\n","epoch: 9, batch: 18, loss: 0.848, acc: 0.74\n","epoch: 9, batch: 19, loss: 0.796, acc: 0.67\n","epoch: 9, batch: 20, loss: 0.941, acc: 0.66\n","epoch: 9, batch: 21, loss: 0.919, acc: 0.70\n","epoch: 9, batch: 22, loss: 0.851, acc: 0.75\n","epoch: 9, batch: 23, loss: 1.007, acc: 0.65\n","epoch: 9, batch: 24, loss: 0.910, acc: 0.66\n","epoch: 9, batch: 25, loss: 0.917, acc: 0.71\n","epoch: 9, batch: 26, loss: 0.799, acc: 0.73\n","epoch: 9, batch: 27, loss: 0.801, acc: 0.72\n","epoch: 9, batch: 28, loss: 0.811, acc: 0.70\n","epoch: 9, batch: 29, loss: 0.831, acc: 0.76\n","epoch: 9, batch: 30, loss: 0.836, acc: 0.69\n","epoch: 9, batch: 31, loss: 1.117, acc: 0.69\n","epoch: 9, batch: 32, loss: 0.880, acc: 0.73\n","epoch: 9, batch: 33, loss: 0.894, acc: 0.69\n","epoch: 9, batch: 34, loss: 0.928, acc: 0.67\n","epoch: 9, batch: 35, loss: 0.963, acc: 0.69\n","epoch: 9, batch: 36, loss: 0.899, acc: 0.65\n","epoch: 9, batch: 37, loss: 0.897, acc: 0.70\n","epoch: 9, batch: 38, loss: 0.969, acc: 0.63\n","epoch: 9, batch: 39, loss: 0.812, acc: 0.68\n","epoch: 9, batch: 40, loss: 0.804, acc: 0.73\n","epoch: 9, batch: 41, loss: 0.732, acc: 0.73\n","epoch: 9, batch: 42, loss: 1.031, acc: 0.67\n","epoch: 9, batch: 43, loss: 0.915, acc: 0.70\n","epoch: 9, batch: 44, loss: 1.035, acc: 0.69\n","epoch: 9, batch: 45, loss: 0.746, acc: 0.73\n","epoch: 9, batch: 46, loss: 0.979, acc: 0.70\n","epoch: 9, batch: 47, loss: 0.880, acc: 0.66\n","epoch: 9, batch: 48, loss: 0.963, acc: 0.66\n","epoch: 9, batch: 49, loss: 0.682, acc: 0.79\n","epoch: 9, batch: 50, loss: 0.932, acc: 0.69\n","epoch: 9, batch: 51, loss: 0.948, acc: 0.66\n","epoch: 9, batch: 52, loss: 0.870, acc: 0.70\n","epoch: 9, batch: 53, loss: 0.943, acc: 0.71\n","epoch: 9, batch: 54, loss: 0.896, acc: 0.69\n","epoch: 9, batch: 55, loss: 0.903, acc: 0.66\n","epoch: 9, batch: 56, loss: 0.832, acc: 0.73\n","epoch: 9, batch: 57, loss: 0.949, acc: 0.69\n","epoch: 9, batch: 58, loss: 0.882, acc: 0.74\n","epoch: 9, batch: 59, loss: 0.996, acc: 0.71\n","epoch: 9, batch: 60, loss: 0.720, acc: 0.75\n","epoch: 9, batch: 61, loss: 1.092, acc: 0.64\n","epoch: 9, batch: 62, loss: 0.880, acc: 0.73\n","epoch: 9, batch: 63, loss: 0.757, acc: 0.73\n","epoch: 9, batch: 64, loss: 0.916, acc: 0.68\n","epoch: 9, batch: 65, loss: 0.997, acc: 0.63\n","epoch: 9, batch: 66, loss: 0.908, acc: 0.68\n","epoch: 9, batch: 67, loss: 0.834, acc: 0.68\n","epoch: 9, batch: 68, loss: 0.832, acc: 0.71\n","epoch: 9, batch: 69, loss: 0.950, acc: 0.66\n","epoch: 9, batch: 70, loss: 1.068, acc: 0.66\n","epoch: 9, batch: 71, loss: 0.936, acc: 0.71\n","epoch: 9, batch: 72, loss: 0.991, acc: 0.65\n","epoch: 9, batch: 73, loss: 1.069, acc: 0.62\n","epoch: 9, batch: 74, loss: 0.783, acc: 0.73\n","epoch: 9, batch: 75, loss: 1.034, acc: 0.60\n","epoch: 9, batch: 76, loss: 0.832, acc: 0.68\n","epoch: 9, batch: 77, loss: 1.073, acc: 0.68\n","epoch: 9, batch: 78, loss: 1.089, acc: 0.63\n","epoch: 9, batch: 79, loss: 1.018, acc: 0.66\n","epoch: 9, batch: 80, loss: 0.957, acc: 0.65\n","epoch: 9, batch: 81, loss: 0.888, acc: 0.70\n","epoch: 9, batch: 82, loss: 0.860, acc: 0.70\n","epoch: 9, batch: 83, loss: 0.817, acc: 0.76\n","epoch: 9, batch: 84, loss: 0.926, acc: 0.68\n","epoch: 9, batch: 85, loss: 0.948, acc: 0.71\n","epoch: 9, batch: 86, loss: 0.967, acc: 0.69\n","epoch: 9, batch: 87, loss: 0.832, acc: 0.70\n","epoch: 9, batch: 88, loss: 0.744, acc: 0.77\n","epoch: 9, batch: 89, loss: 1.003, acc: 0.67\n","epoch: 9, batch: 90, loss: 0.721, acc: 0.75\n","epoch: 9, batch: 91, loss: 0.736, acc: 0.80\n","epoch: 9, batch: 92, loss: 0.931, acc: 0.65\n","epoch: 9, batch: 93, loss: 0.893, acc: 0.66\n","epoch: 9, batch: 94, loss: 0.913, acc: 0.70\n","epoch: 9, batch: 95, loss: 0.773, acc: 0.73\n","epoch: 9, batch: 96, loss: 1.072, acc: 0.67\n","epoch: 9, batch: 97, loss: 0.906, acc: 0.70\n","epoch: 9, batch: 98, loss: 0.852, acc: 0.71\n","epoch: 9, batch: 99, loss: 0.950, acc: 0.64\n","epoch: 9, batch: 100, loss: 0.825, acc: 0.73\n","epoch: 9, batch: 101, loss: 0.766, acc: 0.77\n","epoch: 9, batch: 102, loss: 0.931, acc: 0.69\n","epoch: 9, batch: 103, loss: 0.917, acc: 0.62\n","epoch: 9, batch: 104, loss: 0.842, acc: 0.71\n","epoch: 9, batch: 105, loss: 0.927, acc: 0.73\n","epoch: 9, batch: 106, loss: 0.876, acc: 0.72\n","epoch: 9, batch: 107, loss: 0.898, acc: 0.69\n","epoch: 9, batch: 108, loss: 0.869, acc: 0.70\n","epoch: 9, batch: 109, loss: 0.877, acc: 0.70\n","epoch: 9, batch: 110, loss: 0.892, acc: 0.72\n","epoch: 9, batch: 111, loss: 0.830, acc: 0.73\n","epoch: 9, batch: 112, loss: 0.760, acc: 0.75\n","epoch: 9, batch: 113, loss: 0.852, acc: 0.70\n","epoch: 9, batch: 114, loss: 0.897, acc: 0.67\n","epoch: 9, batch: 115, loss: 0.971, acc: 0.63\n","epoch: 9, batch: 116, loss: 0.849, acc: 0.72\n","epoch: 9, batch: 117, loss: 0.818, acc: 0.66\n","epoch: 9, batch: 118, loss: 0.911, acc: 0.68\n","epoch: 9, batch: 119, loss: 0.811, acc: 0.74\n","epoch: 9, batch: 120, loss: 0.797, acc: 0.72\n","epoch: 9, batch: 121, loss: 0.842, acc: 0.70\n","epoch: 9, batch: 122, loss: 0.948, acc: 0.66\n","epoch: 9, batch: 123, loss: 0.857, acc: 0.69\n","epoch: 9, batch: 124, loss: 1.014, acc: 0.68\n","epoch: 9, batch: 125, loss: 0.994, acc: 0.68\n","epoch: 9, batch: 126, loss: 0.837, acc: 0.72\n","epoch: 9, batch: 127, loss: 0.936, acc: 0.69\n","epoch: 9, batch: 128, loss: 0.979, acc: 0.65\n","epoch: 9, batch: 129, loss: 0.797, acc: 0.72\n","epoch: 9, batch: 130, loss: 0.832, acc: 0.71\n","epoch: 9, batch: 131, loss: 0.936, acc: 0.67\n","epoch: 9, batch: 132, loss: 0.890, acc: 0.71\n","epoch: 9, batch: 133, loss: 1.056, acc: 0.66\n","epoch: 9, batch: 134, loss: 0.869, acc: 0.72\n","epoch: 9, batch: 135, loss: 0.924, acc: 0.71\n","epoch: 9, batch: 136, loss: 0.945, acc: 0.66\n","epoch: 9, batch: 137, loss: 0.904, acc: 0.65\n","epoch: 9, batch: 138, loss: 0.870, acc: 0.71\n","epoch: 9, batch: 139, loss: 0.781, acc: 0.70\n","epoch: 9, batch: 140, loss: 0.836, acc: 0.70\n","epoch: 9, batch: 141, loss: 0.746, acc: 0.74\n","epoch: 9, batch: 142, loss: 0.797, acc: 0.70\n","epoch: 9, batch: 143, loss: 0.862, acc: 0.66\n","epoch: 9, batch: 144, loss: 0.905, acc: 0.67\n","epoch: 9, batch: 145, loss: 0.893, acc: 0.70\n","epoch: 9, batch: 146, loss: 0.797, acc: 0.70\n","epoch: 9, batch: 147, loss: 0.749, acc: 0.77\n","epoch: 9, batch: 148, loss: 1.081, acc: 0.59\n","epoch: 9, batch: 149, loss: 0.943, acc: 0.67\n","epoch: 9, batch: 150, loss: 1.022, acc: 0.65\n","epoch: 9, batch: 151, loss: 1.092, acc: 0.62\n","epoch: 9, batch: 152, loss: 0.865, acc: 0.70\n","epoch: 9, batch: 153, loss: 0.896, acc: 0.68\n","epoch: 9, batch: 154, loss: 0.993, acc: 0.62\n","epoch: 9, batch: 155, loss: 0.875, acc: 0.72\n","epoch: 9, batch: 156, loss: 0.801, acc: 0.72\n","epoch: 9, batch: 157, loss: 0.706, acc: 0.73\n","epoch: 9, batch: 158, loss: 0.911, acc: 0.70\n","epoch: 9, batch: 159, loss: 0.843, acc: 0.70\n","epoch: 9, batch: 160, loss: 0.891, acc: 0.67\n","epoch: 9, batch: 161, loss: 0.905, acc: 0.70\n","epoch: 9, batch: 162, loss: 0.924, acc: 0.66\n","epoch: 9, batch: 163, loss: 1.085, acc: 0.65\n","epoch: 9, batch: 164, loss: 1.161, acc: 0.62\n","epoch: 9, batch: 165, loss: 0.941, acc: 0.70\n","epoch: 9, batch: 166, loss: 0.889, acc: 0.71\n","epoch: 9, batch: 167, loss: 0.847, acc: 0.69\n","epoch: 9, batch: 168, loss: 0.898, acc: 0.68\n","epoch: 9, batch: 169, loss: 0.891, acc: 0.66\n","epoch: 9, batch: 170, loss: 0.766, acc: 0.75\n","epoch: 9, batch: 171, loss: 0.922, acc: 0.65\n","epoch: 9, batch: 172, loss: 0.700, acc: 0.73\n","epoch: 9, batch: 173, loss: 0.952, acc: 0.67\n","epoch: 9, batch: 174, loss: 0.974, acc: 0.60\n","epoch: 9, batch: 175, loss: 1.079, acc: 0.65\n","epoch: 9, batch: 176, loss: 0.905, acc: 0.70\n","epoch: 9, batch: 177, loss: 0.785, acc: 0.76\n","epoch: 9, batch: 178, loss: 0.926, acc: 0.68\n","epoch: 9, batch: 179, loss: 0.889, acc: 0.63\n","epoch: 9, batch: 180, loss: 0.795, acc: 0.73\n","epoch: 9, batch: 181, loss: 0.890, acc: 0.69\n","epoch: 9, batch: 182, loss: 0.798, acc: 0.73\n","epoch: 9, batch: 183, loss: 0.843, acc: 0.71\n","epoch: 9, batch: 184, loss: 0.932, acc: 0.63\n","epoch: 9, batch: 185, loss: 0.957, acc: 0.70\n","epoch: 9, batch: 186, loss: 0.911, acc: 0.67\n","epoch: 9, batch: 187, loss: 0.835, acc: 0.70\n","epoch: 9, batch: 188, loss: 0.812, acc: 0.72\n","epoch: 9, batch: 189, loss: 0.841, acc: 0.67\n","epoch: 9, batch: 190, loss: 0.943, acc: 0.68\n","epoch: 9, batch: 191, loss: 0.861, acc: 0.66\n","epoch: 9, batch: 192, loss: 0.967, acc: 0.69\n","epoch: 9, batch: 193, loss: 0.979, acc: 0.62\n","epoch: 9, batch: 194, loss: 0.994, acc: 0.69\n","epoch: 9, batch: 195, loss: 0.958, acc: 0.67\n","epoch: 9, batch: 196, loss: 0.862, acc: 0.71\n","epoch: 9, batch: 197, loss: 0.813, acc: 0.71\n","epoch: 9, batch: 198, loss: 0.913, acc: 0.65\n","epoch: 9, batch: 199, loss: 1.033, acc: 0.63\n","epoch: 9, batch: 200, loss: 0.951, acc: 0.70\n","epoch: 9, batch: 201, loss: 0.989, acc: 0.66\n","epoch: 9, batch: 202, loss: 0.696, acc: 0.72\n","epoch: 9, batch: 203, loss: 0.724, acc: 0.77\n","epoch: 9, batch: 204, loss: 0.735, acc: 0.74\n","epoch: 9, batch: 205, loss: 0.840, acc: 0.74\n","epoch: 9, batch: 206, loss: 0.894, acc: 0.66\n","epoch: 9, batch: 207, loss: 0.979, acc: 0.68\n","epoch: 9, batch: 208, loss: 0.898, acc: 0.69\n","epoch: 9, batch: 209, loss: 0.840, acc: 0.70\n","epoch: 9, batch: 210, loss: 0.910, acc: 0.66\n","epoch: 9, batch: 211, loss: 0.837, acc: 0.70\n","epoch: 9, batch: 212, loss: 0.920, acc: 0.67\n","epoch: 9, batch: 213, loss: 0.973, acc: 0.71\n","epoch: 9, batch: 214, loss: 0.874, acc: 0.63\n","epoch: 9, batch: 215, loss: 0.941, acc: 0.66\n","epoch: 9, batch: 216, loss: 0.704, acc: 0.76\n","epoch: 9, batch: 217, loss: 0.938, acc: 0.68\n","epoch: 9, batch: 218, loss: 0.757, acc: 0.78\n","epoch: 9, batch: 219, loss: 0.890, acc: 0.71\n","epoch: 9, batch: 220, loss: 0.901, acc: 0.74\n","epoch: 9, batch: 221, loss: 0.996, acc: 0.62\n","epoch: 9, batch: 222, loss: 0.929, acc: 0.68\n","epoch: 9, batch: 223, loss: 0.961, acc: 0.65\n","epoch: 9, batch: 224, loss: 0.871, acc: 0.73\n","epoch: 9, batch: 225, loss: 0.928, acc: 0.68\n","epoch: 9, batch: 226, loss: 0.905, acc: 0.66\n","epoch: 9, batch: 227, loss: 0.885, acc: 0.71\n","epoch: 9, batch: 228, loss: 0.939, acc: 0.72\n","epoch: 9, batch: 229, loss: 0.858, acc: 0.73\n","epoch: 9, batch: 230, loss: 0.875, acc: 0.67\n","epoch: 9, batch: 231, loss: 0.930, acc: 0.72\n","epoch: 9, batch: 232, loss: 0.671, acc: 0.76\n","epoch: 9, batch: 233, loss: 0.717, acc: 0.70\n","epoch: 9, batch: 234, loss: 1.043, acc: 0.59\n","epoch: 9, batch: 235, loss: 0.927, acc: 0.65\n","epoch: 9, batch: 236, loss: 1.017, acc: 0.63\n","epoch: 9, batch: 237, loss: 0.786, acc: 0.70\n","epoch: 9, batch: 238, loss: 0.754, acc: 0.74\n","epoch: 9, batch: 239, loss: 0.760, acc: 0.77\n","epoch: 9, batch: 240, loss: 0.815, acc: 0.73\n","epoch: 9, batch: 241, loss: 0.654, acc: 0.77\n","epoch: 9, batch: 242, loss: 0.740, acc: 0.77\n","epoch: 9, batch: 243, loss: 0.825, acc: 0.67\n","epoch: 9, batch: 244, loss: 0.790, acc: 0.73\n","epoch: 9, batch: 245, loss: 0.808, acc: 0.73\n","epoch: 9, batch: 246, loss: 0.809, acc: 0.74\n","epoch: 9, batch: 247, loss: 0.891, acc: 0.70\n","epoch: 9, batch: 248, loss: 0.853, acc: 0.69\n","epoch: 9, batch: 249, loss: 0.729, acc: 0.78\n","epoch: 9, batch: 250, loss: 0.681, acc: 0.77\n","epoch: 9, batch: 251, loss: 1.024, acc: 0.62\n","epoch: 9, batch: 252, loss: 0.978, acc: 0.70\n","epoch: 9, batch: 253, loss: 0.902, acc: 0.73\n","epoch: 9, batch: 254, loss: 0.897, acc: 0.73\n","epoch: 9, batch: 255, loss: 0.927, acc: 0.66\n","epoch: 9, batch: 256, loss: 0.829, acc: 0.69\n","epoch: 9, batch: 257, loss: 0.865, acc: 0.69\n","epoch: 9, batch: 258, loss: 0.917, acc: 0.69\n","epoch: 9, batch: 259, loss: 0.927, acc: 0.70\n","epoch: 9, batch: 260, loss: 0.908, acc: 0.70\n","epoch: 9, batch: 261, loss: 0.928, acc: 0.68\n","epoch: 9, batch: 262, loss: 0.731, acc: 0.74\n","epoch: 9, batch: 263, loss: 0.885, acc: 0.70\n","epoch: 9, batch: 264, loss: 0.797, acc: 0.75\n","epoch: 9, batch: 265, loss: 0.741, acc: 0.78\n","epoch: 9, batch: 266, loss: 0.909, acc: 0.71\n","epoch: 9, batch: 267, loss: 0.851, acc: 0.68\n","epoch: 9, batch: 268, loss: 0.844, acc: 0.67\n","epoch: 9, batch: 269, loss: 0.855, acc: 0.68\n","epoch: 9, batch: 270, loss: 0.731, acc: 0.74\n","epoch: 9, batch: 271, loss: 0.819, acc: 0.71\n","epoch: 9, batch: 272, loss: 0.818, acc: 0.73\n","epoch: 9, batch: 273, loss: 0.852, acc: 0.73\n","epoch: 9, batch: 274, loss: 0.939, acc: 0.72\n","epoch: 9, batch: 275, loss: 0.884, acc: 0.69\n","epoch: 9, batch: 276, loss: 0.917, acc: 0.70\n","epoch: 9, batch: 277, loss: 0.783, acc: 0.71\n","epoch: 9, batch: 278, loss: 0.827, acc: 0.73\n","epoch: 9, batch: 279, loss: 0.861, acc: 0.76\n","epoch: 9, batch: 280, loss: 0.862, acc: 0.65\n","epoch: 9, batch: 281, loss: 0.791, acc: 0.69\n","epoch: 9, batch: 282, loss: 0.898, acc: 0.70\n","epoch: 9, batch: 283, loss: 0.777, acc: 0.74\n","epoch: 9, batch: 284, loss: 0.948, acc: 0.67\n","epoch: 9, batch: 285, loss: 0.813, acc: 0.75\n","epoch: 9, batch: 286, loss: 0.998, acc: 0.67\n","epoch: 9, batch: 287, loss: 0.981, acc: 0.66\n","epoch: 9, batch: 288, loss: 0.723, acc: 0.73\n","epoch: 9, batch: 289, loss: 1.013, acc: 0.63\n","epoch: 9, batch: 290, loss: 0.784, acc: 0.70\n","epoch: 9, batch: 291, loss: 0.660, acc: 0.78\n","epoch: 9, batch: 292, loss: 0.866, acc: 0.70\n","epoch: 9, batch: 293, loss: 0.897, acc: 0.66\n","epoch: 9, batch: 294, loss: 0.847, acc: 0.70\n","epoch: 9, batch: 295, loss: 0.908, acc: 0.66\n","epoch: 9, batch: 296, loss: 0.942, acc: 0.65\n","epoch: 9, batch: 297, loss: 0.870, acc: 0.66\n","epoch: 9, batch: 298, loss: 1.062, acc: 0.66\n","epoch: 9, batch: 299, loss: 0.862, acc: 0.70\n","epoch: 9, batch: 300, loss: 1.006, acc: 0.65\n","epoch: 9, batch: 301, loss: 0.825, acc: 0.71\n","epoch: 9, batch: 302, loss: 0.837, acc: 0.73\n","epoch: 9, batch: 303, loss: 1.075, acc: 0.62\n","epoch: 9, batch: 304, loss: 0.897, acc: 0.71\n","epoch: 9, batch: 305, loss: 0.768, acc: 0.72\n","epoch: 9, batch: 306, loss: 0.846, acc: 0.71\n","epoch: 9, batch: 307, loss: 0.864, acc: 0.77\n","epoch: 9, batch: 308, loss: 0.740, acc: 0.73\n","epoch: 9, batch: 309, loss: 0.708, acc: 0.72\n","epoch: 9, batch: 310, loss: 0.809, acc: 0.75\n","epoch: 9, batch: 311, loss: 1.015, acc: 0.66\n","epoch: 9, batch: 312, loss: 0.890, acc: 0.69\n","epoch: 9, batch: 313, loss: 0.898, acc: 0.70\n","epoch: 9, batch: 314, loss: 0.901, acc: 0.70\n","epoch: 9, batch: 315, loss: 0.826, acc: 0.73\n","epoch: 9, batch: 316, loss: 0.883, acc: 0.70\n","epoch: 9, batch: 317, loss: 0.760, acc: 0.73\n","epoch: 9, batch: 318, loss: 0.823, acc: 0.69\n","epoch: 9, batch: 319, loss: 0.795, acc: 0.71\n","epoch: 9, batch: 320, loss: 0.812, acc: 0.70\n","epoch: 9, batch: 321, loss: 0.865, acc: 0.69\n","epoch: 9, batch: 322, loss: 0.792, acc: 0.72\n","epoch: 9, batch: 323, loss: 0.795, acc: 0.74\n","epoch: 9, batch: 324, loss: 0.867, acc: 0.69\n","epoch: 9, batch: 325, loss: 0.915, acc: 0.75\n","epoch: 9, batch: 326, loss: 0.944, acc: 0.62\n","epoch: 9, batch: 327, loss: 0.920, acc: 0.74\n","epoch: 9, batch: 328, loss: 0.814, acc: 0.68\n","epoch: 9, batch: 329, loss: 0.963, acc: 0.65\n","epoch: 9, batch: 330, loss: 0.770, acc: 0.73\n","epoch: 9, batch: 331, loss: 0.978, acc: 0.63\n","epoch: 9, batch: 332, loss: 0.865, acc: 0.73\n","epoch: 9, batch: 333, loss: 0.919, acc: 0.67\n","epoch: 9, batch: 334, loss: 0.781, acc: 0.73\n","epoch: 9, batch: 335, loss: 0.938, acc: 0.65\n","epoch: 9, batch: 336, loss: 1.020, acc: 0.68\n","epoch: 9, batch: 337, loss: 0.808, acc: 0.73\n","epoch: 9, batch: 338, loss: 0.913, acc: 0.70\n","epoch: 9, batch: 339, loss: 0.813, acc: 0.71\n","epoch: 9, batch: 340, loss: 0.931, acc: 0.70\n","epoch: 9, batch: 341, loss: 0.990, acc: 0.66\n","epoch: 9, batch: 342, loss: 0.650, acc: 0.77\n","epoch: 9, batch: 343, loss: 1.024, acc: 0.62\n","epoch: 9, batch: 344, loss: 0.941, acc: 0.68\n","epoch: 9, batch: 345, loss: 0.862, acc: 0.71\n","epoch: 9, batch: 346, loss: 0.892, acc: 0.70\n","epoch: 9, batch: 347, loss: 0.944, acc: 0.62\n","epoch: 9, batch: 348, loss: 1.097, acc: 0.60\n","epoch: 9, batch: 349, loss: 0.918, acc: 0.66\n","epoch: 9, batch: 350, loss: 0.913, acc: 0.67\n","epoch: 9, batch: 351, loss: 0.937, acc: 0.68\n","epoch: 9, batch: 352, loss: 1.021, acc: 0.62\n","epoch: 9, batch: 353, loss: 1.015, acc: 0.65\n","epoch: 9, batch: 354, loss: 0.972, acc: 0.66\n","epoch: 9, batch: 355, loss: 0.896, acc: 0.72\n","epoch: 9, batch: 356, loss: 0.960, acc: 0.67\n","epoch: 9, batch: 357, loss: 0.791, acc: 0.76\n","epoch: 9, batch: 358, loss: 0.679, acc: 0.74\n","epoch: 9, batch: 359, loss: 0.864, acc: 0.66\n","epoch: 9, batch: 360, loss: 1.060, acc: 0.66\n","epoch: 9, batch: 361, loss: 0.860, acc: 0.68\n","epoch: 9, batch: 362, loss: 1.039, acc: 0.70\n","epoch: 9, batch: 363, loss: 0.758, acc: 0.73\n","epoch: 9, batch: 364, loss: 0.950, acc: 0.65\n","epoch: 9, batch: 365, loss: 0.883, acc: 0.71\n","epoch: 9, batch: 366, loss: 0.981, acc: 0.66\n","epoch: 9, batch: 367, loss: 0.955, acc: 0.68\n","epoch: 9, batch: 368, loss: 0.750, acc: 0.74\n","epoch: 9, batch: 369, loss: 0.799, acc: 0.75\n","epoch: 9, batch: 370, loss: 0.986, acc: 0.64\n","epoch: 9, batch: 371, loss: 0.790, acc: 0.70\n","epoch: 9, batch: 372, loss: 1.051, acc: 0.65\n","epoch: 9, batch: 373, loss: 0.867, acc: 0.76\n","epoch: 9, batch: 374, loss: 0.737, acc: 0.71\n","epoch: 9, batch: 375, loss: 1.016, acc: 0.62\n","epoch: 9, batch: 376, loss: 0.784, acc: 0.72\n","epoch: 9, batch: 377, loss: 0.865, acc: 0.66\n","epoch: 9, batch: 378, loss: 0.940, acc: 0.70\n","epoch: 9, batch: 379, loss: 0.805, acc: 0.73\n","epoch: 9, batch: 380, loss: 0.885, acc: 0.75\n","epoch: 9, batch: 381, loss: 0.821, acc: 0.71\n","epoch: 9, batch: 382, loss: 0.888, acc: 0.68\n","epoch: 9, batch: 383, loss: 0.794, acc: 0.72\n","epoch: 9, batch: 384, loss: 0.956, acc: 0.66\n","epoch: 9, batch: 385, loss: 0.837, acc: 0.66\n","epoch: 9, batch: 386, loss: 0.735, acc: 0.79\n","epoch: 9, batch: 387, loss: 0.820, acc: 0.72\n","epoch: 9, batch: 388, loss: 0.748, acc: 0.73\n","epoch: 9, batch: 389, loss: 0.775, acc: 0.72\n","epoch: 9, batch: 390, loss: 0.799, acc: 0.70\n","epoch: 9, batch: 391, loss: 0.688, acc: 0.81\n","epoch: 10, batch: 1, loss: 0.893, acc: 0.67\n","epoch: 10, batch: 2, loss: 0.813, acc: 0.72\n","epoch: 10, batch: 3, loss: 0.767, acc: 0.72\n","epoch: 10, batch: 4, loss: 0.785, acc: 0.70\n","epoch: 10, batch: 5, loss: 0.892, acc: 0.69\n","epoch: 10, batch: 6, loss: 0.818, acc: 0.73\n","epoch: 10, batch: 7, loss: 0.954, acc: 0.65\n","epoch: 10, batch: 8, loss: 0.906, acc: 0.76\n","epoch: 10, batch: 9, loss: 0.953, acc: 0.63\n","epoch: 10, batch: 10, loss: 0.963, acc: 0.68\n","epoch: 10, batch: 11, loss: 0.884, acc: 0.70\n","epoch: 10, batch: 12, loss: 0.825, acc: 0.68\n","epoch: 10, batch: 13, loss: 0.690, acc: 0.79\n","epoch: 10, batch: 14, loss: 1.204, acc: 0.63\n","epoch: 10, batch: 15, loss: 0.853, acc: 0.70\n","epoch: 10, batch: 16, loss: 1.027, acc: 0.67\n","epoch: 10, batch: 17, loss: 0.719, acc: 0.75\n","epoch: 10, batch: 18, loss: 0.916, acc: 0.64\n","epoch: 10, batch: 19, loss: 0.703, acc: 0.74\n","epoch: 10, batch: 20, loss: 0.923, acc: 0.67\n","epoch: 10, batch: 21, loss: 0.865, acc: 0.72\n","epoch: 10, batch: 22, loss: 0.824, acc: 0.73\n","epoch: 10, batch: 23, loss: 0.800, acc: 0.70\n","epoch: 10, batch: 24, loss: 0.851, acc: 0.69\n","epoch: 10, batch: 25, loss: 0.949, acc: 0.64\n","epoch: 10, batch: 26, loss: 0.683, acc: 0.77\n","epoch: 10, batch: 27, loss: 0.929, acc: 0.70\n","epoch: 10, batch: 28, loss: 0.956, acc: 0.67\n","epoch: 10, batch: 29, loss: 0.892, acc: 0.73\n","epoch: 10, batch: 30, loss: 0.857, acc: 0.72\n","epoch: 10, batch: 31, loss: 0.748, acc: 0.75\n","epoch: 10, batch: 32, loss: 0.883, acc: 0.70\n","epoch: 10, batch: 33, loss: 0.925, acc: 0.68\n","epoch: 10, batch: 34, loss: 0.991, acc: 0.64\n","epoch: 10, batch: 35, loss: 0.870, acc: 0.70\n","epoch: 10, batch: 36, loss: 0.851, acc: 0.73\n","epoch: 10, batch: 37, loss: 0.822, acc: 0.66\n","epoch: 10, batch: 38, loss: 0.989, acc: 0.69\n","epoch: 10, batch: 39, loss: 1.001, acc: 0.66\n","epoch: 10, batch: 40, loss: 0.852, acc: 0.68\n","epoch: 10, batch: 41, loss: 0.921, acc: 0.71\n","epoch: 10, batch: 42, loss: 0.881, acc: 0.74\n","epoch: 10, batch: 43, loss: 0.750, acc: 0.73\n","epoch: 10, batch: 44, loss: 0.873, acc: 0.70\n","epoch: 10, batch: 45, loss: 0.914, acc: 0.67\n","epoch: 10, batch: 46, loss: 0.911, acc: 0.68\n","epoch: 10, batch: 47, loss: 0.770, acc: 0.71\n","epoch: 10, batch: 48, loss: 0.844, acc: 0.73\n","epoch: 10, batch: 49, loss: 0.850, acc: 0.72\n","epoch: 10, batch: 50, loss: 0.902, acc: 0.65\n","epoch: 10, batch: 51, loss: 0.908, acc: 0.63\n","epoch: 10, batch: 52, loss: 0.870, acc: 0.65\n","epoch: 10, batch: 53, loss: 0.925, acc: 0.70\n","epoch: 10, batch: 54, loss: 0.900, acc: 0.73\n","epoch: 10, batch: 55, loss: 0.948, acc: 0.66\n","epoch: 10, batch: 56, loss: 0.742, acc: 0.72\n","epoch: 10, batch: 57, loss: 0.839, acc: 0.72\n","epoch: 10, batch: 58, loss: 0.929, acc: 0.71\n","epoch: 10, batch: 59, loss: 0.883, acc: 0.74\n","epoch: 10, batch: 60, loss: 0.875, acc: 0.73\n","epoch: 10, batch: 61, loss: 0.974, acc: 0.65\n","epoch: 10, batch: 62, loss: 0.779, acc: 0.74\n","epoch: 10, batch: 63, loss: 0.796, acc: 0.73\n","epoch: 10, batch: 64, loss: 0.842, acc: 0.73\n","epoch: 10, batch: 65, loss: 0.871, acc: 0.67\n","epoch: 10, batch: 66, loss: 0.904, acc: 0.73\n","epoch: 10, batch: 67, loss: 0.691, acc: 0.74\n","epoch: 10, batch: 68, loss: 0.813, acc: 0.70\n","epoch: 10, batch: 69, loss: 0.855, acc: 0.68\n","epoch: 10, batch: 70, loss: 0.852, acc: 0.68\n","epoch: 10, batch: 71, loss: 0.928, acc: 0.70\n","epoch: 10, batch: 72, loss: 0.916, acc: 0.67\n","epoch: 10, batch: 73, loss: 0.766, acc: 0.77\n","epoch: 10, batch: 74, loss: 0.908, acc: 0.73\n","epoch: 10, batch: 75, loss: 1.070, acc: 0.63\n","epoch: 10, batch: 76, loss: 0.861, acc: 0.66\n","epoch: 10, batch: 77, loss: 1.001, acc: 0.64\n","epoch: 10, batch: 78, loss: 1.090, acc: 0.66\n","epoch: 10, batch: 79, loss: 0.860, acc: 0.66\n","epoch: 10, batch: 80, loss: 0.905, acc: 0.70\n","epoch: 10, batch: 81, loss: 0.966, acc: 0.64\n","epoch: 10, batch: 82, loss: 0.795, acc: 0.66\n","epoch: 10, batch: 83, loss: 0.834, acc: 0.73\n","epoch: 10, batch: 84, loss: 0.883, acc: 0.69\n","epoch: 10, batch: 85, loss: 1.021, acc: 0.69\n","epoch: 10, batch: 86, loss: 0.874, acc: 0.73\n","epoch: 10, batch: 87, loss: 0.856, acc: 0.74\n","epoch: 10, batch: 88, loss: 0.995, acc: 0.71\n","epoch: 10, batch: 89, loss: 0.908, acc: 0.70\n","epoch: 10, batch: 90, loss: 0.635, acc: 0.85\n","epoch: 10, batch: 91, loss: 0.929, acc: 0.68\n","epoch: 10, batch: 92, loss: 1.052, acc: 0.63\n","epoch: 10, batch: 93, loss: 0.855, acc: 0.72\n","epoch: 10, batch: 94, loss: 0.871, acc: 0.69\n","epoch: 10, batch: 95, loss: 0.866, acc: 0.70\n","epoch: 10, batch: 96, loss: 0.685, acc: 0.80\n","epoch: 10, batch: 97, loss: 0.992, acc: 0.66\n","epoch: 10, batch: 98, loss: 0.928, acc: 0.67\n","epoch: 10, batch: 99, loss: 0.774, acc: 0.77\n","epoch: 10, batch: 100, loss: 0.787, acc: 0.74\n","epoch: 10, batch: 101, loss: 0.806, acc: 0.72\n","epoch: 10, batch: 102, loss: 0.803, acc: 0.71\n","epoch: 10, batch: 103, loss: 1.071, acc: 0.62\n","epoch: 10, batch: 104, loss: 0.771, acc: 0.73\n","epoch: 10, batch: 105, loss: 0.904, acc: 0.68\n","epoch: 10, batch: 106, loss: 0.943, acc: 0.67\n","epoch: 10, batch: 107, loss: 0.850, acc: 0.73\n","epoch: 10, batch: 108, loss: 0.697, acc: 0.75\n","epoch: 10, batch: 109, loss: 0.920, acc: 0.70\n","epoch: 10, batch: 110, loss: 0.911, acc: 0.71\n","epoch: 10, batch: 111, loss: 0.816, acc: 0.75\n","epoch: 10, batch: 112, loss: 0.666, acc: 0.75\n","epoch: 10, batch: 113, loss: 0.760, acc: 0.75\n","epoch: 10, batch: 114, loss: 0.874, acc: 0.70\n","epoch: 10, batch: 115, loss: 0.754, acc: 0.73\n","epoch: 10, batch: 116, loss: 0.848, acc: 0.70\n","epoch: 10, batch: 117, loss: 0.917, acc: 0.70\n","epoch: 10, batch: 118, loss: 0.823, acc: 0.73\n","epoch: 10, batch: 119, loss: 0.874, acc: 0.71\n","epoch: 10, batch: 120, loss: 0.802, acc: 0.74\n","epoch: 10, batch: 121, loss: 0.769, acc: 0.74\n","epoch: 10, batch: 122, loss: 0.806, acc: 0.71\n","epoch: 10, batch: 123, loss: 1.052, acc: 0.60\n","epoch: 10, batch: 124, loss: 0.749, acc: 0.77\n","epoch: 10, batch: 125, loss: 0.779, acc: 0.73\n","epoch: 10, batch: 126, loss: 0.798, acc: 0.69\n","epoch: 10, batch: 127, loss: 0.807, acc: 0.70\n","epoch: 10, batch: 128, loss: 0.913, acc: 0.66\n","epoch: 10, batch: 129, loss: 0.917, acc: 0.70\n","epoch: 10, batch: 130, loss: 0.879, acc: 0.70\n","epoch: 10, batch: 131, loss: 0.971, acc: 0.70\n","epoch: 10, batch: 132, loss: 0.814, acc: 0.73\n","epoch: 10, batch: 133, loss: 0.947, acc: 0.64\n","epoch: 10, batch: 134, loss: 0.879, acc: 0.72\n","epoch: 10, batch: 135, loss: 0.906, acc: 0.70\n","epoch: 10, batch: 136, loss: 0.770, acc: 0.74\n","epoch: 10, batch: 137, loss: 0.820, acc: 0.73\n","epoch: 10, batch: 138, loss: 0.724, acc: 0.73\n","epoch: 10, batch: 139, loss: 0.939, acc: 0.69\n","epoch: 10, batch: 140, loss: 0.981, acc: 0.67\n","epoch: 10, batch: 141, loss: 0.824, acc: 0.75\n","epoch: 10, batch: 142, loss: 0.872, acc: 0.67\n","epoch: 10, batch: 143, loss: 0.930, acc: 0.65\n","epoch: 10, batch: 144, loss: 0.856, acc: 0.70\n","epoch: 10, batch: 145, loss: 0.990, acc: 0.65\n","epoch: 10, batch: 146, loss: 0.698, acc: 0.76\n","epoch: 10, batch: 147, loss: 0.957, acc: 0.70\n","epoch: 10, batch: 148, loss: 0.927, acc: 0.70\n","epoch: 10, batch: 149, loss: 0.863, acc: 0.68\n","epoch: 10, batch: 150, loss: 0.850, acc: 0.70\n","epoch: 10, batch: 151, loss: 0.717, acc: 0.79\n","epoch: 10, batch: 152, loss: 0.829, acc: 0.74\n","epoch: 10, batch: 153, loss: 0.875, acc: 0.68\n","epoch: 10, batch: 154, loss: 0.989, acc: 0.65\n","epoch: 10, batch: 155, loss: 0.835, acc: 0.72\n","epoch: 10, batch: 156, loss: 0.992, acc: 0.61\n","epoch: 10, batch: 157, loss: 0.985, acc: 0.66\n","epoch: 10, batch: 158, loss: 0.847, acc: 0.67\n","epoch: 10, batch: 159, loss: 0.854, acc: 0.73\n","epoch: 10, batch: 160, loss: 0.758, acc: 0.76\n","epoch: 10, batch: 161, loss: 0.786, acc: 0.75\n","epoch: 10, batch: 162, loss: 0.975, acc: 0.66\n","epoch: 10, batch: 163, loss: 0.979, acc: 0.70\n","epoch: 10, batch: 164, loss: 0.755, acc: 0.77\n","epoch: 10, batch: 165, loss: 0.892, acc: 0.70\n","epoch: 10, batch: 166, loss: 0.785, acc: 0.74\n","epoch: 10, batch: 167, loss: 0.974, acc: 0.62\n","epoch: 10, batch: 168, loss: 0.945, acc: 0.62\n","epoch: 10, batch: 169, loss: 0.902, acc: 0.65\n","epoch: 10, batch: 170, loss: 0.848, acc: 0.71\n","epoch: 10, batch: 171, loss: 0.903, acc: 0.66\n","epoch: 10, batch: 172, loss: 0.806, acc: 0.70\n","epoch: 10, batch: 173, loss: 0.896, acc: 0.73\n","epoch: 10, batch: 174, loss: 0.965, acc: 0.65\n","epoch: 10, batch: 175, loss: 0.976, acc: 0.70\n","epoch: 10, batch: 176, loss: 0.835, acc: 0.74\n","epoch: 10, batch: 177, loss: 0.847, acc: 0.68\n","epoch: 10, batch: 178, loss: 0.763, acc: 0.76\n","epoch: 10, batch: 179, loss: 0.974, acc: 0.67\n","epoch: 10, batch: 180, loss: 0.873, acc: 0.68\n","epoch: 10, batch: 181, loss: 0.757, acc: 0.74\n","epoch: 10, batch: 182, loss: 0.813, acc: 0.73\n","epoch: 10, batch: 183, loss: 0.972, acc: 0.65\n","epoch: 10, batch: 184, loss: 0.708, acc: 0.73\n","epoch: 10, batch: 185, loss: 0.691, acc: 0.73\n","epoch: 10, batch: 186, loss: 0.944, acc: 0.68\n","epoch: 10, batch: 187, loss: 0.795, acc: 0.70\n","epoch: 10, batch: 188, loss: 0.788, acc: 0.70\n","epoch: 10, batch: 189, loss: 0.813, acc: 0.70\n","epoch: 10, batch: 190, loss: 0.752, acc: 0.73\n","epoch: 10, batch: 191, loss: 0.793, acc: 0.73\n","epoch: 10, batch: 192, loss: 0.952, acc: 0.66\n","epoch: 10, batch: 193, loss: 0.728, acc: 0.71\n","epoch: 10, batch: 194, loss: 0.858, acc: 0.66\n","epoch: 10, batch: 195, loss: 0.844, acc: 0.70\n","epoch: 10, batch: 196, loss: 0.843, acc: 0.68\n","epoch: 10, batch: 197, loss: 0.890, acc: 0.74\n","epoch: 10, batch: 198, loss: 0.757, acc: 0.75\n","epoch: 10, batch: 199, loss: 0.771, acc: 0.70\n","epoch: 10, batch: 200, loss: 1.030, acc: 0.66\n","epoch: 10, batch: 201, loss: 0.783, acc: 0.75\n","epoch: 10, batch: 202, loss: 1.021, acc: 0.65\n","epoch: 10, batch: 203, loss: 0.836, acc: 0.73\n","epoch: 10, batch: 204, loss: 0.906, acc: 0.66\n","epoch: 10, batch: 205, loss: 0.785, acc: 0.73\n","epoch: 10, batch: 206, loss: 0.734, acc: 0.73\n","epoch: 10, batch: 207, loss: 0.837, acc: 0.70\n","epoch: 10, batch: 208, loss: 1.091, acc: 0.62\n","epoch: 10, batch: 209, loss: 0.906, acc: 0.65\n","epoch: 10, batch: 210, loss: 0.699, acc: 0.73\n","epoch: 10, batch: 211, loss: 0.730, acc: 0.72\n","epoch: 10, batch: 212, loss: 0.752, acc: 0.73\n","epoch: 10, batch: 213, loss: 0.829, acc: 0.69\n","epoch: 10, batch: 214, loss: 0.768, acc: 0.74\n","epoch: 10, batch: 215, loss: 1.039, acc: 0.62\n","epoch: 10, batch: 216, loss: 0.871, acc: 0.70\n","epoch: 10, batch: 217, loss: 0.727, acc: 0.77\n","epoch: 10, batch: 218, loss: 0.657, acc: 0.83\n","epoch: 10, batch: 219, loss: 0.881, acc: 0.70\n","epoch: 10, batch: 220, loss: 0.870, acc: 0.68\n","epoch: 10, batch: 221, loss: 0.981, acc: 0.66\n","epoch: 10, batch: 222, loss: 0.850, acc: 0.71\n","epoch: 10, batch: 223, loss: 0.799, acc: 0.75\n","epoch: 10, batch: 224, loss: 0.785, acc: 0.74\n","epoch: 10, batch: 225, loss: 1.009, acc: 0.65\n","epoch: 10, batch: 226, loss: 0.849, acc: 0.72\n","epoch: 10, batch: 227, loss: 0.905, acc: 0.74\n","epoch: 10, batch: 228, loss: 0.868, acc: 0.71\n","epoch: 10, batch: 229, loss: 0.843, acc: 0.68\n","epoch: 10, batch: 230, loss: 0.982, acc: 0.63\n","epoch: 10, batch: 231, loss: 0.780, acc: 0.73\n","epoch: 10, batch: 232, loss: 0.755, acc: 0.73\n","epoch: 10, batch: 233, loss: 0.755, acc: 0.74\n","epoch: 10, batch: 234, loss: 0.828, acc: 0.71\n","epoch: 10, batch: 235, loss: 0.694, acc: 0.78\n","epoch: 10, batch: 236, loss: 0.771, acc: 0.75\n","epoch: 10, batch: 237, loss: 0.957, acc: 0.70\n","epoch: 10, batch: 238, loss: 0.837, acc: 0.70\n","epoch: 10, batch: 239, loss: 0.783, acc: 0.74\n","epoch: 10, batch: 240, loss: 0.646, acc: 0.79\n","epoch: 10, batch: 241, loss: 0.704, acc: 0.81\n","epoch: 10, batch: 242, loss: 0.774, acc: 0.72\n","epoch: 10, batch: 243, loss: 0.868, acc: 0.68\n","epoch: 10, batch: 244, loss: 0.834, acc: 0.75\n","epoch: 10, batch: 245, loss: 0.969, acc: 0.66\n","epoch: 10, batch: 246, loss: 0.875, acc: 0.76\n","epoch: 10, batch: 247, loss: 0.801, acc: 0.71\n","epoch: 10, batch: 248, loss: 0.783, acc: 0.73\n","epoch: 10, batch: 249, loss: 0.880, acc: 0.69\n","epoch: 10, batch: 250, loss: 0.767, acc: 0.74\n","epoch: 10, batch: 251, loss: 0.850, acc: 0.68\n","epoch: 10, batch: 252, loss: 0.955, acc: 0.72\n","epoch: 10, batch: 253, loss: 0.844, acc: 0.78\n","epoch: 10, batch: 254, loss: 0.971, acc: 0.71\n","epoch: 10, batch: 255, loss: 0.797, acc: 0.71\n","epoch: 10, batch: 256, loss: 0.730, acc: 0.73\n","epoch: 10, batch: 257, loss: 0.817, acc: 0.71\n","epoch: 10, batch: 258, loss: 0.973, acc: 0.68\n","epoch: 10, batch: 259, loss: 0.783, acc: 0.73\n","epoch: 10, batch: 260, loss: 0.767, acc: 0.70\n","epoch: 10, batch: 261, loss: 0.714, acc: 0.77\n","epoch: 10, batch: 262, loss: 0.798, acc: 0.75\n","epoch: 10, batch: 263, loss: 0.875, acc: 0.68\n","epoch: 10, batch: 264, loss: 0.731, acc: 0.77\n","epoch: 10, batch: 265, loss: 0.707, acc: 0.74\n","epoch: 10, batch: 266, loss: 0.899, acc: 0.66\n","epoch: 10, batch: 267, loss: 0.929, acc: 0.65\n","epoch: 10, batch: 268, loss: 0.760, acc: 0.77\n","epoch: 10, batch: 269, loss: 0.688, acc: 0.80\n","epoch: 10, batch: 270, loss: 0.943, acc: 0.72\n","epoch: 10, batch: 271, loss: 0.839, acc: 0.73\n","epoch: 10, batch: 272, loss: 0.774, acc: 0.74\n","epoch: 10, batch: 273, loss: 0.768, acc: 0.77\n","epoch: 10, batch: 274, loss: 0.881, acc: 0.66\n","epoch: 10, batch: 275, loss: 0.871, acc: 0.66\n","epoch: 10, batch: 276, loss: 0.905, acc: 0.73\n","epoch: 10, batch: 277, loss: 0.747, acc: 0.73\n","epoch: 10, batch: 278, loss: 0.910, acc: 0.71\n","epoch: 10, batch: 279, loss: 0.851, acc: 0.65\n","epoch: 10, batch: 280, loss: 0.744, acc: 0.77\n","epoch: 10, batch: 281, loss: 0.902, acc: 0.66\n","epoch: 10, batch: 282, loss: 0.866, acc: 0.72\n","epoch: 10, batch: 283, loss: 0.868, acc: 0.67\n","epoch: 10, batch: 284, loss: 0.725, acc: 0.71\n","epoch: 10, batch: 285, loss: 0.802, acc: 0.77\n","epoch: 10, batch: 286, loss: 0.837, acc: 0.64\n","epoch: 10, batch: 287, loss: 0.788, acc: 0.70\n","epoch: 10, batch: 288, loss: 0.897, acc: 0.69\n","epoch: 10, batch: 289, loss: 0.920, acc: 0.67\n","epoch: 10, batch: 290, loss: 0.798, acc: 0.66\n","epoch: 10, batch: 291, loss: 0.732, acc: 0.73\n","epoch: 10, batch: 292, loss: 0.899, acc: 0.66\n","epoch: 10, batch: 293, loss: 0.849, acc: 0.72\n","epoch: 10, batch: 294, loss: 0.950, acc: 0.70\n","epoch: 10, batch: 295, loss: 0.652, acc: 0.77\n","epoch: 10, batch: 296, loss: 0.883, acc: 0.70\n","epoch: 10, batch: 297, loss: 1.002, acc: 0.62\n","epoch: 10, batch: 298, loss: 0.879, acc: 0.68\n","epoch: 10, batch: 299, loss: 0.795, acc: 0.74\n","epoch: 10, batch: 300, loss: 1.004, acc: 0.66\n","epoch: 10, batch: 301, loss: 1.000, acc: 0.65\n","epoch: 10, batch: 302, loss: 0.927, acc: 0.71\n","epoch: 10, batch: 303, loss: 0.837, acc: 0.73\n","epoch: 10, batch: 304, loss: 0.885, acc: 0.70\n","epoch: 10, batch: 305, loss: 0.853, acc: 0.68\n","epoch: 10, batch: 306, loss: 0.803, acc: 0.73\n","epoch: 10, batch: 307, loss: 0.658, acc: 0.74\n","epoch: 10, batch: 308, loss: 0.930, acc: 0.70\n","epoch: 10, batch: 309, loss: 0.840, acc: 0.73\n","epoch: 10, batch: 310, loss: 0.825, acc: 0.72\n","epoch: 10, batch: 311, loss: 0.910, acc: 0.70\n","epoch: 10, batch: 312, loss: 0.919, acc: 0.70\n","epoch: 10, batch: 313, loss: 0.748, acc: 0.77\n","epoch: 10, batch: 314, loss: 0.816, acc: 0.71\n","epoch: 10, batch: 315, loss: 0.731, acc: 0.76\n","epoch: 10, batch: 316, loss: 0.894, acc: 0.70\n","epoch: 10, batch: 317, loss: 0.905, acc: 0.72\n","epoch: 10, batch: 318, loss: 0.692, acc: 0.77\n","epoch: 10, batch: 319, loss: 0.832, acc: 0.70\n","epoch: 10, batch: 320, loss: 0.835, acc: 0.70\n","epoch: 10, batch: 321, loss: 0.781, acc: 0.75\n","epoch: 10, batch: 322, loss: 0.830, acc: 0.71\n","epoch: 10, batch: 323, loss: 0.781, acc: 0.73\n","epoch: 10, batch: 324, loss: 0.724, acc: 0.80\n","epoch: 10, batch: 325, loss: 0.697, acc: 0.77\n","epoch: 10, batch: 326, loss: 1.026, acc: 0.70\n","epoch: 10, batch: 327, loss: 0.801, acc: 0.73\n","epoch: 10, batch: 328, loss: 0.870, acc: 0.70\n","epoch: 10, batch: 329, loss: 0.947, acc: 0.64\n","epoch: 10, batch: 330, loss: 0.832, acc: 0.68\n","epoch: 10, batch: 331, loss: 0.972, acc: 0.64\n","epoch: 10, batch: 332, loss: 1.035, acc: 0.66\n","epoch: 10, batch: 333, loss: 0.882, acc: 0.68\n","epoch: 10, batch: 334, loss: 1.005, acc: 0.62\n","epoch: 10, batch: 335, loss: 0.839, acc: 0.70\n","epoch: 10, batch: 336, loss: 0.929, acc: 0.70\n","epoch: 10, batch: 337, loss: 0.830, acc: 0.73\n","epoch: 10, batch: 338, loss: 0.999, acc: 0.66\n","epoch: 10, batch: 339, loss: 0.752, acc: 0.76\n","epoch: 10, batch: 340, loss: 0.793, acc: 0.73\n","epoch: 10, batch: 341, loss: 0.901, acc: 0.71\n","epoch: 10, batch: 342, loss: 1.039, acc: 0.66\n","epoch: 10, batch: 343, loss: 0.974, acc: 0.67\n","epoch: 10, batch: 344, loss: 0.784, acc: 0.69\n","epoch: 10, batch: 345, loss: 0.711, acc: 0.79\n","epoch: 10, batch: 346, loss: 0.859, acc: 0.70\n","epoch: 10, batch: 347, loss: 0.865, acc: 0.69\n","epoch: 10, batch: 348, loss: 0.713, acc: 0.74\n","epoch: 10, batch: 349, loss: 0.792, acc: 0.68\n","epoch: 10, batch: 350, loss: 0.935, acc: 0.68\n","epoch: 10, batch: 351, loss: 0.950, acc: 0.66\n","epoch: 10, batch: 352, loss: 0.863, acc: 0.71\n","epoch: 10, batch: 353, loss: 0.775, acc: 0.66\n","epoch: 10, batch: 354, loss: 0.909, acc: 0.71\n","epoch: 10, batch: 355, loss: 1.017, acc: 0.64\n","epoch: 10, batch: 356, loss: 0.934, acc: 0.66\n","epoch: 10, batch: 357, loss: 0.895, acc: 0.69\n","epoch: 10, batch: 358, loss: 0.829, acc: 0.71\n","epoch: 10, batch: 359, loss: 0.848, acc: 0.71\n","epoch: 10, batch: 360, loss: 0.725, acc: 0.73\n","epoch: 10, batch: 361, loss: 1.019, acc: 0.67\n","epoch: 10, batch: 362, loss: 0.954, acc: 0.66\n","epoch: 10, batch: 363, loss: 0.950, acc: 0.70\n","epoch: 10, batch: 364, loss: 0.846, acc: 0.74\n","epoch: 10, batch: 365, loss: 0.815, acc: 0.69\n","epoch: 10, batch: 366, loss: 0.887, acc: 0.73\n","epoch: 10, batch: 367, loss: 0.965, acc: 0.65\n","epoch: 10, batch: 368, loss: 0.757, acc: 0.79\n","epoch: 10, batch: 369, loss: 0.806, acc: 0.76\n","epoch: 10, batch: 370, loss: 0.710, acc: 0.80\n","epoch: 10, batch: 371, loss: 0.918, acc: 0.69\n","epoch: 10, batch: 372, loss: 0.989, acc: 0.64\n","epoch: 10, batch: 373, loss: 0.897, acc: 0.63\n","epoch: 10, batch: 374, loss: 0.593, acc: 0.80\n","epoch: 10, batch: 375, loss: 0.896, acc: 0.68\n","epoch: 10, batch: 376, loss: 0.716, acc: 0.73\n","epoch: 10, batch: 377, loss: 0.903, acc: 0.66\n","epoch: 10, batch: 378, loss: 0.822, acc: 0.68\n","epoch: 10, batch: 379, loss: 0.666, acc: 0.75\n","epoch: 10, batch: 380, loss: 0.958, acc: 0.68\n","epoch: 10, batch: 381, loss: 0.915, acc: 0.66\n","epoch: 10, batch: 382, loss: 0.749, acc: 0.71\n","epoch: 10, batch: 383, loss: 0.762, acc: 0.72\n","epoch: 10, batch: 384, loss: 0.720, acc: 0.77\n","epoch: 10, batch: 385, loss: 0.755, acc: 0.73\n","epoch: 10, batch: 386, loss: 0.873, acc: 0.70\n","epoch: 10, batch: 387, loss: 0.880, acc: 0.77\n","epoch: 10, batch: 388, loss: 0.742, acc: 0.76\n","epoch: 10, batch: 389, loss: 0.823, acc: 0.73\n","epoch: 10, batch: 390, loss: 0.871, acc: 0.66\n","epoch: 10, batch: 391, loss: 0.841, acc: 0.71\n"]}]},{"cell_type":"markdown","metadata":{"id":"QUOpEZR4T9-O"},"source":["# GradientTape 커스텀 학습"]},{"cell_type":"code","metadata":{"id":"MAHBhmpBS3mS","executionInfo":{"status":"ok","timestamp":1630918690001,"user_tz":-540,"elapsed":216,"user":{"displayName":"김별희","photoUrl":"","userId":"06602448826503759202"}}},"source":["model = Sequential([\n","                    Conv2D(32, 3, activation='relu', input_shape=(32, 32, 3)),\n","                    MaxPooling2D(2, 2),\n","                    Conv2D(64, 3, activation='relu'),\n","                    MaxPooling2D(2, 2),\n","                    Flatten(),\n","                    Dense(32, activation='relu'),\n","                    Dense(10, activation='softmax'),\n","])"],"execution_count":37,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Mt-VKsjLVEKj","executionInfo":{"status":"ok","timestamp":1630918696386,"user_tz":-540,"elapsed":254,"user":{"displayName":"김별희","photoUrl":"","userId":"06602448826503759202"}},"outputId":"f161fafb-586c-4259-844f-738e2345472e"},"source":["model.summary()"],"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_15 (Conv2D)           (None, 30, 30, 32)        896       \n","_________________________________________________________________\n","max_pooling2d_14 (MaxPooling (None, 15, 15, 32)        0         \n","_________________________________________________________________\n","conv2d_16 (Conv2D)           (None, 13, 13, 64)        18496     \n","_________________________________________________________________\n","max_pooling2d_15 (MaxPooling (None, 6, 6, 64)          0         \n","_________________________________________________________________\n","flatten_3 (Flatten)          (None, 2304)              0         \n","_________________________________________________________________\n","dense_6 (Dense)              (None, 32)                73760     \n","_________________________________________________________________\n","dense_7 (Dense)              (None, 10)                330       \n","=================================================================\n","Total params: 93,482\n","Trainable params: 93,482\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","metadata":{"id":"5sRTP3PxVFtq","executionInfo":{"status":"ok","timestamp":1630918732653,"user_tz":-540,"elapsed":212,"user":{"displayName":"김별희","photoUrl":"","userId":"06602448826503759202"}}},"source":["loss_function = tf.keras.losses.SparseCategoricalCrossentropy()\n","optimizer = tf.keras.optimizers.Adam()"],"execution_count":40,"outputs":[]},{"cell_type":"code","metadata":{"id":"5INVYX4PVNPi","executionInfo":{"status":"ok","timestamp":1630918955763,"user_tz":-540,"elapsed":212,"user":{"displayName":"김별희","photoUrl":"","userId":"06602448826503759202"}}},"source":["train_loss = tf.keras.metrics.Mean(name='train_loss')\n","train_acc = tf.keras.metrics.SparseCategoricalAccuracy(name='train_acc')\n","\n","valid_loss = tf.keras.metrics.Mean(name='valid_loss')\n","valid_acc = tf.keras.metrics.SparseCategoricalAccuracy(name='valid_acc')"],"execution_count":41,"outputs":[]},{"cell_type":"code","metadata":{"id":"sVxW_Y3NWFDh","executionInfo":{"status":"ok","timestamp":1630919955128,"user_tz":-540,"elapsed":219,"user":{"displayName":"김별희","photoUrl":"","userId":"06602448826503759202"}}},"source":["@tf.function\n","\n","def train_step(image, label):\n","  with tf.GradientTape() as tape:\n","    prediction = model(image, training=True)\n","    loss = loss_function(label, prediction)\n","\n","  gradients = tape.gradient(loss, model.trainable_variables)\n","  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n","\n","  train_loss(loss)\n","  train_acc(label, prediction)"],"execution_count":49,"outputs":[]},{"cell_type":"code","metadata":{"id":"7UcBtFgrW3UR","executionInfo":{"status":"ok","timestamp":1630919956706,"user_tz":-540,"elapsed":369,"user":{"displayName":"김별희","photoUrl":"","userId":"06602448826503759202"}}},"source":["@tf.function\n","\n","def valid_step(image, label):\n","  prediction = model(image, training=False)\n","  loss = loss_function(label, prediction)\n","\n","  valid_loss(loss)\n","  valid_acc(label, prediction)"],"execution_count":50,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gZxAMpMqZCra","executionInfo":{"status":"ok","timestamp":1630920018066,"user_tz":-540,"elapsed":60425,"user":{"displayName":"김별희","photoUrl":"","userId":"06602448826503759202"}},"outputId":"f7a81364-b182-4a88-a545-65e8177b962b"},"source":["EPOCHS = 10\n","\n","for epoch in range(EPOCHS):\n","  train_loss.reset_states()\n","  train_acc.reset_states()\n","  valid_loss.reset_states()\n","  valid_acc.reset_states()\n","\n","  for image, label in train_data:\n","    train_step(image, label)\n","\n","  for image, label in valid_data:\n","    valid_step(image, label)\n","\n","  print(f'epoch :{epoch+1}, loss :{train_loss.result()}, acc: {train_acc.result()}, val_loss: {valid_loss.result()}, val_accc: {valid_acc.result()}')"],"execution_count":51,"outputs":[{"output_type":"stream","name":"stdout","text":["epoch :1, loss :1.6576952934265137, acc: 0.39976000785827637, val_loss: 1.4008327722549438, val_accc: 0.501800000667572\n","epoch :2, loss :1.3097424507141113, acc: 0.5357000231742859, val_loss: 1.2179440259933472, val_accc: 0.5687999725341797\n","epoch :3, loss :1.1825929880142212, acc: 0.5863199830055237, val_loss: 1.154996633529663, val_accc: 0.593500018119812\n","epoch :4, loss :1.0932848453521729, acc: 0.6168799996376038, val_loss: 1.093947410583496, val_accc: 0.6190000176429749\n","epoch :5, loss :1.031445860862732, acc: 0.6390399932861328, val_loss: 1.055542230606079, val_accc: 0.6377999782562256\n","epoch :6, loss :0.9823026061058044, acc: 0.6575199961662292, val_loss: 1.0182693004608154, val_accc: 0.6517999768257141\n","epoch :7, loss :0.9410445094108582, acc: 0.6736400127410889, val_loss: 0.9803670644760132, val_accc: 0.6664000153541565\n","epoch :8, loss :0.9064726829528809, acc: 0.6856399774551392, val_loss: 0.9564294815063477, val_accc: 0.6743999719619751\n","epoch :9, loss :0.8765926957130432, acc: 0.6973999738693237, val_loss: 0.9617460370063782, val_accc: 0.6736000180244446\n","epoch :10, loss :0.8476676940917969, acc: 0.7076399922370911, val_loss: 0.9541712999343872, val_accc: 0.6790000200271606\n"]}]},{"cell_type":"code","metadata":{"id":"Ltq3PPs2ZkUa"},"source":[""],"execution_count":null,"outputs":[]}]}